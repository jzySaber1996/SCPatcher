[
  {
    "guid": 0,
    "question": "I have two apps that use Integrated Security. One assigns <code>Integrated Security = true</code> in the connection string,  and the other sets <code>Integrated Security = SSPI</code>.\n\nWhat is the difference between <code>SSPI</code> and <code>true</code> in the context of Integrated Security?\n",
    "accepted_answer": "According to <a href=\"https://learn.microsoft.com/en-us/dotnet/framework/data/adonet/connection-string-syntax\" rel=\"noreferrer\">Microsoft</a> they are the same thing.\n\n<blockquote>\n  When <code>false</code>, User ID and Password are specified in the connection. When true, the current Windows account credentials are used for authentication.<br>\n  Recognized values are <code>true</code>, <code>false</code>, <code>yes</code>, <code>no</code>, and <code>sspi</code> (strongly recommended), which is equivalent to <code>true</code>.\n</blockquote>\n",
    "text_a": "I have two apps that use Integrated Security. One assigns [CODE1] in the connection string,  and the other sets [CODE2].  What is the difference between SSPI and true in the context of Integrated Security? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 1,
    "question": "My team got handed over some server side code (in Java) that generates random tokens and I have a question regarding the same -\n\nThe purpose of these tokens is fairly sensitive - used for session id, password reset links etc. So they do need to be cryptographically random to avoid somebody guessing them or brute force them feasibly. The token is a \"long\" so it is 64 bits long.\n\nThe code currently uses the <code>java.util.Random</code> class to generate these tokens. The <a href=\"https://docs.oracle.com/javase/7/docs/api/java/util/Random.html\" rel=\"noreferrer\">documentation</a> for <code>java.util.Random</code> clearly states the following: \n\n<blockquote>\n  Instances of java.util.Random are not cryptographically secure. Consider instead using SecureRandom to get a cryptographically secure pseudo-random number generator for use by security-sensitive applications.\n</blockquote>\n\nHowever, the way the code is currently using <code>java.util.Random</code> is this - It instantiates the <code>java.security.SecureRandom</code> class and then uses the <code>SecureRandom.nextLong()</code> method to obtain the seed that is used for instantiating the <code>java.util.Random</code>class. Then it uses <code>java.util.Random.nextLong()</code> method to generate the token.\n\nSo my question now - Is it still insecure given that the <code>java.util.Random</code> is being seeded using <code>java.security.SecureRandom</code>? Do I need to modify the code so that it uses <code>java.security.SecureRandom</code> exclusively to generate the tokens?\n\nCurrently the code seed's the <code>Random</code> once at startup\n",
    "accepted_answer": "The standard Oracle JDK 7 implementation uses what's called a Linear Congruential Generator  to produce random values in <code>java.util.Random</code>. \n\nTaken from <code>java.util.Random</code> source code (JDK 7u2), from a comment on the method <code>protected int next(int bits)</code>, which is the one that generates the random values:\n\n<blockquote>\n  This is a linear congruential pseudorandom number generator, as\n    defined by D. H. Lehmer and described by Donald E. Knuth in\n    <i>The Art of Computer Programming,</i> Volume 3:\n    <i>Seminumerical Algorithms</i>, section 3.2.1.\n</blockquote>\n\n<h3>Predictability of Linear Congruential Generators</h3>\n\nHugo Krawczyk wrote a pretty good paper about how these LCGs can be predicted (\"How to predict congruential generators\"). If you're lucky and interested, you may still find a free, downloadable version of it on the web. And there's plenty more research that clearly shows that you should <strong>never</strong> use an LCG for security-critical purposes. This also means that your random numbers <em>are</em> predictable right now, something you don't want for session IDs and the like.\n\n<h3>How to break a Linear Congruential Generator</h3>\n\nThe assumption that an attacker would have to wait for the LCG to repeat after a full cycle is wrong. Even with an optimal cycle (the modulus m in its recurrence relation) it is very easy to predict future values in much less time than a full cycle. After all, it's just a bunch of modular equations that need to be solved, which becomes easy as soon as you have observed enough output values of the LCG. \n\nThe security doesn't improve with a \"better\" seed. It simply doesn't matter if you seed with a random value generated by <code>SecureRandom</code> or even produce the value by rolling a die several times. \n\nAn attacker will simply compute the seed from the output values observed. This takes <em>significantly less</em> time than 2^48 in the case of <code>java.util.Random</code>. Disbelievers may try out this <a href=\"http://jazzy.id.au/default/2010/09/20/cracking_random_number_generators_part_1.html\" rel=\"noreferrer\">experiment</a>, where it is shown that you can predict future <code>Random</code> outputs observing only two(!) output values in time roughly 2^16. It takes not even a second on a modern computer to predict the output of your random numbers right now.\n\n<h3>Conclusion</h3>\n\nReplace your current code. Use <code>SecureRandom</code> exclusively. Then at least you will have a little guarantee that the result will be hard to predict. If you want the properties of a cryptographically secure PRNG (in your case, that's what you want), then you have to go with <code>SecureRandom</code> only. Being clever about changing the way it was supposed to be used will almost always result in something less secure...\n",
    "text_a": "My team got handed over some server side code (in Java) that generates random tokens and I have a question regarding the same -  The purpose of these tokens is fairly sensitive - used for session id, password reset links etc. So they do need to be cryptographically random to avoid somebody guessing them or brute force them feasibly. The token is a \"long\" so it is 64 bits long.  The code currently uses the [CODE1] class to generate these tokens. The documentation for [CODE2] clearly states the following:      Instances of java.util.Random are not cryptographically secure. Consider instead using SecureRandom to get a cryptographically secure pseudo-random number generator for use by security-sensitive applications.   However, the way the code is currently using [CODE3] is this - It instantiates the java.security.SecureRandom class and then uses the SecureRandom.nextLong() method to obtain the seed that is used for instantiating the [CODE4]class. Then it uses java.util.Random.nextLong() method to generate the token.  So my question now - Is it still insecure given that the [CODE5] is being seeded using java.security.SecureRandom? Do I need to modify the code so that it uses java.security.SecureRandom exclusively to generate the tokens?  Currently the code seed's the Random once at startup ",
    "tgt_text": "The purpose of these tokens is fairly sensitive - used for session id, password reset links etc. So they do need to be cryptographically random to avoid somebody guessing them or brute force them feasibly. The token is a \"long\" so it is 64 bits long.",
    "label": "C4",
    "code": "<code>java.util.Random</code>",
    "insecure_code": "java.util.Random"
  },
  {
    "guid": 2,
    "question": "I am wondering wether the Password Hasher that is default implemented in the <a href=\"http://msdn.microsoft.com/en-us/library/dn468199%28v=vs.111%29.aspx\" rel=\"noreferrer\">UserManager</a> that comes with MVC 5 and ASP.NET Identity Framework, is secure enough? And if so, if you could explain to me how it works?\n\nIPasswordHasher interface looks like this:\n\n<pre><code>public interface IPasswordHasher\n{\n    string HashPassword(string password);\n    PasswordVerificationResult VerifyHashedPassword(string hashedPassword, \n                                                       string providedPassword);\n}\n</code></pre>\n\nAs you can see, it doesn't take a salt, but it is mentioned in this thread: \"<a href=\"https://stackoverflow.com/questions/19957176/asp-net-identity-password-hashing?rq=1\">Asp.net Identity password hashing</a>\"\n that it does infact salt it behind the scenes. So I am wondering how does it do this? And where does this salt come from?\n\nMy concern is that the salt is static, rendering it quite insecure.\n",
    "accepted_answer": "Here is how the default implementation (<a href=\"https://github.com/aspnet/AspNetIdentity/blob/master/src/Microsoft.AspNet.Identity.Core/Crypto.cs\" rel=\"noreferrer\">ASP.NET Framework</a> or <a href=\"https://github.com/dotnet/aspnetcore/blob/master/src/Identity/Extensions.Core/src/PasswordHasher.cs\" rel=\"noreferrer\">ASP.NET Core</a>) works. It uses a <a href=\"http://msdn.microsoft.com/en-us/library/h83s4e12%28v=vs.110%29.aspx\" rel=\"noreferrer\">Key Derivation Function</a> with random salt to produce the hash. The salt is included as part of the output of the KDF. Thus, each time you \"hash\" the same password you will get different hashes. To verify the hash the output is split back to the salt and the rest, and the KDF is run again on the password with the specified salt. If the result matches to the rest of the initial output the hash is verified.\n\nHashing:\n\n<pre><code>public static string HashPassword(string password)\n{\n    byte[] salt;\n    byte[] buffer2;\n    if (password == null)\n    {\n        throw new ArgumentNullException(\"password\");\n    }\n    using (Rfc2898DeriveBytes bytes = new Rfc2898DeriveBytes(password, 0x10, 0x3e8))\n    {\n        salt = bytes.Salt;\n        buffer2 = bytes.GetBytes(0x20);\n    }\n    byte[] dst = new byte[0x31];\n    Buffer.BlockCopy(salt, 0, dst, 1, 0x10);\n    Buffer.BlockCopy(buffer2, 0, dst, 0x11, 0x20);\n    return Convert.ToBase64String(dst);\n}\n</code></pre>\n\nVerifying:\n\n<pre><code>public static bool VerifyHashedPassword(string hashedPassword, string password)\n{\n    byte[] buffer4;\n    if (hashedPassword == null)\n    {\n        return false;\n    }\n    if (password == null)\n    {\n        throw new ArgumentNullException(\"password\");\n    }\n    byte[] src = Convert.FromBase64String(hashedPassword);\n    if ((src.Length != 0x31) || (src[0] != 0))\n    {\n        return false;\n    }\n    byte[] dst = new byte[0x10];\n    Buffer.BlockCopy(src, 1, dst, 0, 0x10);\n    byte[] buffer3 = new byte[0x20];\n    Buffer.BlockCopy(src, 0x11, buffer3, 0, 0x20);\n    using (Rfc2898DeriveBytes bytes = new Rfc2898DeriveBytes(password, dst, 0x3e8))\n    {\n        buffer4 = bytes.GetBytes(0x20);\n    }\n    return ByteArraysEqual(buffer3, buffer4);\n}\n</code></pre>\n",
    "text_a": "I am wondering wether the Password Hasher that is default implemented in the UserManager that comes with MVC 5 and ASP.NET Identity Framework, is secure enough? And if so, if you could explain to me how it works?  IPasswordHasher interface looks like this:  [CODE1]  As you can see, it doesn't take a salt, but it is mentioned in this thread: \"Asp.net Identity password hashing\"  that it does infact salt it behind the scenes. So I am wondering how does it do this? And where does this salt come from?  My concern is that the salt is static, rendering it quite insecure. ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 3,
    "question": "I'm trying to grok the purpose of .NET's SecureString.  From MSDN:\n<blockquote>\nAn instance of the System.String class is both immutable and, when no longer needed, cannot be programmatically scheduled for garbage collection; that is, the instance is read-only after it is created and it is not possible to predict when the instance will be deleted from computer memory. Consequently, if a String object contains sensitive information such as a password, credit card number, or personal data, there is a risk the information could be revealed after it is used because your application cannot delete the data from computer memory.\nA SecureString object is similar to a String object in that it has a text value. However, the value of a SecureString object is automatically encrypted, can be modified until your application marks it as read-only, and can be deleted from computer memory by either your application or the .NET Framework garbage collector.\nThe value of an instance of SecureString is automatically encrypted when the instance is initialized or when the value is modified. Your application can render the instance immutable and prevent further modification by invoking the MakeReadOnly method.\n</blockquote>\nIs the automatic encryption the big payoff?\nAnd why can't I just say:\n<pre><code>SecureString password = new SecureString(&quot;password&quot;);\n</code></pre>\ninstead of\n<pre><code>SecureString pass = new SecureString();\nforeach (char c in &quot;password&quot;.ToCharArray())\n    pass.AppendChar(c);\n</code></pre>\nWhat aspect of SecureString am I missing?\n",
    "accepted_answer": "I would stop using SecureString .  Looks like PG guys are dropping support for it.  Possibly even pull it in the future - <a href=\"https://github.com/dotnet/apireviews/tree/master/2015-07-14-securestring\" rel=\"nofollow\">https://github.com/dotnet/apireviews/tree/master/2015-07-14-securestring</a> .\n\n<blockquote>\n  We should remove encryption from  SecureString  across all platforms in .NET Core - We should obsolete  SecureString - We probably shouldn't expose  SecureString  in .NET Core\n</blockquote>\n",
    "text_a": "I'm trying to grok the purpose of .NET's SecureString.  From MSDN:  An instance of the System.String class is both immutable and, when no longer needed, cannot be programmatically scheduled for garbage collection; that is, the instance is read-only after it is created and it is not possible to predict when the instance will be deleted from computer memory. Consequently, if a String object contains sensitive information such as a password, credit card number, or personal data, there is a risk the information could be revealed after it is used because your application cannot delete the data from computer memory. A SecureString object is similar to a String object in that it has a text value. However, the value of a SecureString object is automatically encrypted, can be modified until your application marks it as read-only, and can be deleted from computer memory by either your application or the .NET Framework garbage collector. The value of an instance of SecureString is automatically encrypted when the instance is initialized or when the value is modified. Your application can render the instance immutable and prevent further modification by invoking the MakeReadOnly method.  Is the automatic encryption the big payoff? And why can't I just say: [CODE1] instead of [CODE2] What aspect of SecureString am I missing? ",
    "tgt_text": "I'm trying to grok the purpose of .NET's SecureString.",
    "label": "C2",
    "code": "<code>SecureString pass = new SecureString();\nforeach (char c in &quot;password&quot;.ToCharArray())\n    pass.AppendChar(c);\n</code>",
    "insecure_code": "SecureString pass = new SecureString();"
  },
  {
    "guid": 4,
    "question": "I came across a discussion in which I learned that what I'd been doing wasn't in fact salting passwords but peppering them, and I've since begun doing both with a function like:\n\n<pre><code>hash_function($salt.hash_function($pepper.$password)) [multiple iterations]\n</code></pre>\n\nIgnoring the chosen hash algorithm (I want this to be a discussion of salts &amp; peppers and not specific algorithms but I'm using a secure one), is this a secure option or should I be doing something different? For those unfamiliar with the terms:\n\n<ul>\n<li>A <strong>salt</strong> is a randomly generated value usually stored with the string in the database designed to make it impossible to use hash tables to crack passwords. As each password has its own salt, they must all be brute-forced individually in order to crack them; however, as the salt is stored in the database with the password hash, a database compromise means losing both.</li>\n<li>A <strong>pepper</strong> is a site-wide static value stored separately from the database (usually hard-coded in the application's source code) which is intended to be secret. It is used so that a compromise of the database would not cause the entire application's password table to be brute-forceable.</li>\n</ul>\n\nIs there anything I'm missing and is salting &amp; peppering my passwords the best option to protect my user's security? Is there any potential security flaw to doing it this way?\n\n<em>Note: Assume for the purpose of the discussion that the application &amp; database are stored on separate machines, do not share passwords etc. so a breach of the database server does not automatically mean a breach of the application server.</em>\n",
    "accepted_answer": "Ok. Seeing as I need to write about this <a href=\"https://stackoverflow.com/a/16597402/338665\">over</a> and <a href=\"http://blog.ircmaxell.com/2012/04/properly-salting-passwords-case-against.html\" rel=\"noreferrer\">over</a>, I'll do one last canonical answer on pepper alone.\n\n<h1>The Apparent Upside Of Peppers</h1>\n\nIt seems quite obvious that peppers should make hash functions more secure. I mean, if the attacker only gets your database, then your users passwords should be secure, right? Seems logical, right?\n\nThat's why so many people believe that peppers are a good idea. It \"makes sense\". \n\n<h1>The Reality Of Peppers</h1>\n\nIn the security and cryptography realms, \"make sense\" isn't enough. Something has to be provable <strong>and</strong> make sense in order for it to be considered secure. Additionally, it has to be implementable in a maintainable way. The most secure system that can't be maintained is considered insecure (because if any part of that security breaks down, the entire system falls apart).\n\nAnd peppers fit neither the provable or the maintainable models...\n\n<h1>Theoretical Problems With Peppers</h1>\n\nNow that we've set the stage, let's look at what's wrong with peppers.\n\n<ul>\n<li><strong>Feeding one hash into another can be dangerous.</strong>\n\nIn your example, you do <code>hash_function($salt . hash_function($pepper . $password))</code>.\n\nWe know from past experience that \"just feeding\" one hash result into another hash function can decrease the overall security. The reason is that both hash functions can become a target of attack. \n\nThat's why algorithms like <a href=\"http://en.wikipedia.org/wiki/PBKDF2\" rel=\"noreferrer\">PBKDF2</a> use special operations to combine them (hmac in that case).\n\nThe point is that while it's not a big deal, it is also not a trivial thing to just throw around. Crypto systems are designed to avoid \"should work\" cases, and instead focus on \"designed to work\" cases.\n\nWhile this may seem purely theoretical, it's in fact not. For example, <a href=\"http://blog.ircmaxell.com/2015/03/security-issue-combining-bcrypt-with.html\" rel=\"noreferrer\">Bcrypt cannot accept arbitrary passwords</a>. So passing <code>bcrypt(hash(pw), salt)</code> can indeed result in a far weaker hash than <code>bcrypt(pw, salt)</code> if <code>hash()</code> returns a binary string.</li>\n<li><strong>Working Against Design</strong>\n\nThe way bcrypt (and other password hashing algorithms) were designed is to work with a salt. The concept of a pepper was never introduced. This may seem like a triviality, but it's not. The reason is that a salt is not a secret. It is just a value that can be known to an attacker. A pepper on the other hand, by very definition is a cryptographic secret.\n\nThe current password hashing algorithms (bcrypt, pbkdf2, etc) all are designed to only take in one secret value (the password). Adding in another secret into the algorithm hasn't been studied at all.\n\nThat doesn't mean it is not safe. It means we don't know if it is safe. And the general recommendation with security and cryptography is that if we don't know, it isn't.\n\nSo until algorithms are designed and vetted by cryptographers for use with secret values (peppers), current algorithms shouldn't be used with them.</li>\n<li><strong>Complexity Is The Enemy Of Security</strong>\n\nBelieve it or not, <a href=\"http://www.schneier.com/news-038.html\" rel=\"noreferrer\">Complexity Is The Enemy Of Security</a>. Making an algorithm that looks complex may be secure, or it may be not. But the chances are quite significant that it's not secure. </li>\n</ul>\n\n<h1>Significant Problems With Peppers</h1>\n\n<ul>\n<li><strong>It's Not Maintainable</strong>\n\nYour implementation of peppers precludes the ability to rotate the pepper key. Since the pepper is used at the input to the one way function, you can never change the pepper for the lifetime of the value. This means that you'd need to come up with some wonky hacks to get it to support key rotation.\n\nThis is <strong>extremely</strong> important as it's required whenever you store cryptographic secrets. Not having a mechanism to rotate keys (periodically, and after a breach) is a huge security vulnerability.\n\nAnd your current pepper approach would require every user to either have their password completely invalidated by a rotation, or wait until their next login to rotate (which may be never)...\n\nWhich basically makes your approach an immediate no-go.</li>\n<li><strong>It Requires You To Roll Your Own Crypto</strong>\n\nSince no current algorithm supports the concept of a pepper, it requires you to either compose algorithms or invent new ones to support a pepper. And if you can't immediately see why that's a really bad thing:\n\n<blockquote>\n  Anyone, from the most clueless amateur to the best cryptographer, can create an algorithm that he himself can't break.\n</blockquote>\n\n<ul>\n<li><a href=\"http://www.schneier.com/blog/archives/2011/04/schneiers_law.html\" rel=\"noreferrer\">Bruce Schneier</a></li>\n</ul>\n\n<strong>NEVER</strong> roll your own crypto...</li>\n</ul>\n\n<h1>The Better Way</h1>\n\nSo, out of all the problems detailed above, there are two ways of handling the situation. \n\n<ul>\n<li><strong>Just Use The Algorithms As They Exist</strong>\n\nIf you use bcrypt or scrypt correctly (with a high cost), all but the weakest dictionary passwords should be statistically safe. The current record for hashing bcrypt at cost 5 is 71k hashes per second. At that rate even a 6 character random password would take years to crack. And considering my minimum recommended cost is 10, that reduces the hashes per second by a factor of 32. So we'd be talking only about 2200 hashes per second. At that rate, even some dictionary phrases or modificaitons may be safe.\n\nAdditionally, we should be checking for those weak classes of passwords at the door and not allowing them in. As password cracking gets more advanced, so should password quality requirements. It's still a statistical game, but with a proper storage technique, and strong passwords, everyone should be practically very safe...</li>\n<li><strong>Encrypt The Output Hash Prior To Storage</strong>\n\nThere exists in the security realm an algorithm designed to handle everything we've said above. It's a block cipher. It's good, because it's reversible, so we can rotate keys (yay! maintainability!). It's good because it's being used as designed. It's good because it gives the user no information.\n\nLet's look at that line again. Let's say that an attacker knows your algorithm (which is required for security, otherwise it's security through obscurity). With a traditional pepper approach, the attacker can create a sentinel password, and since he knows the salt and the output, he can brute force the pepper. Ok, that's a long shot, but it's possible. With a cipher, the attacker gets nothing. And since the salt is randomized, a sentinel password won't even help him/her. So the best they are left with is to attack the encrypted form. Which means that they first have to attack your encrypted hash to recover the encryption key, and then attack the hashes. But there's a <strong>lot</strong> of research into the attacking of ciphers, so we want to rely on that.</li>\n</ul>\n\n<h1>TL/DR</h1>\n\nDon't use peppers. There are a host of problems with them, and there are two better ways: not using any server-side secret (yes, it's ok) and encrypting the output hash using a block cipher prior to storage.\n",
    "text_a": "I came across a discussion in which I learned that what I'd been doing wasn't in fact salting passwords but peppering them, and I've since begun doing both with a function like:  [CODE1]  Ignoring the chosen hash algorithm (I want this to be a discussion of salts &amp; peppers and not specific algorithms but I'm using a secure one), is this a secure option or should I be doing something different? For those unfamiliar with the terms:   A salt is a randomly generated value usually stored with the string in the database designed to make it impossible to use hash tables to crack passwords. As each password has its own salt, they must all be brute-forced individually in order to crack them; however, as the salt is stored in the database with the password hash, a database compromise means losing both. A pepper is a site-wide static value stored separately from the database (usually hard-coded in the application's source code) which is intended to be secret. It is used so that a compromise of the database would not cause the entire application's password table to be brute-forceable.   Is there anything I'm missing and is salting &amp; peppering my passwords the best option to protect my user's security? Is there any potential security flaw to doing it this way?  Note: Assume for the purpose of the discussion that the application &amp; database are stored on separate machines, do not share passwords etc. so a breach of the database server does not automatically mean a breach of the application server. ",
    "tgt_text": "Ignoring the chosen hash algorithm (I want this to be a discussion of salts &amp; peppers and not specific algorithms but I'm using a secure one), is this a secure option or should I be doing something different?",
    "label": "C1",
    "code": "<code>hash_function($salt.hash_function($pepper.$password)) [multiple iterations]\n</code>",
    "insecure_code": "hash_function($salt.hash_function($pepper.$password))"
  },
  {
    "guid": 5,
    "question": "I am trying to use one-time passwords that can be generated using <a href=\"https://market.android.com/details?id=com.google.android.apps.authenticator\" rel=\"noreferrer\">Google Authenticator application</a>.\n<h2>What Google Authenticator does</h2>\nBasically, Google Authenticator implements two types of passwords:\n<ul>\n<li><strong>HOTP</strong> - HMAC-based One-Time Password, which means the password is changed with each call, in compliance to <a href=\"https://www.rfc-editor.org/rfc/rfc4226\" rel=\"noreferrer\">RFC4226</a>, and</li>\n<li><strong>TOTP</strong> - Time-based One-Time Password, which changes for every 30-seconds period (as far as I know).</li>\n</ul>\nGoogle Authenticator is also available as Open Source here: <a href=\"http://code.google.com/p/google-authenticator/\" rel=\"noreferrer\">code.google.com/p/google-authenticator</a>\n<h2>Current code</h2>\nI was looking for existing solutions to generate HOTP and TOTP passwords, but did not find much. The code I have is the following snippet responsible for generating HOTP:\n<pre><code>import hmac, base64, struct, hashlib, time\n\ndef get_token(secret, digest_mode=hashlib.sha1, intervals_no=None):\n    if intervals_no == None:\n        intervals_no = int(time.time()) // 30\n    key = base64.b32decode(secret)\n    msg = struct.pack(&quot;&gt;Q&quot;, intervals_no)\n    h = hmac.new(key, msg, digest_mode).digest()\n    o = ord(h[19]) &amp; 15\n    h = (struct.unpack(&quot;&gt;I&quot;, h[o:o+4])[0] &amp; 0x7fffffff) % 1000000\n    return h\n</code></pre>\nThe problem I am facing is that the password I generate using the above code is not the same as generated using Google Authenticator app for Android. Even though I tried multiple <code>intervals_no</code> values (exactly first 10000, beginning with <code>intervals_no = 0</code>), with <code>secret</code> being equal to key provided within the GA app.\n<h2>Questions I have</h2>\nMy questions are:\n<ol>\n<li>What am I doing wrong?</li>\n<li>How can I generate HOTP and/or TOTP in Python?</li>\n<li>Are there any existing Python libraries for this?</li>\n</ol>\nTo sum up: please give me any clues that will help me implement Google Authenticator authentication within my Python code.\n",
    "accepted_answer": "I wanted to set a bounty on my question, but I have succeeded in creating solution. My problem seemed to be connected with incorrect value of <code>secret</code> key (it must be correct parameter for <code>base64.b32decode()</code> function).\n\nBelow I post full working solution with explanation on how to use it.\n\n<h2>Code</h2>\n\nThe following code is enough. I have also uploaded it to GitHub as separate module called <em>onetimepass</em> (available here: <a href=\"https://github.com/tadeck/onetimepass\">https://github.com/tadeck/onetimepass</a>).\n\n<pre class=\"lang-py prettyprint-override\"><code>import hmac, base64, struct, hashlib, time\n\ndef get_hotp_token(secret, intervals_no):\n    key = base64.b32decode(secret, True)\n    msg = struct.pack(\"&gt;Q\", intervals_no)\n    h = hmac.new(key, msg, hashlib.sha1).digest()\n    o = ord(h[19]) &amp; 15\n    h = (struct.unpack(\"&gt;I\", h[o:o+4])[0] &amp; 0x7fffffff) % 1000000\n    return h\n\ndef get_totp_token(secret):\n    return get_hotp_token(secret, intervals_no=int(time.time())//30)\n</code></pre>\n\nIt has two functions:\n\n<ul>\n<li><code>get_hotp_token()</code> generates one-time token (that should invalidate after single use),</li>\n<li><code>get_totp_token()</code> generates token based on time (changed in 30-second intervals),</li>\n</ul>\n\n<h2>Parameters</h2>\n\nWhen it comes to parameters:\n\n<ul>\n<li><code>secret</code> is a secret value known to server (the above script) and client (Google Authenticator, by providing it as password within application),</li>\n<li><code>intervals_no</code> is the number incremeneted after each generation of the token (this should be probably resolved on the server by checking some finite number of integers after last successful one checked in the past)</li>\n</ul>\n\n<h2>How to use it</h2>\n\n<ol>\n<li>Generate <code>secret</code> (it must be correct parameter for <code>base64.b32decode()</code>) - preferably 16-char (no <code>=</code> signs), as it surely worked for both script and Google Authenticator.</li>\n<li>Use <code>get_hotp_token()</code> if you want one-time passwords invalidated after each use. In Google Authenticator this type of passwords i  mentioned as based on the counter. For checking it on the server you will need to check several values of <code>intervals_no</code> (as you have no quarantee that user did not generate the pass between the requests for some reason), but not less than the last working <code>intervals_no</code> value (thus you should probably store it somewhere).</li>\n<li>Use <code>get_totp_token()</code>, if you want a token working in 30-second intervals. You have to make sure both systems have correct time set (meaning that they both generate the same Unix timestamp in any given moment in time).</li>\n<li>Make sure to protect yourself from brute-force attack. If time-based password is used, then trying 1000000 values in less than 30 seconds gives 100% chance of guessing the password. In case of HMAC-based passowrds (HOTPs) it seems to be even worse.</li>\n</ol>\n\n<h2>Example</h2>\n\nWhen using the following code for one-time HMAC-based password:\n\n<pre class=\"lang-py prettyprint-override\"><code>secret = 'MZXW633PN5XW6MZX'\nfor i in xrange(1, 10):\n    print i, get_hotp_token(secret, intervals_no=i)\n</code></pre>\n\nyou will get the following result:\n\n<pre><code>1 448400\n2 656122\n3 457125\n4 35022\n5 401553\n6 581333\n7 16329\n8 529359\n9 171710\n</code></pre>\n\nwhich is corresponding to the tokens generated by the Google Authenticator app (except if shorter than 6 signs, app adds zeros to the beginning to reach a length of 6 chars).\n",
    "text_a": "I am trying to use one-time passwords that can be generated using Google Authenticator application. What Google Authenticator does Basically, Google Authenticator implements two types of passwords:  HOTP - HMAC-based One-Time Password, which means the password is changed with each call, in compliance to RFC4226, and TOTP - Time-based One-Time Password, which changes for every 30-seconds period (as far as I know).  Google Authenticator is also available as Open Source here: code.google.com/p/google-authenticator Current code I was looking for existing solutions to generate HOTP and TOTP passwords, but did not find much. The code I have is the following snippet responsible for generating HOTP: [CODE1] The problem I am facing is that the password I generate using the above code is not the same as generated using Google Authenticator app for Android. Even though I tried multiple intervals_no values (exactly first 10000, beginning with intervals_no = 0), with secret being equal to key provided within the GA app. Questions I have My questions are:  What am I doing wrong? How can I generate HOTP and/or TOTP in Python? Are there any existing Python libraries for this?  To sum up: please give me any clues that will help me implement Google Authenticator authentication within my Python code. ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 6,
    "question": "I am trying to add some security to the forms on my website. One of the forms uses AJAX and the other is a straightforward &quot;contact us&quot; form. I'm trying to add a CSRF token. The problem I'm having is that the token is only showing up in the HTML &quot;value&quot; some of the time. The rest of the time, the value is empty. Here is the code I am using on the AJAX form:\nPHP :\n<pre class=\"lang-php prettyprint-override\"><code>if (!isset($_SESSION)) {\n    session_start();\n    $_SESSION['formStarted'] = true;\n}\n\nif (!isset($_SESSION['token'])) {\n    $token = md5(uniqid(rand(), TRUE));\n    $_SESSION['token'] = $token;\n}\n</code></pre>\nHTML :\n<pre class=\"lang-html prettyprint-override\"><code>&lt;input type=&quot;hidden&quot; name=&quot;token&quot; value=&quot;&lt;?php echo $token; ?&gt;&quot; /&gt;\n</code></pre>\nAny suggestions?\n",
    "accepted_answer": "For security code, please don't generate your tokens this way: <code>$token = md5(uniqid(rand(), TRUE));</code>\n\n<ul>\n<li><a href=\"https://jazzy.id.au/2010/09/20/cracking_random_number_generators_part_1.html\" rel=\"noreferrer\"><code>rand()</code> is predictable</a></li>\n<li><a href=\"http://securitymaverick.com/php-uniqid-entropy-analysis-and-potentially-vulnerable-apps\" rel=\"noreferrer\"><code>uniqid()</code> only adds up to 29 bits of entropy</a></li>\n<li><code>md5()</code> doesn't add entropy, it just mixes it deterministically</li>\n</ul>\n\nTry this out:\n\n<h2>Generating a CSRF Token</h2>\n\n<h3>PHP 7</h3>\n\n<pre><code>session_start();\nif (empty($_SESSION['token'])) {\n    $_SESSION['token'] = bin2hex(random_bytes(32));\n}\n$token = $_SESSION['token'];\n</code></pre>\n\nSidenote: One of <a href=\"https://paragonie.com/projects\" rel=\"noreferrer\">my employer's open source projects</a> is an initiative to backport <code>random_bytes()</code> and <code>random_int()</code> into PHP 5 projects. It's MIT licensed and available on Github and Composer as <a href=\"https://github.com/paragonie/random_compat\" rel=\"noreferrer\">paragonie/random_compat</a>.\n\n<h3>PHP 5.3+ (or with ext-mcrypt)</h3>\n\n<pre><code>session_start();\nif (empty($_SESSION['token'])) {\n    if (function_exists('mcrypt_create_iv')) {\n        $_SESSION['token'] = bin2hex(mcrypt_create_iv(32, MCRYPT_DEV_URANDOM));\n    } else {\n        $_SESSION['token'] = bin2hex(openssl_random_pseudo_bytes(32));\n    }\n}\n$token = $_SESSION['token'];\n</code></pre>\n\n<h2>Verifying the CSRF Token</h2>\n\nDon't just use <code>==</code> or even <code>===</code>, use <a href=\"https://secure.php.net/hash_equals\" rel=\"noreferrer\"><code>hash_equals()</code></a> (PHP 5.6+ only, but available to earlier versions with the <a href=\"https://github.com/indigophp/hash-compat\" rel=\"noreferrer\">hash-compat</a> library).\n\n<pre><code>if (!empty($_POST['token'])) {\n    if (hash_equals($_SESSION['token'], $_POST['token'])) {\n         // Proceed to process the form data\n    } else {\n         // Log this as a warning and keep an eye on these attempts\n    }\n}\n</code></pre>\n\n<hr>\n\n<h2>Going Further with Per-Form Tokens</h2>\n\nYou can further restrict tokens to only be available for a particular form by using <a href=\"https://secure.php.net/hash_hmac\" rel=\"noreferrer\"><code>hash_hmac()</code></a>. HMAC is a particular keyed hash function that is safe to use, even with weaker hash functions (e.g. MD5). However, I recommend using the SHA-2 family of hash functions instead.\n\nFirst, generate a second token for use as an HMAC key, then use logic like this to render it:\n\n<pre><code>&lt;input type=\"hidden\" name=\"token\" value=\"&lt;?php\n    echo hash_hmac('sha256', '/my_form.php', $_SESSION['second_token']);\n?&gt;\" /&gt;\n</code></pre>\n\nAnd then using a congruent operation when verifying the token:\n\n<pre><code>$calc = hash_hmac('sha256', '/my_form.php', $_SESSION['second_token']);\nif (hash_equals($calc, $_POST['token'])) {\n    // Continue...\n}\n</code></pre>\n\nThe tokens generated for one form cannot be reused in another context without knowing <code>$_SESSION['second_token']</code>. <strong>It is important that you use a separate token as an HMAC key than the one you just drop on the page.</strong>\n\n<h3>Bonus: Hybrid Approach + Twig Integration</h3>\n\nAnyone who uses the <a href=\"http://twig.sensiolabs.org\" rel=\"noreferrer\">Twig templating engine</a> can benefit from a simplified dual strategy by adding this filter to their Twig environment:\n\n<pre><code>$twigEnv-&gt;addFunction(\n    new \\Twig_SimpleFunction(\n        'form_token',\n        function($lock_to = null) {\n            if (empty($_SESSION['token'])) {\n                $_SESSION['token'] = bin2hex(random_bytes(32));\n            }\n            if (empty($_SESSION['token2'])) {\n                $_SESSION['token2'] = random_bytes(32);\n            }\n            if (empty($lock_to)) {\n                return $_SESSION['token'];\n            }\n            return hash_hmac('sha256', $lock_to, $_SESSION['token2']);\n        }\n    )\n);\n</code></pre>\n\nWith this Twig function, you can use both the general purpose tokens like so:\n\n<pre><code>&lt;input type=\"hidden\" name=\"token\" value=\"{{ form_token() }}\" /&gt;\n</code></pre>\n\nOr the locked down variant:\n\n<pre><code>&lt;input type=\"hidden\" name=\"token\" value=\"{{ form_token('/my_form.php') }}\" /&gt;\n</code></pre>\n\nTwig is only concerned with template rendering; you still must validate the tokens properly. In my opinion, the Twig strategy offers greater flexibility and simplicity, while maintaining the possibility for maximum security.\n\n<hr>\n\n<h2>Single-Use CSRF Tokens</h2>\n\nIf you have a security requirement that each CSRF token is allowed to be usable exactly once, the simplest strategy regenerate it after each successful validation. However, doing so will invalidate every previous token which doesn't mix well with people who browse multiple tabs at once.\n\nParagon Initiative Enterprises maintains an <a href=\"https://github.com/paragonie/anti-csrf\" rel=\"noreferrer\">Anti-CSRF library</a> for these corner cases. It works with one-use per-form tokens, exclusively. When enough tokens are stored in the session data (default configuration: 65535), it will cycle out the oldest unredeemed tokens first.\n",
    "text_a": "I am trying to add some security to the forms on my website. One of the forms uses AJAX and the other is a straightforward &quot;contact us&quot; form. I'm trying to add a CSRF token. The problem I'm having is that the token is only showing up in the HTML &quot;value&quot; some of the time. The rest of the time, the value is empty. Here is the code I am using on the AJAX form: PHP : [CODE1] HTML : [CODE2] Any suggestions? ",
    "tgt_text": "rand() is predictable uniqid() only adds up to 29 bits of entropy md5() doesn't add entropy, it just mixes it deterministically",
    "label": "C1",
    "code": "<code>if (!isset($_SESSION)) {\n    session_start();\n    $_SESSION['formStarted'] = true;\n}\n\nif (!isset($_SESSION['token'])) {\n    $token = md5(uniqid(rand(), TRUE));\n    $_SESSION['token'] = $token;\n}\n</code>",
    "insecure_code": "$token = md5(uniqid(rand(), TRUE));"
  },
  {
    "guid": 7,
    "question": "I need to store sensitive information (a symmetric encryption key that I want to keep private) in my C++ application. The simple approach is to do this:\n<pre><code>std::string myKey = &quot;mysupersupersecretpasswordthatyouwillneverguess&quot;;\n</code></pre>\nHowever, running the application through the <code>strings</code> process (or any other that extracts strings from a binary app) will reveal the above string.\nWhat techniques should be used to obscure such sensitive data?\n<strong>Edit:</strong>\nOK, so pretty much all of you have said <em>&quot;your executable can be reverse engineered&quot;</em> - of course! This is a pet peeve of mine, so I'm going to rant a bit here:\nWhy is it that 99% (OK, so perhaps I exaggerate a little) of all security-related questions on this site are answered with a  torrent of &quot;there is no possible way to create a perfectly secure program&quot; - that is not a helpful answer! Security is a sliding scale between perfect usability and no security at one end, and perfect security but no usability at the other.\nThe point is that you pick your position on that sliding scale depending on what you're trying to do and the environment in which your software will run. <em>I'm not writing an app for a military installation, I'm writing an app for a home PC</em>. I need to encrypt data across an untrusted network with a pre-known encryption key. In these cases, &quot;security through obscurity&quot; is probably good enough! Sure, someone with enough time, energy and skill could reverse-engineer the binary and find the password, but guess what? I don't care:\nThe time it takes me to implement a top-notch secure system is more expensive than the loss of sales due to the cracked versions (not that I'm actually selling this, but you get my point). This blue-sky &quot;lets do it the absolute best way possible&quot; trend in programming amongst new programmers is foolish to say the least.\nThank you for taking the time to answer this question - they were most helpful. Unfortunately I can only accept one answer, but I've up-voted all the useful answers.\n",
    "accepted_answer": "Basically, anyone with access to your program and a debugger <em>can</em> and <em>will</em> find the key in the application if they want to.\n\nBut, if you just want to make sure the key doesn't show up when running <code>strings</code> on your binary, you could for instance make sure that the key is not within the printable range.\n\n<strong>Obscuring key with XOR</strong>\n\nFor instance, you could use XOR to split the key into two byte arrays:\n\n<pre><code>key = key1 XOR key2\n</code></pre>\n\nIf you create key1 with the same byte-length as <code>key</code> you can use (completely) random byte values and then compute <code>key2</code>:\n\n<pre><code>key1[n] = crypto_grade_random_number(0..255)\nkey2[n] = key[n] XOR key1[n]\n</code></pre>\n\nYou can do this in your build environment, and then only store <code>key1</code>and <code>key2</code> in your application.\n\n<strong>Protecting your binary</strong>\n\nAnother approach is to use a tool to protect your binary.  For instance, there are several security tools that can make sure your binary is obfuscated and starts a virtual machine that it runs on.  This makes it hard(er) to debug, and is also the convential way many commercial grade secure applications (also, alas, malware) is protected.\n\nOne of the premier tools is <a href=\"http://www.oreans.com/products.php\" rel=\"noreferrer\">Themida</a>, which does an awesome job of protecting your binaries.  It is often used by well known programs, such as Spotify, to protect against reverse engineering.  It has features to prevent debugging in programs such as OllyDbg and Ida Pro.\n\nThere is also a larger list, maybe somewhat outdated, of <a href=\"http://www.google.com/Top/Computers/Security/Products_and_Tools/Software_Protection_and_License_Control/\" rel=\"noreferrer\">tools to protect your binary</a>.<br>\nSome of them are free.\n\n<strong>Password matching</strong>\n\nSomeone here discussed hashing password+salt.  \n\nIf you need to store the key to match it against some kind of user submitted password, you should use a one-way hashing function, preferrably by combining username, password and a salt.  The problem with this, though, is that your application has to know the salt to be able to do the one-way and compare the resulting hashes.  So therefore you still need to store the salt somewhere in your application. But, as @Edward points out in the comments below, this will effectively protect against a dictionary attack using, e.g, rainbow tables.\n\nFinally, you can use a combination of all the techniques above.\n",
    "text_a": "I need to store sensitive information (a symmetric encryption key that I want to keep private) in my C++ application. The simple approach is to do this: [CODE1] However, running the application through the strings process (or any other that extracts strings from a binary app) will reveal the above string. What techniques should be used to obscure such sensitive data? Edit: OK, so pretty much all of you have said &quot;your executable can be reverse engineered&quot; - of course! This is a pet peeve of mine, so I'm going to rant a bit here: Why is it that 99% (OK, so perhaps I exaggerate a little) of all security-related questions on this site are answered with a  torrent of &quot;there is no possible way to create a perfectly secure program&quot; - that is not a helpful answer! Security is a sliding scale between perfect usability and no security at one end, and perfect security but no usability at the other. The point is that you pick your position on that sliding scale depending on what you're trying to do and the environment in which your software will run. I'm not writing an app for a military installation, I'm writing an app for a home PC. I need to encrypt data across an untrusted network with a pre-known encryption key. In these cases, &quot;security through obscurity&quot; is probably good enough! Sure, someone with enough time, energy and skill could reverse-engineer the binary and find the password, but guess what? I don't care: The time it takes me to implement a top-notch secure system is more expensive than the loss of sales due to the cracked versions (not that I'm actually selling this, but you get my point). This blue-sky &quot;lets do it the absolute best way possible&quot; trend in programming amongst new programmers is foolish to say the least. Thank you for taking the time to answer this question - they were most helpful. Unfortunately I can only accept one answer, but I've up-voted all the useful answers. ",
    "tgt_text": "store sensitive information (a symmetric encryption key that I want to keep private) in my C++ application",
    "label": "C1",
    "code": "<code>std::string myKey = &quot;mysupersupersecretpasswordthatyouwillneverguess&quot;;\n</code>",
    "insecure_code": "std::string myKey = &quot;mysupersupersecretpasswordthatyouwillneverguess&quot;;"
  },
  {
    "guid": 8,
    "question": "The more I learned about the power of <code>java.lang.reflect.AccessibleObject.setAccessible</code>, the more astonished I am at what it can do. This is adapted from my answer to the question (<a href=\"https://stackoverflow.com/questions/2474017/using-reflection-to-change-static-final-file-separatorchar-for-unit-testing/2474242#2474242\">Using reflection to change static final File.separatorChar for unit testing</a>).\n\n<pre><code>import java.lang.reflect.*;\n\npublic class EverythingIsTrue {\n   static void setFinalStatic(Field field, Object newValue) throws Exception {\n      field.setAccessible(true);\n\n      Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n      modifiersField.setAccessible(true);\n      modifiersField.setInt(field, field.getModifiers() &amp; ~Modifier.FINAL);\n\n      field.set(null, newValue);\n   }\n   public static void main(String args[]) throws Exception {      \n      setFinalStatic(Boolean.class.getField(\"FALSE\"), true);\n\n      System.out.format(\"Everything is %s\", false); // \"Everything is true\"\n   }\n}\n</code></pre>\n\nYou can do truly outrageous stuff:\n\n<pre><code>public class UltimateAnswerToEverything {\n   static Integer[] ultimateAnswer() {\n      Integer[] ret = new Integer[256];\n      java.util.Arrays.fill(ret, 42);\n      return ret;\n   }   \n   public static void main(String args[]) throws Exception {\n      EverythingIsTrue.setFinalStatic(\n         Class.forName(\"java.lang.Integer$IntegerCache\")\n            .getDeclaredField(\"cache\"),\n         ultimateAnswer()\n      );\n      System.out.format(\"6 * 9 = %d\", 6 * 9); // \"6 * 9 = 42\"\n   }\n}\n</code></pre>\n\nPresumably the API designers realize how abusable <code>setAccessible</code> can be, but must have conceded that it has legitimate uses to provide it. So my questions are:\n\n<ul>\n<li>What are the truly legitimate uses for <code>setAccessible</code>?\n\n<ul>\n<li>Could Java has been designed as to NOT have this need in the first place?</li>\n<li>What would the negative consequences (if any) of such design be?</li>\n</ul></li>\n<li>Can you restrict <code>setAccessible</code> to legitimate uses only?\n\n<ul>\n<li>Is it only through <code>SecurityManager</code>?\n\n<ul>\n<li>How does it work? Whitelist/blacklist, granularity, etc?</li>\n<li>Is it common to have to configure it in your applications?</li>\n</ul></li>\n<li>Can I write my classes to be <code>setAccessible</code>-proof regardless of <code>SecurityManager</code> configuration?\n\n<ul>\n<li>Or am I at the mercy of whoever manages the configuration?</li>\n</ul></li>\n</ul></li>\n</ul>\n\n<hr>\n\nI guess one more important question is: DO I NEED TO WORRY ABOUT THIS???\n\nNone of my classes have any semblance of enforceable privacy what-so-ever. The singleton pattern (putting doubts about its merits aside) is now impossible to enforce. As my snippets above show, even some basic assumptions of how Java fundamental works is not even close to being guaranteed.\n\nARE THESE PROBLEMS NOT REAL???\n\n<hr>\n\nOkay, I just confirmed: thanks to <code>setAccessible</code>, Java strings are <em>NOT</em> immutable.\n\n<pre><code>import java.lang.reflect.*;\n\npublic class MutableStrings {\n   static void mutate(String s) throws Exception {\n      Field value = String.class.getDeclaredField(\"value\");\n      value.setAccessible(true);\n      value.set(s, s.toUpperCase().toCharArray());\n   }   \n   public static void main(String args[]) throws Exception {\n      final String s = \"Hello world!\";\n      System.out.println(s); // \"Hello world!\"\n      mutate(s);\n      System.out.println(s); // \"HELLO WORLD!\"\n   }\n}\n</code></pre>\n\nAm I the only one who thinks this is a HUGE concern?\n",
    "accepted_answer": "<strong>DO I NEED TO WORRY ABOUT THIS???</strong>\n\nThat depends entirely on what types of programs you're writing and for what kind of an architecture.\n\nIf you're distributing a software component called foo.jar to the people of the world, you're completely at their mercy anyway. They could modify the class definitions inside your .jar (through reverse engineering or direct bytecode manipulation). They could run your code in their own JVM, etc. In this case worrying will do you no good.\n\nIf you're writing a web-application that only interfaces with people and systems via HTTP and you control the application server, it's also not a concern. Sure the fellow coders at your company may create code that breaks your singleton pattern, but only if they really want to.\n\nIf your future job is writing code at Sun Microsystems/Oracle and you're tasked with writing code for the Java core or other trusted components, it's something you should be aware of. Worrying, however, will just make you lose your hair. In any case they'll probably make you read the <a href=\"http://java.sun.com/security/seccodeguide.html\" rel=\"noreferrer\">Secure Coding Guidelines</a> along with internal documentation.\n\nIf you're going to be writing Java applets, the security framework is something you should be aware of. You'll find that unsigned applets trying to call setAccessible will just result in a SecurityException.\n\nsetAccessible is not the only thing that goes around conventional integrity checks. There's a non-API, core Java class called sun.misc.Unsafe that can do pretty much anything at all it wants to, including accessing memory directly. Native code (JNI) can go around this kind of control as well.\n\nIn a sandboxed environment (for example Java Applets, JavaFX), each class has a set of permissions and access to Unsafe, setAccessible and defining native implementations are controlled by the SecurityManager.\n\n\"Java access modifiers are not intended to be a security mechanism.\"\n\nThat very much depends on where the Java code is being run. The core Java classes do use access modifiers as a security mechanism to enforce the sandbox.\n\n<strong>What are the truly legitimate uses for setAccessible?</strong>\n\nThe Java core classes use it as an easy way to access stuff that has to remain private for security reasons. As an example, the Java Serialization framework uses it to invoke private object constructors when deserializing objects. Someone mentioned System.setErr, and it would be a good example, but curiously the System class methods setOut/setErr/setIn all use native code for setting the value of the final field.\n\nAnother obvious legitimate use are the frameworks (persistence, web frameworks, injection) that need to peek into the insides of objects.\n\nDebuggers, in my opinion, don't fall into this category, as they normally don't run in the same JVM process, but instead the interface with the JVM using other means (JPDA).\n\n<strong>Could Java has been designed as to NOT have this need in the first place?</strong>\n\nThat's a pretty deep question to answer well. I imagine yes, but you'd need to add some other mechanism(s) that might not be all that preferrable.\n\n<strong>Can you restrict setAccessible to legitimate uses only?</strong>\n\nThe most straight-forward OOTB restriction you can apply is to have a SecurityManager and allow setAccessible only to code coming from certain sources. This is what Java already does - the standard Java classes that come from your JAVA_HOME are allowed to do setAccessible, while unsigned applet classes from foo.com aren't allowed to do setAccessible. As was said before, this permission is binary, in the sense that one either has it or not. There is no obvious way to allow setAccessible to modify certain fields/methods while disallowing others. Using the SecurityManager you could, however, disallow classes from referencing certain packages completely, with or without reflection.\n\n<strong>Can I write my classes to be setAccessible-proof regardless of SecurityManager configuration? ... Or am I at the mercy of whoever manages the configuration?</strong>\n\nYou can't and you most certainly are.\n",
    "text_a": "The more I learned about the power of java.lang.reflect.AccessibleObject.setAccessible, the more astonished I am at what it can do. This is adapted from my answer to the question (Using reflection to change static final File.separatorChar for unit testing).  [CODE1]  You can do truly outrageous stuff:  [CODE2]  Presumably the API designers realize how abusable setAccessible can be, but must have conceded that it has legitimate uses to provide it. So my questions are:   What are the truly legitimate uses for setAccessible?   Could Java has been designed as to NOT have this need in the first place? What would the negative consequences (if any) of such design be?  Can you restrict setAccessible to legitimate uses only?   Is it only through SecurityManager?   How does it work? Whitelist/blacklist, granularity, etc? Is it common to have to configure it in your applications?  Can I write my classes to be setAccessible-proof regardless of SecurityManager configuration?   Or am I at the mercy of whoever manages the configuration?       I guess one more important question is: DO I NEED TO WORRY ABOUT THIS???  None of my classes have any semblance of enforceable privacy what-so-ever. The singleton pattern (putting doubts about its merits aside) is now impossible to enforce. As my snippets above show, even some basic assumptions of how Java fundamental works is not even close to being guaranteed.  ARE THESE PROBLEMS NOT REAL???    Okay, I just confirmed: thanks to setAccessible, Java strings are NOT immutable.  [CODE3]  Am I the only one who thinks this is a HUGE concern? ",
    "tgt_text": "",
    "label": "C1",
    "code": "<code>import java.lang.reflect.*;\n\npublic class EverythingIsTrue {\n   static void setFinalStatic(Field field, Object newValue) throws Exception {\n      field.setAccessible(true);\n\n      Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n      modifiersField.setAccessible(true);\n      modifiersField.setInt(field, field.getModifiers() &amp; ~Modifier.FINAL);\n\n      field.set(null, newValue);\n   }\n   public static void main(String args[]) throws Exception {      \n      setFinalStatic(Boolean.class.getField(\"FALSE\"), true);\n\n      System.out.format(\"Everything is %s\", false); // \"Everything is true\"\n   }\n}\n</code>",
    "insecure_code": " Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n      modifiersField.setAccessible(true);\n      modifiersField.setInt(field, field.getModifiers() &amp; ~Modifier.FINAL);"
  },
  {
    "guid": 9,
    "question": "When trying to read a RSA private key from a file using the method\n\n<pre><code>public PrivateKey getPrivateKey()\n        throws NoSuchAlgorithmException,\n        InvalidKeySpecException, IOException {\n\n    final InputStream inputStream = getClass().getClassLoader()\n                    .getResourceAsStream(\"privatekey\");\n    byte[] privKeyBytes = null;\n    try {\n        privKeyBytes = IOUtils.toByteArray(inputStream);\n    } catch (final IOException exception) {\n        LOGGER.error(\"\", exception);\n        IOUtils.closeQuietly(inputStream);\n    }\n\n    LOGGER.debug(\"privKeyBytes: {}\", privKeyBytes);\n\n    String BEGIN = \"-----BEGIN RSA PRIVATE KEY-----\";\n    String END = \"-----END RSA PRIVATE KEY-----\";\n    String str = new String(privKeyBytes);\n    if (str.contains(BEGIN) &amp;&amp; str.contains(END)) {\n        str = str.substring(BEGIN.length(), str.lastIndexOf(END));\n    }\n\n    KeyFactory fac = KeyFactory.getInstance(\"RSA\");\n    EncodedKeySpec privKeySpec =\n            new PKCS8EncodedKeySpec(Base64.decode(str.getBytes()));\n    return fac.generatePrivate(privKeySpec);\n}\n</code></pre>\n\nI get the exception\n\n<pre><code>java.security.spec.InvalidKeySpecException: java.security.InvalidKeyException: IOException : algid parse error, not a sequence\n    at sun.security.rsa.RSAKeyFactory.engineGeneratePrivate(RSAKeyFactory.java:200) ~[na:1.6.0_23]\n    at java.security.KeyFactory.generatePrivate(KeyFactory.java:342) ~[na:1.6.0_23]\n</code></pre>\n\nat the fac.generatePrivate(privKeySpec) call.\n\nWhat does this error mean?\n\nThanks\n\nDmitri\n",
    "accepted_answer": "It means your key is not in PKCS#8 format. The easiest thing to do is to use the <code>openssl pkcs8 -topk8 &lt;...other options...&gt;</code> command to convert the key once. Alternatively you can use the <a href=\"http://www.bouncycastle.org/docs/docs1.5on/org/bouncycastle/util/io/pem/PemReader.html\"><code>PEMReader</code></a> class of the <a href=\"http://www.bouncycastle.org/documentation.html\">Bouncycastle lightweight API</a>.\n",
    "text_a": "When trying to read a RSA private key from a file using the method  [CODE1]  I get the exception  [CODE2]  at the fac.generatePrivate(privKeySpec) call.  What does this error mean?  Thanks  Dmitri ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 10,
    "question": "The last week I read a lot articles about password hashing and Blowfish seems to be (one of) the best hashing algorithm right now - but that's not the topic of this question!\n\n<h1>The 72 character limit</h1>\n\nBlowfish only consider the first 72 characters in the entered password:\n\n<pre class=\"lang-php prettyprint-override\"><code>&lt;?php\n$password = \"Wow. This is a super secret and super, super long password. Let's add some special ch4r4ct3rs a#d everything is fine :)\";\n$hash = password_hash($password, PASSWORD_BCRYPT);\nvar_dump($password);\n\n$input = substr($password, 0, 72);\nvar_dump($input);\n\nvar_dump(password_verify($input, $hash));\n?&gt;\n</code></pre>\n\nThe output is:\n\n<pre><code>string(119) \"Wow. This is a super secret and super, super long password. Let's add some special ch4r4ct3rs a#d everything is fine :)\"\nstring(72) \"Wow. This is a super secret and super, super long password. Let's add so\"\nbool(true)\n</code></pre>\n\nAs you can see only the first 72 characters matter. Twitter is using blowfish aka bcrypt to store their passwords (<a href=\"https://shouldichangemypassword.com/twitter-hacked.php\" rel=\"noreferrer\">https://shouldichangemypassword.com/twitter-hacked.php</a>) and guess what: change your twitter password to a long password with more than 72 characters and you can login to your account by entering only the first 72 characters.\n\n<h1>Blowfish and Pepper</h1>\n\nThere are a lot different opinions about \"peppering\" passwords. Some people say it's unnecessary, because you have to assume that the secret pepper-string is also known/published so it doesn't enhance the hash. I have a separate database server so it's quite possible that only the database is leaked and not the constant pepper.\n\nIn this case (pepper not leaked) you make an attack based on a dictionary more difficult (correct me if this isn't right). If your pepper-string is also leaked: not that bad - you still have the salt and it's as good protected as a hash without pepper.  \n\nSo I think peppering the password is at least no bad choice.\n\n<h1>Suggestion</h1>\n\nMy suggestion to get a Blowfish hash for a password with more than 72 characters (and pepper) is:\n\n<pre class=\"lang-php prettyprint-override\"><code>&lt;?php\n$pepper = \"foIwUVmkKGrGucNJMOkxkvcQ79iPNzP5OKlbIdGPCMTjJcDYnR\";\n\n// Generate Hash\n$password = \"Wow. This is a super secret and super, super long password. Let's add some special ch4r4ct3rs a#d everything is fine :)\";\n$password_peppered = hash_hmac('sha256', $password, $pepper);\n$hash = password_hash($password_peppered, PASSWORD_BCRYPT);\n\n// Check\n$input = substr($password, 0, 72);\n$input_peppered = hash_hmac('sha256', $input, $pepper);\n\nvar_dump(password_verify($input_peppered, $hash));\n?&gt;\n</code></pre>\n\nThis is based on <a href=\"https://security.stackexchange.com/questions/21263/how-to-apply-a-pepper-correctly-to-bcrypt\">this question</a>: <code>password_verify</code> return <code>false</code>.  \n\n<h1>The Question</h1>\n\nWhat is the safer way? Getting an SHA-256 hash first (which returns 64 characters) or consider only the first 72 characters of the password?  \n\n<h2>Pros</h2>\n\n<ul>\n<li>The user can't login by entering just the first 72 characters</li>\n<li>You can add the pepper without exceeding the character-limit</li>\n<li>The output of hash_hmac would probably have more entropy than the password itself</li>\n<li>The password is hashed by two different functions</li>\n</ul>\n\n<h2>Cons</h2>\n\n<ul>\n<li>Only 64 characters are used to build the blowfish hash</li>\n</ul>\n\n<br/>\n\n<strong>Edit 1:</strong> This question adresses only the PHP integration of blowfish/bcrypt. Thank's for the comments!\n",
    "accepted_answer": "Note: if you choose to do this, use a library. For PHP, I strongly recommend Zend Framework 2's Zend\\Crypt package. It's actually the only one I'd recommend at this current point in time. It's been strongly reviewed, and it makes all the decisions for you (which is a very good thing)...\n\nSomething like:\n\n<pre><code>use Zend\\Crypt\\BlockCipher;\n\npublic function createHash($password) {\n    $hash = password_hash($password, PASSWORD_BCRYPT, [\"cost\"=&gt;$this-&gt;cost]);\n\n    $blockCipher = BlockCipher::factory('mcrypt', array('algo' =&gt; 'aes'));\n    $blockCipher-&gt;setKey($this-&gt;key);\n    return $blockCipher-&gt;encrypt($hash);\n}\n\npublic function verifyHash($password, $hash) {\n    $blockCipher = BlockCipher::factory('mcrypt', array('algo' =&gt; 'aes'));\n    $blockCipher-&gt;setKey($this-&gt;key);\n    $hash = $blockCipher-&gt;decrypt($hash);\n\n    return password_verify($password, $hash);\n}\n</code></pre>\n\nAnd it's beneficial because you're using all of the algorithms in ways that are well understood and well studied (relatively at least). Remember:\n\n<blockquote>\n  Anyone, from the most clueless amateur to the best cryptographer, can create an algorithm that he himself can't break.\n</blockquote>\n\n<ul>\n<li><a href=\"http://www.schneier.com/blog/archives/2011/04/schneiers_law.html\" rel=\"noreferrer\">Bruce Schneier</a></li>\n</ul>\n",
    "text_a": "The last week I read a lot articles about password hashing and Blowfish seems to be (one of) the best hashing algorithm right now - but that's not the topic of this question!  The 72 character limit  Blowfish only consider the first 72 characters in the entered password:  [CODE1]  The output is:  [CODE2]  As you can see only the first 72 characters matter. Twitter is using blowfish aka bcrypt to store their passwords (https://shouldichangemypassword.com/twitter-hacked.php) and guess what: change your twitter password to a long password with more than 72 characters and you can login to your account by entering only the first 72 characters.  Blowfish and Pepper  There are a lot different opinions about \"peppering\" passwords. Some people say it's unnecessary, because you have to assume that the secret pepper-string is also known/published so it doesn't enhance the hash. I have a separate database server so it's quite possible that only the database is leaked and not the constant pepper.  In this case (pepper not leaked) you make an attack based on a dictionary more difficult (correct me if this isn't right). If your pepper-string is also leaked: not that bad - you still have the salt and it's as good protected as a hash without pepper.    So I think peppering the password is at least no bad choice.  Suggestion  My suggestion to get a Blowfish hash for a password with more than 72 characters (and pepper) is:  [CODE3]  This is based on this question: password_verify return false.    The Question  What is the safer way? Getting an SHA-256 hash first (which returns 64 characters) or consider only the first 72 characters of the password?    Pros   The user can't login by entering just the first 72 characters You can add the pepper without exceeding the character-limit The output of hash_hmac would probably have more entropy than the password itself The password is hashed by two different functions   Cons   Only 64 characters are used to build the blowfish hash     Edit 1: This question adresses only the PHP integration of blowfish/bcrypt. Thank's for the comments! ",
    "tgt_text": "hash password with Blowfish",
    "label": "C1",
    "code": "<code>&lt;?php\n$password = \"Wow. This is a super secret and super, super long password. Let's add some special ch4r4ct3rs a#d everything is fine :)\";\n$hash = password_hash($password, PASSWORD_BCRYPT);\nvar_dump($password);\n\n$input = substr($password, 0, 72);\nvar_dump($input);\n\nvar_dump(password_verify($input, $hash));\n?&gt;\n</code>",
    "insecure_code": "$hash = password_hash($password, PASSWORD_BCRYPT);\nvar_dump($password);\n\n$input = substr($password, 0, 72);\nvar_dump($input);\n\nvar_dump(password_verify($input, $hash));"
  },
  {
    "guid": 11,
    "question": "I want to validate a set of credentials against the domain controller. e.g.:\n\n<pre><code>Username: STACKOVERFLOW\\joel\nPassword: splotchy\n</code></pre>\n\n<h2>Method 1. Query Active Directory with Impersonation</h2>\n\nA lot of people suggest querying the Active Directory for something. If an exception is thrown, then you know the credentials are not valid - as is suggested in <a href=\"https://stackoverflow.com/questions/290548/c-validate-a-username-and-password-against-active-directory\">this stackoverflow question</a>.\n\nThere are some serious <a href=\"http://bytes.com/groups/net-c/249893-fyi-easy-way-validate-ad-credentials-win2k-using-c\" rel=\"noreferrer\">drawbacks to this approach</a> however:\n\n<ol>\n<li>You are not only authenticating a domain account, but you are also doing an implicit authorization check. That is, you are reading properties from the AD using an impersonation token. What if the otherwise valid account has no rights to read from the AD? By default all users have read access, but domain policies can be set to disable access permissions for restricted accounts (and or groups).</li>\n<li>Binding against the AD has a serious overhead, the AD schema cache has to be loaded at the client (ADSI cache in the ADSI provider used by DirectoryServices). This is both network, and AD server, resource consuming - and is too expensive for a simple operation like authenticating a user account.</li>\n<li>You're relying on an exception failure for a non-exceptional case, and assuming that means invalid username and password. Other problems (e.g. network failure, AD connectivity failure, memory allocation error, etc) are then mis-intrepreted as authentication failure.</li>\n</ol>\n\n<h2>Method 2. LogonUser Win32 API</h2>\n\n<a href=\"https://stackoverflow.com/questions/290548/c-validate-a-username-and-password-against-active-directory#290558\">Others</a> have suggested using the <a href=\"http://msdn.microsoft.com/en-us/library/aa378184.aspx\" rel=\"noreferrer\"><code>LogonUser()</code></a> API function. This sounds nice, but unfortunately the calling user sometimes needs a permission usually only given to the operating system itself:\n\n<blockquote>\n  The process calling LogonUser requires\n  the SE_TCB_NAME privilege. If the\n  calling process does not have this\n  privilege, LogonUser fails and\n  GetLastError returns\n  ERROR_PRIVILEGE_NOT_HELD. \n  \n  In some\n  cases, the process that calls\n  LogonUser must also have the\n  SE_CHANGE_NOTIFY_NAME privilege\n  enabled; otherwise, LogonUser fails\n  and GetLastError returns\n  ERROR_ACCESS_DENIED. This privilege is\n  not required for the local system\n  account or accounts that are members\n  of the administrators group. By\n  default, SE_CHANGE_NOTIFY_NAME is\n  enabled for all users, but some\n  administrators may disable it for\n  everyone.\n</blockquote>\n\nHanding out the \"<em>Act as a part of the operating system</em>\" privilege is not something you want to do willy-nilly - as Microsoft points out in a <a href=\"http://support.microsoft.com/kb/180548\" rel=\"noreferrer\">knowledge base article</a>:\n\n<blockquote>\n  ...the process that is calling\n  LogonUser must have the SE_TCB_NAME\n  privilege (in User Manager, this is\n  the \"<em>Act as part of the Operating\n  System</em>\" right). The SE_TCB_NAME\n  privilege is very powerful and\n  <strong>should not be granted to any arbitrary user just so that they can\n  run an application</strong> that needs to\n  validate credentials.\n</blockquote>\n\nAdditionally, a call to <code>LogonUser()</code> will fail if a blank password is specified.\n\n<hr>\n\nWhat is the proper way to authenticate a set of domain credentials?\n\n<hr>\n\nI <em>happen</em> to be calling from managed code, but this is a a general Windows question. It can be assumed that the customers have the .NET Framework 2.0 installed.\n",
    "accepted_answer": "C# in .NET 3.5 using <a href=\"http://msdn.microsoft.com/en-us/library/system.directoryservices.accountmanagement.aspx\" rel=\"noreferrer\">System.DirectoryServices.AccountManagement</a>.\n\n<pre><code> bool valid = false;\n using (PrincipalContext context = new PrincipalContext(ContextType.Domain))\n {\n     valid = context.ValidateCredentials( username, password );\n }\n</code></pre>\n\nThis will validate against the current domain.  Check out the parameterized PrincipalContext constructor for other options.\n",
    "text_a": "I want to validate a set of credentials against the domain controller. e.g.:  [CODE1]  Method 1. Query Active Directory with Impersonation  A lot of people suggest querying the Active Directory for something. If an exception is thrown, then you know the credentials are not valid - as is suggested in this stackoverflow question.  There are some serious drawbacks to this approach however:   You are not only authenticating a domain account, but you are also doing an implicit authorization check. That is, you are reading properties from the AD using an impersonation token. What if the otherwise valid account has no rights to read from the AD? By default all users have read access, but domain policies can be set to disable access permissions for restricted accounts (and or groups). Binding against the AD has a serious overhead, the AD schema cache has to be loaded at the client (ADSI cache in the ADSI provider used by DirectoryServices). This is both network, and AD server, resource consuming - and is too expensive for a simple operation like authenticating a user account. You're relying on an exception failure for a non-exceptional case, and assuming that means invalid username and password. Other problems (e.g. network failure, AD connectivity failure, memory allocation error, etc) are then mis-intrepreted as authentication failure.   Method 2. LogonUser Win32 API  Others have suggested using the LogonUser() API function. This sounds nice, but unfortunately the calling user sometimes needs a permission usually only given to the operating system itself:     The process calling LogonUser requires   the SE_TCB_NAME privilege. If the   calling process does not have this   privilege, LogonUser fails and   GetLastError returns   ERROR_PRIVILEGE_NOT_HELD.       In some   cases, the process that calls   LogonUser must also have the   SE_CHANGE_NOTIFY_NAME privilege   enabled; otherwise, LogonUser fails   and GetLastError returns   ERROR_ACCESS_DENIED. This privilege is   not required for the local system   account or accounts that are members   of the administrators group. By   default, SE_CHANGE_NOTIFY_NAME is   enabled for all users, but some   administrators may disable it for   everyone.   Handing out the \"Act as a part of the operating system\" privilege is not something you want to do willy-nilly - as Microsoft points out in a knowledge base article:     ...the process that is calling   LogonUser must have the SE_TCB_NAME   privilege (in User Manager, this is   the \"Act as part of the Operating   System\" right). The SE_TCB_NAME   privilege is very powerful and   should not be granted to any arbitrary user just so that they can   run an application that needs to   validate credentials.   Additionally, a call to LogonUser() will fail if a blank password is specified.    What is the proper way to authenticate a set of domain credentials?    I happen to be calling from managed code, but this is a a general Windows question. It can be assumed that the customers have the .NET Framework 2.0 installed. ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 12,
    "question": "In order to generate a 32 character token for access to our API we currently use:\n\n<pre><code>$token = md5(uniqid(mt_rand(), true));\n</code></pre>\n\nI have read that this method is not cryptographically secure as it's based on the system clock, and that <code>openssl_random_pseudo_bytes</code> would be a better solution as it would be harder to predict.\n\nIf this is the case, what would the equivalent code look like?\n\nI presume something like this, but I don't know if this is right...\n\n<pre><code>$token = md5(openssl_random_pseudo_bytes(32));\n</code></pre>\n\nAlso what length makes sense that I should pass to the function?\n",
    "accepted_answer": "Here is the correct solution:\n\n<pre><code>$token = bin2hex(openssl_random_pseudo_bytes(16));\n\n# or in php7\n$token = bin2hex(random_bytes(16));\n</code></pre>\n",
    "text_a": "In order to generate a 32 character token for access to our API we currently use:  [CODE1]  I have read that this method is not cryptographically secure as it's based on the system clock, and that openssl_random_pseudo_bytes would be a better solution as it would be harder to predict.  If this is the case, what would the equivalent code look like?  I presume something like this, but I don't know if this is right...  [CODE2]  Also what length makes sense that I should pass to the function? ",
    "tgt_text": "generate a 32 character token for access to our API",
    "label": "C1",
    "code": "<code>$token = md5(uniqid(mt_rand(), true));\n</code>",
    "insecure_code": "$token = md5(uniqid(mt_rand(), true));"
  },
  {
    "guid": 13,
    "question": "I had a look at <a href=\"https://stackoverflow.com/questions/1391132/two-way-encryption-in-php\">this</a> question, and wanted to do it for myself. When I ran this code (taken straight from <a href=\"https://stackoverflow.com/a/6639179/962144\">this answer</a>):\n\n<pre><code>$textToEncrypt = \"My super secret information.\";\n$encryptionMethod = \"AES-256-CBC\";  // AES is used by the U.S. gov't to encrypt top secret documents.\n$secretHash = \"25c6c7ff35b9979b151f2136cd13b0ff\";\n\n//To encrypt\n$encryptedMessage = openssl_encrypt($textToEncrypt, $encryptionMethod, $secretHash, '1234567812345678');\n\n//To Decrypt\n$decryptedMessage = openssl_decrypt($encryptedMessage, $encryptionMethod, $secretHash);\n\n//Result\necho \"Encrypted: $encryptedMessage &lt;br&gt;Decrypted: $decryptedMessage\";\n</code></pre>\n\nHowever I get the warning\n\n<pre><code>openssl_encrypt(): Using an empty Initialization Vector (iv) is potentially insecure and not recommended\n</code></pre>\n\nSo I went and had a look at the <a href=\"http://www.php.net/manual/en/function.openssl-encrypt.php\" rel=\"noreferrer\">docs</a>, but there 'is no documentation'. I found this <a href=\"http://www.php.net/manual/en/function.openssl-encrypt.php#99188\" rel=\"noreferrer\">comment</a>, but still no mention of what the Initialization Vector should be and how I should use it. Can anyone enlighten me?\n\nI know I could have done some more Googleing, but Stackoverflow comes up first in so many search results I thought this question might be useful to anyone else who was having this problem.\n",
    "accepted_answer": "\nNow, your code appears to be setting the IV (1234567812345678) but not using it on decryption. That's certain to fail.\nYou also may want to utilize some of PHP's IV generation functions. I think this should work for you:\n<pre><code>$iv_size = mcrypt_get_iv_size(MCRYPT_RIJNDAEL_128, MCRYPT_MODE_CBC);\n$iv = mcrypt_create_iv($iv_size, MCRYPT_RAND);\n$encryptedMessage = openssl_encrypt($textToEncrypt, $encryptionMethod, $secretHash, 0, $iv);\n$decryptedMessage = openssl_decrypt($encryptedMessage, $encryptionMethod, $secretHash, 0, $iv);\n</code></pre>\nFor storage/transmission, one option is to simply concatenate the IV and cipher text like so:\n<pre><code>$data = $iv.$encryptedMessage;\n</code></pre>\nThen on retrieval, pull the IV out for decryption:\n<pre><code>$iv_size = mcrypt_get_iv_size(MCRYPT_RIJNDAEL_128, MCRYPT_MODE_CBC);\n$iv = substr($data, 0, $iv_size);\n$decryptedMessage = openssl_decrypt(substr($data, $iv_size), $encryptionMethod, $secretHash, 0, $iv);\n</code></pre>\nIf you're storing the IV in a database for example, you could also store the IV in an adjacent column to simplify the extraction process.\n<hr />\nFor more info, check out PHP's Mcrypt library. It's quite full featured and has tons of examples, many of which can help you out with openssh encryption implementations.\n<a href=\"http://php.net/manual/en/function.mcrypt-encrypt.php\" rel=\"nofollow noreferrer\">http://php.net/manual/en/function.mcrypt-encrypt.php</a>\n<hr />\nAn obligatory security disclaimer: My words describe the simplest of simple concepts in the simplest possible way. In the reach and depth of my knowledge, I am an absolute novice. Even the best of the best security researchers and experts introduce encryption vulnerabilities <em>all the time</em>. Even so, the less you write on your own, the better off your users, customers, family, and friends will be. No offense! While it's fun, interesting, and even practical to learn about encryption theory, especially applied to computer science in something as accessible as PHP, staying up to date with best practices and using the latest trusted libraries is going to provide the most secure systems for 99.9999999% of us. Nothing is perfect, but it's best to stand on the shoulders of giants. As a wise man probably might have said, &quot;The more you <em>learn</em> the more you realize how little you <em>know</em>.&quot;\n",
    "text_a": "I had a look at this question, and wanted to do it for myself. When I ran this code (taken straight from this answer):  [CODE1]  However I get the warning  [CODE2]  So I went and had a look at the docs, but there 'is no documentation'. I found this comment, but still no mention of what the Initialization Vector should be and how I should use it. Can anyone enlighten me?  I know I could have done some more Googleing, but Stackoverflow comes up first in so many search results I thought this question might be useful to anyone else who was having this problem. ",
    "tgt_text": "Use of Initialization Vector in openssl_encrypt",
    "label": "C1",
    "code": "<code>$textToEncrypt = \"My super secret information.\";\n$encryptionMethod = \"AES-256-CBC\";  // AES is used by the U.S. gov't to encrypt top secret documents.\n$secretHash = \"25c6c7ff35b9979b151f2136cd13b0ff\";\n\n//To encrypt\n$encryptedMessage = openssl_encrypt($textToEncrypt, $encryptionMethod, $secretHash, '1234567812345678');\n\n//To Decrypt\n$decryptedMessage = openssl_decrypt($encryptedMessage, $encryptionMethod, $secretHash);\n\n//Result\necho \"Encrypted: $encryptedMessage &lt;br&gt;Decrypted: $decryptedMessage\";\n</code>",
    "insecure_code": "$encryptedMessage = openssl_encrypt($textToEncrypt, $encryptionMethod, $secretHash, '1234567812345678');"
  },
  {
    "guid": 14,
    "question": "I am developing a JSON/REST web API, for which I specifically want third party websites to be able to call my service through AJAX. Hence, my service is sending the famous CORS header:\n\n<pre><code>Access-Control-Allow-Origin: *\n</code></pre>\n\nWhich allows third party sites to call my service through AJAX. All fine so far.\n\nHowever, a subsection of my web api is non-public and requires authentication (pretty standard stuff with OAuth and an access_token cookie). Is it safe to enable CORS on this part of my site as well?\n\nOn the one hand, it would be cool if third party websites could have ajax clients that also interact with this part of my service. However, the reason that there is a same origin policy in the first place, is that this might be risky. You don't want any website that you visit afterwards to be able to access your private content. \n\nThe scenario that I am afraid of is that a user logs in on my web api, either on the website or through a website that he trusts, and he forgets to logout. Will this allow every other website that he vists afterwards to access his private content using the existing session?\n\nSo my questions:\n\n<ul>\n<li>Is it ever safe to enable CORS on non-public content?</li>\n<li>If a CORS enabled server sets a session_token through a cookie, will this cookie be saved under the domain of the CORS server or main web-page server? </li>\n</ul>\n",
    "accepted_answer": "In answer to your second question (If a CORS enabled server sets a session_token through a cookie...?), the cookie is saved under the domain of the CORS server. The main web page's JS code can't access the cookie, even via <code>document.cookie</code>. The cookie is only sent to the server when the <code>.withCredentials</code> property is set, and even then, it is only accepted when the server sets the <code>Access-Control-Allow-Credentials</code> header.\n\nYour first question is a little more open ended. It is fairly secure, but there are ways to circumvent things. For example, an attacker could use a DNS poisoning technique to cause a preflight request to hit the actual server, but send the actual CORS request to the rogue server. Here are some more resources on CORS security:\n\n<ul>\n<li><a href=\"http://code.google.com/p/html5security/wiki/CrossOriginRequestSecurity\" rel=\"noreferrer\">http://code.google.com/p/html5security/wiki/CrossOriginRequestSecurity</a></li>\n<li><a href=\"https://www.owasp.org/index.php/HTML5_Security_Cheat_Sheet#Cross_Origin_Resource_Sharing\" rel=\"noreferrer\">owasp.org CORS CheatSheet</a></li>\n</ul>\n\nLastly, your concern is around giving <em>any</em> website access to your CORS data. In order to protect against this, you should not use the <code>Access-Control-Allow-Origin: *</code> header. Instead, you should echo back the user's Origin value. For example:\n\n<pre><code>Access-Control-Allow-Origin: http://www.example.com\n</code></pre>\n\nThis header will allow only <code>http://www.example.com</code> to access the response data.\n",
    "text_a": "I am developing a JSON/REST web API, for which I specifically want third party websites to be able to call my service through AJAX. Hence, my service is sending the famous CORS header:  [CODE1]  Which allows third party sites to call my service through AJAX. All fine so far.  However, a subsection of my web api is non-public and requires authentication (pretty standard stuff with OAuth and an access_token cookie). Is it safe to enable CORS on this part of my site as well?  On the one hand, it would be cool if third party websites could have ajax clients that also interact with this part of my service. However, the reason that there is a same origin policy in the first place, is that this might be risky. You don't want any website that you visit afterwards to be able to access your private content.   The scenario that I am afraid of is that a user logs in on my web api, either on the website or through a website that he trusts, and he forgets to logout. Will this allow every other website that he vists afterwards to access his private content using the existing session?  So my questions:   Is it ever safe to enable CORS on non-public content? If a CORS enabled server sets a session_token through a cookie, will this cookie be saved under the domain of the CORS server or main web-page server?   ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 15,
    "question": "<strong>Update: Please note I am not asking what a salt is, what a rainbow table is, what a dictionary attack is, or what the purpose of a salt is. I am querying: If you know the users salt and hash, isn't it quite easy to calculate their password?</strong>\n\nI understand the process, and implement it myself in some of my projects.\n\n<pre><code>s =  random salt\nstoredPassword = sha1(password + s)\n</code></pre>\n\nIn the database you store:\n\n<pre><code>username | hashed_password | salt\n</code></pre>\n\nEvery implementation of salting I have seen adds the salt either at the end of the password, or beginning:\n\n<pre><code>hashed_Password = sha1(s + password )\nhashed_Password = sha1(password + s)\n</code></pre>\n\nTherfore, a dictionary attack from a hacker who is worth his salt (ha ha) would simply run each keyword against the stored salts in the common combinations listed above.\n\nSurely the implementation described above simply adds another step for the hacker, without actually solving the underlying issue?  What alternatives are there to step around this issue, or am I misunderstanding the problem?\n\nThe only thing I can think to do is have a secret blending algorithm that laces the salt and password together in a random pattern, or adds other user fields to the hashing process meaning the hacker would have to have access to the database AND code to lace them for a dictionary attack to prove fruitful. (Update, as pointed out in comments it's best to assume the hacker has access to all your information so this probably isn't best).\n\nLet me give an example of how I propose a hacker would hack a user database with a list of passwords and hashes:\n\nData from our hacked database:\n\n<pre><code>RawPassword (not stored)  |  Hashed   |     Salt\n--------------------------------------------------------\nletmein                       WEFLS...       WEFOJFOFO...\n</code></pre>\n\nCommon password dictionary:\n\n<pre><code>   Common Password\n   --------------\n   letmein\n   12345\n   ...\n</code></pre>\n\nFor each user record, loop the common passwords and hash them:\n\n<pre><code>for each user in hacked_DB\n\n    salt = users_salt\n    hashed_pw = users_hashed_password\n\n    for each common_password\n\n        testhash = sha1(common_password + salt)\n        if testhash = hashed_pw then\n           //Match!  Users password = common_password\n           //Lets visit the webpage and login now.\n        end if\n\n    next\n\nnext\n</code></pre>\n\nI hope this illustrates my point a lot better.\n\nGiven 10,000 common passwords, and 10,000 user records, we would need to calculate 100,000,000 hashes to discover as many user passwords as possible.  It might take a few hours, but it's not really an issue.",
    "accepted_answer": "Yes, you need just 3 days for sha1(salt | password). That's why good password storage algorithms use 1000-iteration hashing: you will need 8 years.\n",
    "text_a": "Update: Please note I am not asking what a salt is, what a rainbow table is, what a dictionary attack is, or what the purpose of a salt is. I am querying: If you know the users salt and hash, isn't it quite easy to calculate their password?  I understand the process, and implement it myself in some of my projects.  [CODE1]  In the database you store:  [CODE2]  Every implementation of salting I have seen adds the salt either at the end of the password, or beginning:  [CODE3]  Therfore, a dictionary attack from a hacker who is worth his salt (ha ha) would simply run each keyword against the stored salts in the common combinations listed above.  Surely the implementation described above simply adds another step for the hacker, without actually solving the underlying issue?  What alternatives are there to step around this issue, or am I misunderstanding the problem?  The only thing I can think to do is have a secret blending algorithm that laces the salt and password together in a random pattern, or adds other user fields to the hashing process meaning the hacker would have to have access to the database AND code to lace them for a dictionary attack to prove fruitful. (Update, as pointed out in comments it's best to assume the hacker has access to all your information so this probably isn't best).  Let me give an example of how I propose a hacker would hack a user database with a list of passwords and hashes:  Data from our hacked database:  [CODE4]  Common password dictionary:  [CODE5]  For each user record, loop the common passwords and hash them:  [CODE6]  I hope this illustrates my point a lot better.  Given 10,000 common passwords, and 10,000 user records, we would need to calculate 100,000,000 hashes to discover as many user passwords as possible.  It might take a few hours, but it's not really an issue.",
    "tgt_text": "Every implementation of salting I have seen adds the salt either at the end of the password, or beginnin",
    "label": "C3",
    "code": "<code>hashed_Password = sha1(s + password )\nhashed_Password = sha1(password + s)\n</code>",
    "insecure_code": "hashed_Password = sha1(s + password )\nhashed_Password = sha1(password + s)"
  },
  {
    "guid": 16,
    "question": "I read about DDD and Access Control, and I found some contradiction between the following two opinions:\n\n<ul>\n<li>\"security concerns should be handled outside the domain\"</li>\n<li>\"access control requirements are domain specific\"</li>\n</ul>\n\nI am looking for a best practice about this. So where should I put the access control logic by domain driven design, and how should I implement it?\n\n(To be more specific by DDD + CQRS + ES.)\n\nI think it should be somewhere near to the business logic, for example a user story could be something like this:\n\n<blockquote>\n  The user can edit his profile by sending an user name, a list of hobbies, cv, etc...\n</blockquote>\n\nBased on the user story we implement the domain model and the services, for example:\n\n<pre><code>UserService\n    editProfile(EditUserProfileCommand command)\n        User user = userRepository.getOneById(command.id)\n        user.changeName(command.name)\n        user.changeHobbies(command.hobbies)\n        user.changeCV(command.cv)\n\nUserRepository\n    User getOneById(id)\n\nUser\n    changeName(String name)\n    changeHobbies(String[] hobbies)\n    changeCV(String cv)\n</code></pre>\n\nThis is okay, but where is the <code>HIS profile</code> part of the story?\n\nThis is obviously attribute based access control, because we should write a rule something like this:\n\n<pre><code>deny all, but if subject.id = resource.owner.id then grant access\n</code></pre>\n\nBut where should we enforce this rule, and how should we implement it?\n",
    "accepted_answer": "<blockquote>\n  So where should I put the access control logic?\n</blockquote>\n\nAccording to this: <a href=\"https://softwareengineering.stackexchange.com/a/71883/65755\">https://softwareengineering.stackexchange.com/a/71883/65755</a> the policy enforcement point should be right before the call of the <code>UserService.editProfile()</code>.\n\nI came to the same conclusion: it cannot be in the UI because by multiple UIs we would have code repetition. It should be before the creation of domain events, because they indicated that we have already done something in the system. So we can restrict the access to domain objects or to services which use those domain objects. By CQRS we don't necessary have domain objects by the read model, just services, so we have to restrict access to the services if we want a general solution. We could put the access decisions at the beginning of every service operation, but that would be <code>grant all, deny x</code> security anti pattern.\n\n<blockquote>\n  How should I implement it?\n</blockquote>\n\nThis depends on which access control model fits to the domain, so it depends on the user story. By an access decision we usually send an access request and wait a permission in return. The access request usually has the following parts: subject, resource, operation, environment. So the subject requires permission to perform an operation on the resource in an environment. First we identify the subject, then we authenticate it, and after that comes the authorization, where we check whether the access request fits to our access policy. Every access control model works in a similar way. Ofc. they can lack of some of these steps, but that does not matter...  \n\nI created a short list of access control models. I put the rules, policies into annotations, but normally we should store them in a database probably in XACML format if we want to have a well maintainable system...\n\n<ul>\n<li>By identity based access control (IBAC) we have an identity - permission storage (access control list, capability list, access control matrix). So for example by an access control list, we store the list of the users or groups whose can have permissions.  \n\n<pre><code>UserService\n    @AccessControlList[inf3rno]\n    editProfile(EditUserProfileCommand command)\n</code></pre></li>\n<li>By lattice based access control (LBAC) the subject has a clearance level, the resource has a required clearance level, and we check which level is higher...\n\n<pre><code>@posseses[level=5]\ninf3rno\n\nUserService\n    @requires(level&gt;=3)\n    editProfile(EditUserProfileCommand command)\n</code></pre></li>\n<li>By role based access control (RBAC) we define subject roles and we grant permissions to subjects whose act the actual role.\n\n<pre><code>@roles[admin]\ninf3rno\n\nUserService\n    @requires(role=admin)\n    editProfile(EditUserProfileCommand command)\n</code></pre></li>\n<li>By attribute based access control (ABAC) we define subject, resource and environment attributes and we write our policies based on them.\n\n<pre><code>@attributes[roles=[admin]]\ninf3rno\n\nUserService\n    @policy(subject.role=admin or resource.owner.id = subject.id)\n    editProfile(EditUserProfileCommand command)\n    @attribute(owner)\n    Subject getOwner(EditUserProfileCommand command)\n</code></pre></li>\n<li>By policy based access control (PBAC) we don't assign our policies to anything else, they are standalone.\n\n<pre><code>@attributes[roles=[admin]]\ninf3rno\n\nUserService\n    editProfile(EditUserProfileCommand command)\n    deleteProfile(DeleteUserProfileCommand command)\n    @attribute(owner)\n    Subject getOwner(EditUserProfileCommand command)\n\n@permission(UserService.editProfile, UserService.deleteProfile)\n@criteria(subject.role=admin or resource.owner.id = subject.id)\nWriteUserServicePolicy\n</code></pre></li>\n<li>By risk-adaptive access control (RAdAC) we base our decision on the relative risk profile of the subject and the risk level of the operation. This cannot be described with rules I think. I am unsure of the implementation, maybe this is what stackoverflow uses by its point system.</li>\n<li>By authorization based access control (ZBAC) we don't do identification and authentication, instead we assign permissions to identification factors. For example if somebody sends a token, then she can have access to a service. Everything else is similar to the previous solutions. For example with ABAC:\n\n<pre><code>@attributes[roles=[editor]]\ntoken:2683fraicfv8a2zuisbkcaac\n\nArticleService\n    @policy(subject.role=editor)\n    editArticle(EditArticleCommand command)\n</code></pre>\n\nSo everybody who knows the <code>2683fraicfv8a2zuisbkcaac</code> token can use the service.</li>\n</ul>\n\nand so on...\n\nThere are many other models, and the best fit always depends on the needs of your customer.\n\nSo to summarize\n\n<pre><code>- \"security concerns should be handled outside the domain\"\n- \"access control requirements are domain specific\"\n</code></pre>\n\nboth can be right, because security is not part of the domain model, but its implementation depends on the domain model and the application logic.\n\n<strong>edit after 2 years</strong>\n2016-09-05\n\nSince I answered my own question as a DDD newbie, I have read <a href=\"https://rads.stackoverflow.com/amzn/click/com/0321834577\" rel=\"noreferrer\" rel=\"nofollow noreferrer\">Implementing Domain-Driven Design</a> from Vaughn Vernon. It was an interesting book in the topic. Here is a quote from it:\n\n<blockquote>\n  This constitutes a new Bounded Context - the Identity and Access\n  Context - and will be used by other Bounded Contexts through standard\n  DDD integration techniques. To the consuming contexts the Identity and\n  Access Context is a Generic Subdomain. The product will be named\n  IdOvation.\n</blockquote>\n\nSo according to Vernon probably the best solution to move the access control to a generic subdomain.\n",
    "text_a": "I read about DDD and Access Control, and I found some contradiction between the following two opinions:   \"security concerns should be handled outside the domain\" \"access control requirements are domain specific\"   I am looking for a best practice about this. So where should I put the access control logic by domain driven design, and how should I implement it?  (To be more specific by DDD + CQRS + ES.)  I think it should be somewhere near to the business logic, for example a user story could be something like this:     The user can edit his profile by sending an user name, a list of hobbies, cv, etc...   Based on the user story we implement the domain model and the services, for example:  [CODE1]  This is okay, but where is the HIS profile part of the story?  This is obviously attribute based access control, because we should write a rule something like this:  [CODE2]  But where should we enforce this rule, and how should we implement it? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 17,
    "question": "The jar (bcprov-jdk16-145.jar) has been added to the project, <code>Security.addProvider(new org.bouncycastle.jce.provider.BouncyCastleProvider())</code> has been added to the class, and <code>BouncyCastleProvider.PROVIDER_NAME</code> does return \"BC\" but AesFileIo.writeFile() still throws <code>java.security.NoSuchProviderException No such provider: BC</code>. Any ideas?\n\n<pre><code>import java.io.FileOutputStream;\nimport java.io.InputStreamReader;\nimport java.io.ObjectOutputStream;\nimport javax.crypto.Cipher;\nimport javax.crypto.spec.IvParameterSpec;\nimport javax.crypto.spec.SecretKeySpec;\nimport org.bouncycastle.jce.provider.BouncyCastleProvider;\n\npublic class AesFileIo {\n\n    private static final String AES_ALGORITHM = \"AES/CTR/NoPadding\";\n    private static final String PROVIDER = BouncyCastleProvider.PROVIDER_NAME;\n    private static final byte[] AES_KEY_128 = { // Hard coded for now\n        78, -90, 42, 70, -5, 20, -114, 103,\n        -99, -25, 76, 95, -85, 94, 57, 54};\n    private static final byte[] IV = { // Hard coded for now\n        -85, -67, -5, 88, 28, 49, 49, 85,\n        114, 83, -40, 119, -65, 91, 76, 108};\n    private static final SecretKeySpec secretKeySpec =\n            new SecretKeySpec(AES_KEY_128, \"AES\");\n    private static final IvParameterSpec ivSpec = new IvParameterSpec(IV);\n\n    public void AesFileIo() {\n        Security.addProvider(new org.bouncycastle.jce.provider\n                .BouncyCastleProvider());\n    }\n\n    public void writeFile(String fileName, String theFile) {\n        try {\n            Cipher cipher = Cipher.getInstance(AES_ALGORITHM, PROVIDER);\n            cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec, ivSpec);\n            byte[] encrypted = cipher.doFinal(theFile.getBytes());\n            ObjectOutputStream os = new ObjectOutputStream(\n                new FileOutputStream(fileName));\n            os.write(encrypted);\n            os.flush();\n            os.close();\n        } catch (Exception e) {\n            StackTraceElement se = new Exception().getStackTrace()[0];\n            System.err.println(se.getFileName() + \" \" + se.getLineNumber()\n                    + \" \" + e);\n        }\n    }\n}\n</code></pre>\n",
    "accepted_answer": "Im not very familiar with the Android sdk, but it seems that the <code>android-sdk</code> comes with the <code>BouncyCastle</code> provider already added to the security.\n\nWhat you will have to do in the PC environment is just add it manually,\n\n<pre><code>Security.addProvider(new org.bouncycastle.jce.provider.BouncyCastleProvider());\n</code></pre>\n\nif you have access to the <code>policy</code> file, just add an entry like:\n\n<pre><code>security.provider.5=org.bouncycastle.jce.provider.BouncyCastleProvider \n</code></pre>\n\nNotice the <code>.5</code> it is equal to a sequential number of the already added providers.\n",
    "text_a": "The jar (bcprov-jdk16-145.jar) has been added to the project, Security.addProvider(new org.bouncycastle.jce.provider.BouncyCastleProvider()) has been added to the class, and BouncyCastleProvider.PROVIDER_NAME does return \"BC\" but AesFileIo.writeFile() still throws [CODE1]. Any ideas?  [CODE2] ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 18,
    "question": "Cross Site Request Forgery (CSRF) is typically prevent with one of the following methods:\n\n<ul>\n<li>Check referer - RESTful but unreliable</li>\n<li>insert token into form and store the token in the server session - not really RESTful</li>\n<li>cryptic one time URIs - not RESTful for the same reason as tokens</li>\n<li>send password manually for this request (not the cached password used with HTTP auth) - RESTful but not convenient</li>\n</ul>\n\nMy idea is to use a user secret, a cryptic but static form id and JavaScript to generate tokens. \n\n<pre><code>&lt;form method=\"POST\" action=\"/someresource\" id=\"7099879082361234103\"&gt;\n    &lt;input type=\"hidden\" name=\"token\" value=\"generateToken(...)\"&gt;\n    ...\n&lt;/form&gt;\n</code></pre>\n\n<ol>\n<li><code>GET /usersecret/john_doe</code> fetched by the JavaScript from the authenticated user.</li>\n<li>Response: <code>OK 89070135420357234586534346</code> This secret is conceptionally static, but can be changed every day/hour ... to improve security. This is the only confidential thing.</li>\n<li>Read the cryptic (but static for all users!) form id with JavaScript, process it together with the user secret: <code>generateToken(7099879082361234103, 89070135420357234586534346)</code></li>\n<li>Send the form along with the generated token to the server.</li>\n<li>Since the server knows the user secret and the form id, it is possible to run the same generateToken function as the client did before sending and compare both results. Only when both values are equal the action will be authorized.</li>\n</ol>\n\nIs something wrong with this approach, despite the fact that it doesn't work without JavaScript?\n\n<strong>Addendum:</strong>\n\n<ul>\n<li><a href=\"http://appsandsecurity.blogspot.de/2012/01/stateless-csrf-protection.html\" rel=\"noreferrer\">Stateless CSRF Protection</a></li>\n</ul>\n",
    "accepted_answer": "There are a lot of answers here, and problems with quite a few of them.\nThings you should NOT do:\n<ol>\n<li>If you need to read the session token from JavaScript, you're doing something horribly wrong.  Your session identifier cookie should ALWAYS have HTTPOnly set on it so its not available to scripts.\nThis one protection makes it so that the impact of XSS is considerably reduced, since an attacker will no longer be able to get a logged in users session token, which for all intents and purposes are the equivalent of credentials in the application. You don't want one error to give keys to the kingdom.\n</li>\n<li>The session identifier should not be written to the contents of the page. This is for the same reasons you set HTTPOnly. This means that that your csrf token can not be your session id. They need to be different values.\n</li>\n</ol>\nThings you should do:\n<ol>\n<li>Follow <a href=\"https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html\" rel=\"noreferrer\">OWASP's guidance</a>:\n</li>\n<li>Specifically, if this is a REST application you can <a href=\"https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)_Prevention_Cheat_Sheet#Double_Submit_Cookie\" rel=\"noreferrer\">require double-submission of CSRF tokens</a>. If you do this, just be sure that you define it to a specific full-domain (<a href=\"http://www.mydomain.com\" rel=\"noreferrer\">www.mydomain.com</a>) and not a parent domain (example.com), and that you also utilize the &quot;samesite&quot; cookie attribute which is gaining popularity.\n</li>\n</ol>\nSimply create something cryptographically random, store it in ASCII Hex or Base64 encode, and add it as a cookie and to your forms when the server returns the page. On the server side make sure that the cookie value matches the form value. Voila, you've killed CSRF, avoided extra prompts for your users, and not opened yourself up to more vulnerabilities.\nNOTE: As @krubo states below the double-submission technique <a href=\"https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.md\" rel=\"noreferrer\">has been found to have some weaknesses (See Double-Submission)</a>. Since this weakness requires that:\n<ol>\n<li>You define a cookie scoped to the parent domain.</li>\n<li><a href=\"https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.md\" rel=\"noreferrer\">You fail to set HSTS</a>.</li>\n<li>The attacker controls some network location inbetween the user and the server</li>\n</ol>\nI kind of think the weakness falls more in the category of a &quot;Cool Defcon Talk&quot; rather than a &quot;Realworld Security Risk&quot;. In any case, if you are going to use double-submission it doesn't hurt to take a few extra steps to protect yourself fully.\n<hr />\n<h2>New Update 07/06/2020</h2>\nMy new favorite way to do double-submission is to create and pass a cryptographic random string in the body of the request as before; but rather than have the cookie be the same exact value have the cookie be the encoded value of the string being signed by a certificate. This is still just as easy to validate on the server side, but is MUCH harder for an attacker to mimic. You should still use the samesite Cookie attribute and other protections outlined earlier in my post.\n",
    "text_a": "Cross Site Request Forgery (CSRF) is typically prevent with one of the following methods:   Check referer - RESTful but unreliable insert token into form and store the token in the server session - not really RESTful cryptic one time URIs - not RESTful for the same reason as tokens send password manually for this request (not the cached password used with HTTP auth) - RESTful but not convenient   My idea is to use a user secret, a cryptic but static form id and JavaScript to generate tokens.   [CODE1]   GET /usersecret/john_doe fetched by the JavaScript from the authenticated user. Response: OK 89070135420357234586534346 This secret is conceptionally static, but can be changed every day/hour ... to improve security. This is the only confidential thing. Read the cryptic (but static for all users!) form id with JavaScript, process it together with the user secret: generateToken(7099879082361234103, 89070135420357234586534346) Send the form along with the generated token to the server. Since the server knows the user secret and the form id, it is possible to run the same generateToken function as the client did before sending and compare both results. Only when both values are equal the action will be authorized.   Is something wrong with this approach, despite the fact that it doesn't work without JavaScript?  Addendum:   Stateless CSRF Protection  ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 19,
    "question": "We have a high security application and we want to allow users to enter URLs that other users will see.\n\nThis introduces a high risk of XSS hacks - a user could potentially enter javascript that another user ends up executing. Since we hold sensitive data it's essential that this never happens.\n\nWhat are the best practices in dealing with this? Is any security whitelist or escape pattern alone good enough? \n\nAny advice on dealing with redirections (\"this link goes outside our site\" message on a warning page before following the link, for instance)\n\nIs there an argument for not supporting user entered links at all?\n\n<hr>\n\nClarification:\n\nBasically our users want to input: \n\n<blockquote>\n  stackoverflow.com\n</blockquote>\n\nAnd have it output to another user:\n\n<pre><code>&lt;a href=\"http://stackoverflow.com\"&gt;stackoverflow.com&lt;/a&gt;\n</code></pre>\n\nWhat I really worry about is them using this in a XSS hack. I.e. they input:\n\n<blockquote>\n  alert('hacked!');\n</blockquote>\n\nSo other users get this link:\n\n<pre><code>&lt;a href=\"javascript:alert('hacked!');\"&gt;stackoverflow.com&lt;/a&gt;\n</code></pre>\n\nMy example is just to explain the risk - I'm well aware that javascript and URLs are different things, but by letting them input the latter they may be able to execute the former.\n\nYou'd be amazed how many sites you can break with this trick - HTML is even worse. If they know to deal with links do they also know to sanitise <code>&lt;iframe&gt;</code>, <code>&lt;img&gt;</code> and clever CSS references?\n\nI'm working in a high security environment - a single XSS hack could result in very high losses for us. I'm happy that I could produce a Regex (or use one of the excellent suggestions so far) that could exclude everything that I could think of, but would that be enough?\n",
    "accepted_answer": "If you think URLs can't contain code, think again!\n<a href=\"https://owasp.org/www-community/xss-filter-evasion-cheatsheet\" rel=\"noreferrer\">https://owasp.org/www-community/xss-filter-evasion-cheatsheet</a>\nRead that, and weep.\nHere's how we do it on Stack Overflow:\n<pre><code>/// &lt;summary&gt;\n/// returns &quot;safe&quot; URL, stripping anything outside normal charsets for URL\n/// &lt;/summary&gt;\npublic static string SanitizeUrl(string url)\n{\n    return Regex.Replace(url, @&quot;[^-A-Za-z0-9+&amp;@#/%?=~_|!:,.;\\(\\)]&quot;, &quot;&quot;);\n}\n</code></pre>\n",
    "text_a": "We have a high security application and we want to allow users to enter URLs that other users will see.  This introduces a high risk of XSS hacks - a user could potentially enter javascript that another user ends up executing. Since we hold sensitive data it's essential that this never happens.  What are the best practices in dealing with this? Is any security whitelist or escape pattern alone good enough?   Any advice on dealing with redirections (\"this link goes outside our site\" message on a warning page before following the link, for instance)  Is there an argument for not supporting user entered links at all?    Clarification:  Basically our users want to input:      stackoverflow.com   And have it output to another user:  [CODE1]  What I really worry about is them using this in a XSS hack. I.e. they input:     alert('hacked!');   So other users get this link:  [CODE2]  My example is just to explain the risk - I'm well aware that javascript and URLs are different things, but by letting them input the latter they may be able to execute the former.  You'd be amazed how many sites you can break with this trick - HTML is even worse. If they know to deal with links do they also know to sanitise &lt;iframe&gt;, &lt;img&gt; and clever CSS references?  I'm working in a high security environment - a single XSS hack could result in very high losses for us. I'm happy that I could produce a Regex (or use one of the excellent suggestions so far) that could exclude everything that I could think of, but would that be enough? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 20,
    "question": "I'm trying to implement JWT in my authentication system and I have a few questions. To store the token, I could use cookies but it's also possible to use <code>localStorage</code> or <code>sessionStorage</code>.\n\nWhich would be the best choice? \n\nI have read that JWT protects the site from CSRF. However, I can't imagine how that would work assuming I save the JWT token in cookie storage.\n\nHow would it then protect from CSRF?\n\n<strong>Update 1</strong><br>\nI saw some usage samples like the following:\n\n<pre><code>curl -v -X POST -H \"Authorization: Basic VE01enNFem9FZG9NRERjVEJjbXRBcWJGdTBFYTpYUU9URExINlBBOHJvUHJfSktrTHhUSTNseGNh\"\n</code></pre>\n\nHow can I implement that when I make a request to server from the browser? I also saw that some implement the token in the URL:\n\n<pre><code>http://exmple.com?jwt=token\n</code></pre>\n\nIf I would make a request via AJAX then I could set an header like <code>jwt: [token]</code> and then I could read the token from header. \n\n<strong>Update 2</strong>  \n\nI installed the Advanced REST Client Google Chrome extension and was able to pass the token as a custom header. Is it possible to set this header data via Javascript when making a GET request to the server? \n",
    "accepted_answer": "<strong>[EDIT] This answer is the accepted one, however the response from Jo\u832bo Angelo is way more detailed and should be considered. One remark though and because the security pratices evolved since Nov. 2016, the Option 2 should be implemented in favour of the Option 1.</strong>\n\nLook at this web site: <a href=\"https://auth0.com/blog/2014/01/07/angularjs-authentication-with-cookies-vs-token/\" rel=\"noreferrer\">https://auth0.com/blog/2014/01/07/angularjs-authentication-with-cookies-vs-token/</a>\n\nIf you want to store them, you should use the localStorage or sessionStorage if available or cookies.\nYou should also use the Authorization header, but instead of Basic scheme, use the Bearer one:\n\n<pre><code>curl -v -X POST -H \"Authorization: Bearer YOUR_JWT_HERE\"\n</code></pre>\n\nWith JS, you could use the following code:\n\n<pre><code>&lt;script type='text/javascript'&gt;\n// define vars\nvar url = 'https://...';\n\n// ajax call\n$.ajax({\n    url: url,\n    dataType : 'jsonp',\n    beforeSend : function(xhr) {\n      // set header if JWT is set\n      if ($window.sessionStorage.token) {\n          xhr.setRequestHeader(\"Authorization\", \"Bearer \" +  $window.sessionStorage.token);\n      }\n\n    },\n    error : function() {\n      // error handler\n    },\n    success: function(data) {\n        // success handler\n    }\n});\n&lt;/script&gt;\n</code></pre>\n",
    "text_a": "I'm trying to implement JWT in my authentication system and I have a few questions. To store the token, I could use cookies but it's also possible to use localStorage or sessionStorage.  Which would be the best choice?   I have read that JWT protects the site from CSRF. However, I can't imagine how that would work assuming I save the JWT token in cookie storage.  How would it then protect from CSRF?  Update 1 I saw some usage samples like the following:  [CODE1]  How can I implement that when I make a request to server from the browser? I also saw that some implement the token in the URL:  http://exmple.com?jwt=token   If I would make a request via AJAX then I could set an header like jwt: [token] and then I could read the token from header.   Update 2    I installed the Advanced REST Client Google Chrome extension and was able to pass the token as a custom header. Is it possible to set this header data via Javascript when making a GET request to the server?  ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 21,
    "question": "My Rails app uses Devise for authentication. It has a sister iOS app, and users can log in to the iOS app using the same credentials that they use for the web app. So I need some kind of API for authentication.\n\nLots of similar questions on here point to <a href=\"http://jessewolgamott.com/blog/2012/01/19/the-one-with-a-json-api-login-using-devise/\" rel=\"noreferrer\">this tutorial</a>, but it seems to be out-of-date, as the <code>token_authenticatable</code> module has since been removed from Devise and some of the lines throw errors. (I'm using Devise 3.2.2.) I've attempted to roll my own based on that tutorial (and <a href=\"http://danrodriguez.me/post/54352441822/\" rel=\"noreferrer\">this one</a>), but I'm not 100% confident in it - I feel like there may be something I've misunderstood or missed.\n\nFirstly, following the advice of <a href=\"https://gist.github.com/josevalim/fb706b1e933ef01e4fb6\" rel=\"noreferrer\">this gist</a>, I added an <code>authentication_token</code> text attribute to my <code>users</code> table, and the following to <code>user.rb</code>:\n\n<pre><code>before_save :ensure_authentication_token\n\ndef ensure_authentication_token\n  if authentication_token.blank?\n    self.authentication_token = generate_authentication_token\n  end\nend\n\nprivate\n\n  def generate_authentication_token\n    loop do\n      token = Devise.friendly_token\n      break token unless User.find_by(authentication_token: token)\n    end\n  end\n</code></pre>\n\nThen I have the following controllers:\n\n<strong>api_controller.rb</strong>\n\n<pre><code>class ApiController &lt; ApplicationController\n  respond_to :json\n  skip_before_filter :authenticate_user!\n\n  protected\n\n  def user_params\n    params[:user].permit(:email, :password, :password_confirmation)\n  end\nend\n</code></pre>\n\n(Note that my <code>application_controller</code> has the line <code>before_filter :authenticate_user!</code>.)\n\n<strong>api/sessions_controller.rb</strong>\n\n<pre><code>class Api::SessionsController &lt; Devise::RegistrationsController\n  prepend_before_filter :require_no_authentication, :only =&gt; [:create ]\n\n  before_filter :ensure_params_exist\n\n  respond_to :json\n\n  skip_before_filter :verify_authenticity_token\n\n  def create\n    build_resource\n    resource = User.find_for_database_authentication(\n      email: params[:user][:email]\n    )\n    return invalid_login_attempt unless resource\n\n    if resource.valid_password?(params[:user][:password])\n      sign_in(\"user\", resource)\n      render json: {\n        success: true,\n        auth_token: resource.authentication_token,\n        email: resource.email\n      }\n      return\n    end\n    invalid_login_attempt\n  end\n\n  def destroy\n    sign_out(resource_name)\n  end\n\n  protected\n\n    def ensure_params_exist\n      return unless params[:user].blank?\n      render json: {\n        success: false,\n        message: \"missing user parameter\"\n      }, status: 422\n    end\n\n    def invalid_login_attempt\n      warden.custom_failure!\n      render json: {\n        success: false,\n        message: \"Error with your login or password\"\n      }, status: 401\n    end\nend\n</code></pre>\n\n<strong>api/registrations_controller.rb</strong>\n\n<pre><code>class Api::RegistrationsController &lt; ApiController\n  skip_before_filter :verify_authenticity_token\n\n  def create\n    user = User.new(user_params)\n    if user.save\n      render(\n        json: Jbuilder.encode do |j|\n          j.success true\n          j.email user.email\n          j.auth_token user.authentication_token\n        end,\n        status: 201\n      )\n      return\n    else\n      warden.custom_failure!\n      render json: user.errors, status: 422\n    end\n  end\nend\n</code></pre>\n\nAnd in <strong>config/routes.rb</strong>:\n\n<pre><code>  namespace :api, defaults: { format: \"json\" } do\n    devise_for :users\n  end\n</code></pre>\n\nI'm out of my depth a bit and I'm sure there's something here that my future self will look back on and cringe (there usually is). Some iffy parts:\n\n<strong>Firstly</strong>, you'll notice that <code>Api::SessionsController</code> inherits from <code>Devise::RegistrationsController</code> whereas <code>Api::RegistrationsController</code> inherits from <code>ApiController</code> (I also have some other controllers such as <code>Api::EventsController &lt; ApiController</code> which deal with more standard REST stuff for my other models and don't have much contact with Devise.) This is a pretty ugly arrangement, but I couldn't figure out another way of getting access the methods I need in <code>Api::RegistrationsController</code>. The tutorial I linked to above has the line <code>include Devise::Controllers::InternalHelpers</code>, but this module seems to have been removed in more recent versions of Devise.\n\n<strong>Secondly</strong>, I've disabled CSRF protection with the line <code>skip_before_filter :verify_authentication_token</code>. I have my doubts about whether this is a good idea - I see a lot of <a href=\"https://stackoverflow.com/questions/7600347/rails-api-design-without-disabling-csrf-protection\">conflicting</a> or <a href=\"https://stackoverflow.com/questions/11008469/are-json-web-services-vulnerable-to-csrf-attacks\">hard to understand</a> advice about whether JSON APIs are vulnerable to CSRF attacks - but adding that line was the only way I could get the damn thing to work.\n\n<strong>Thirdly</strong>, I want to make sure I understand how authentication works once a user has signed in. Say I have an API call <code>GET /api/friends</code> which returns a list of the current user's friends. As I understand it, the iOS app would have to get the user's <code>authentication_token</code> from the database (which is a fixed value for each user that never changes??), then submit it as a param along with every request, e.g. <code>GET /api/friends?authentication_token=abcdefgh1234</code>, then my <code>Api::FriendsController</code> could do something like <code>User.find_by(authentication_token: params[:authentication_token])</code> to get the current_user. Is it really this simple, or am I missing something?\n\nSo for anyone who's managed to read all the way to the end of this mammoth question, thanks for your time! To summarise:\n\n<ol>\n<li><strong>Is this login system secure?</strong> Or is there something I've overlooked or misunderstood, e.g. when it comes to CSRF attacks?</li>\n<li><strong>Is my understanding of how to authenticate requests once users are signed in correct?</strong> (See \"thirdly...\" above.)</li>\n<li><strong>Is there any way this code can be cleaned up or made nicer?</strong> Particularly the ugly design of having one controller inherit from <code>Devise::RegistrationsController</code> and the others from <code>ApiController</code>.</li>\n</ol>\n\nThanks!\n",
    "accepted_answer": "You don't want to disable CSRF, I have read that people think it doesn't apply to JSON APIs for some reason, but this is a misunderstanding. To keep it enabled, you want to make a few changes:\n\n<ul>\n<li>on there server side add a after_filter to your sessions controller:\n\n<pre><code>after_filter :set_csrf_header, only: [:new, :create]\n\nprotected\n\ndef set_csrf_header\n   response.headers['X-CSRF-Token'] = form_authenticity_token\nend\n</code></pre>\n\nThis will generate a token, put it in your session and copy it in the response header for selected actions. </li>\n<li>client side (iOS) you need to make sure two things are in place.\n\n<ul>\n<li>your client needs to scan all server responses for this header and retain it when it is passed along.\n\n<pre><code>... get ahold of response object\n// response may be a NSURLResponse object, so convert:\nNSHTTPURLResponse *httpResponse = (NSHTTPURLResponse*)response;\n// grab token if present, make sure you have a config object to store it in\nNSString *token = [[httpResponse allHeaderFields] objectForKey:@\"X-CSRF-Token\"];\nif (token)\n   [yourConfig setCsrfToken:token];\n</code></pre></li>\n<li>finally, your client needs to add this token to all 'non GET' requests it sends out:\n\n<pre><code>... get ahold of your request object\nif (yourConfig.csrfToken &amp;&amp; ![request.httpMethod isEqualToString:@\"GET\"])\n  [request setValue:yourConfig.csrfToken forHTTPHeaderField:@\"X-CSRF-Token\"];\n</code></pre></li>\n</ul></li>\n</ul>\n\nFinal piece of the puzzle is to understand that when logging in to devise, two subsequent sessions/csrf tokens are being used. A login flow would look like this:\n\n<pre><code>GET /users/sign_in -&gt;\n  // new action is called, initial token is set\n  // now send login form on callback:\n  POST /users/sign_in &lt;username, password&gt; -&gt;\n    // create action called, token is reset\n    // when login is successful, session and token are replaced \n    // and you can send authenticated requests\n</code></pre>\n",
    "text_a": "My Rails app uses Devise for authentication. It has a sister iOS app, and users can log in to the iOS app using the same credentials that they use for the web app. So I need some kind of API for authentication.  Lots of similar questions on here point to this tutorial, but it seems to be out-of-date, as the token_authenticatable module has since been removed from Devise and some of the lines throw errors. (I'm using Devise 3.2.2.) I've attempted to roll my own based on that tutorial (and this one), but I'm not 100% confident in it - I feel like there may be something I've misunderstood or missed.  Firstly, following the advice of this gist, I added an authentication_token text attribute to my users table, and the following to user.rb:  [CODE1]  Then I have the following controllers:  api_controller.rb  [CODE2]  (Note that my application_controller has the line before_filter :authenticate_user!.)  api/sessions_controller.rb  [CODE3]  api/registrations_controller.rb  [CODE4]  And in config/routes.rb:  [CODE5]  I'm out of my depth a bit and I'm sure there's something here that my future self will look back on and cringe (there usually is). Some iffy parts:  Firstly, you'll notice that Api::SessionsController inherits from Devise::RegistrationsController whereas Api::RegistrationsController inherits from ApiController (I also have some other controllers such as Api::EventsController &lt; ApiController which deal with more standard REST stuff for my other models and don't have much contact with Devise.) This is a pretty ugly arrangement, but I couldn't figure out another way of getting access the methods I need in Api::RegistrationsController. The tutorial I linked to above has the line include Devise::Controllers::InternalHelpers, but this module seems to have been removed in more recent versions of Devise.  Secondly, I've disabled CSRF protection with the line skip_before_filter :verify_authentication_token. I have my doubts about whether this is a good idea - I see a lot of conflicting or hard to understand advice about whether JSON APIs are vulnerable to CSRF attacks - but adding that line was the only way I could get the damn thing to work.  Thirdly, I want to make sure I understand how authentication works once a user has signed in. Say I have an API call GET /api/friends which returns a list of the current user's friends. As I understand it, the iOS app would have to get the user's authentication_token from the database (which is a fixed value for each user that never changes??), then submit it as a param along with every request, e.g. GET /api/friends?authentication_token=abcdefgh1234, then my Api::FriendsController could do something like User.find_by(authentication_token: params[:authentication_token]) to get the current_user. Is it really this simple, or am I missing something?  So for anyone who's managed to read all the way to the end of this mammoth question, thanks for your time! To summarise:   Is this login system secure? Or is there something I've overlooked or misunderstood, e.g. when it comes to CSRF attacks? Is my understanding of how to authenticate requests once users are signed in correct? (See \"thirdly...\" above.) Is there any way this code can be cleaned up or made nicer? Particularly the ugly design of having one controller inherit from Devise::RegistrationsController and the others from ApiController.   Thanks! ",
    "tgt_text": "Build an session controller",
    "label": "C5",
    "code": "",
    "insecure_code": "class Api::SessionsController < Devise::RegistrationsController\n  prepend_before_filter :require_no_authentication, :only => [:create ]\n\n  before_filter :ensure_params_exist\n\n  respond_to :json\n\n  skip_before_filter :verify_authenticity_token\n\n  def create\n    build_resource\n    resource = User.find_for_database_authentication(\n      email: params[:user][:email]\n    )\n    return invalid_login_attempt unless resource\n\n    if resource.valid_password?(params[:user][:password])\n      sign_in(\"user\", resource)\n      render json: {\n        success: true,\n        auth_token: resource.authentication_token,\n        email: resource.email\n      }\n      return\n    end\n    invalid_login_attempt\n  end\n\n  def destroy\n    sign_out(resource_name)\n  end\n\n  protected\n\n    def ensure_params_exist\n      return unless params[:user].blank?\n      render json: {\n        success: false,\n        message: \"missing user parameter\"\n      }, status: 422\n    end\n\n    def invalid_login_attempt\n      warden.custom_failure!\n      render json: {\n        success: false,\n        message: \"Error with your login or password\"\n      }, status: 401\n    end\nend"
  },
  {
    "guid": 22,
    "question": "I am trying to use a client certificate to authenticate and authorize devices using a Web API and developed a simple proof of concept to work through issues with the potential solution.  I am running into an issue where the client certificate is not being received by the web application.  A number of people of reported this issue, <a href=\"https://stackoverflow.com/questions/22197762/webapi-httpclient-not-sending-client-certificate\">including in this Q&amp;A</a>, but none of them have an answer.  My hope is to provide more detail to revive this issue and hopefully get an answer for my issue.  I am open to other solutions.  The main requirement is that a standalone process written in C# can call a Web API and be authenticated using a client certificate. \n\nThe Web API in this POC is very simple and just returns a single value.  It uses an attribute to validate that HTTPS is used and that a client certificate is present.  \n\n<pre><code>public class SecureController : ApiController\n{\n    [RequireHttps]\n    public string Get(int id)\n    {\n        return \"value\";\n    }\n\n}\n</code></pre>\n\nHere is the code for the RequireHttpsAttribute:\n\n<pre><code>public class RequireHttpsAttribute : AuthorizationFilterAttribute \n{ \n    public override void OnAuthorization(HttpActionContext actionContext) \n    { \n        if (actionContext.Request.RequestUri.Scheme != Uri.UriSchemeHttps) \n        { \n            actionContext.Response = new HttpResponseMessage(System.Net.HttpStatusCode.Forbidden) \n            { \n                ReasonPhrase = \"HTTPS Required\" \n            }; \n        } \n        else \n        {\n            var cert = actionContext.Request.GetClientCertificate();\n            if (cert == null)\n            {\n                actionContext.Response = new HttpResponseMessage(System.Net.HttpStatusCode.Forbidden)\n                {\n                    ReasonPhrase = \"Client Certificate Required\"\n                }; \n\n            }\n            base.OnAuthorization(actionContext); \n        } \n    } \n}\n</code></pre>\n\nIn this POC I am just checking for the availability of the client certificate.  Once this is working I can add checks for information in the certificate to validate against a list of certificates.\n\nHere are the setting in IIS for SSL for this web application.\n\n<a href=\"https://i.stack.imgur.com/Wr1ZK.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/Wr1ZK.png\" alt=\"enter image description here\"></a>\n\nHere is the code for the client that sends the request with a client certificate.  This is a console application.\n\n<pre><code>    private static async Task SendRequestUsingHttpClient()\n    {\n        WebRequestHandler handler = new WebRequestHandler();\n        X509Certificate certificate = GetCert(\"ClientCertificate.cer\");\n        handler.ClientCertificates.Add(certificate);\n        handler.ServerCertificateValidationCallback = new RemoteCertificateValidationCallback(ValidateServerCertificate);\n        handler.ClientCertificateOptions = ClientCertificateOption.Manual;\n        using (var client = new HttpClient(handler))\n        {\n            client.BaseAddress = new Uri(\"https://localhost:44398/\");\n            client.DefaultRequestHeaders.Accept.Clear();\n            client.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue(\"application/json\"));\n\n            HttpResponseMessage response = await client.GetAsync(\"api/Secure/1\");\n            if (response.IsSuccessStatusCode)\n            {\n                string content = await response.Content.ReadAsStringAsync();\n                Console.WriteLine(\"Received response: {0}\",content);\n            }\n            else\n            {\n                Console.WriteLine(\"Error, received status code {0}: {1}\", response.StatusCode, response.ReasonPhrase);\n            }\n        }\n    }\n\n    public static bool ValidateServerCertificate(\n      object sender,\n      X509Certificate certificate,\n      X509Chain chain,\n      SslPolicyErrors sslPolicyErrors)\n    {\n        Console.WriteLine(\"Validating certificate {0}\", certificate.Issuer);\n        if (sslPolicyErrors == SslPolicyErrors.None)\n            return true;\n\n        Console.WriteLine(\"Certificate error: {0}\", sslPolicyErrors);\n\n        // Do not allow this client to communicate with unauthenticated servers.\n        return false;\n    }\n</code></pre>\n\nWhen I run this test app I get back a status code of 403 Forbidden with a reason phrase of \u9225\u6dd0lient Certificate Required\u9225?indicating that it is getting into my RequireHttpsAttribute and it is not finding any client certificates.  Running this through a debugger I have verified that the certificate is getting loaded and added to the WebRequestHandler.  The certificate is exported into a CER file that is being loaded.  The full certificate with the private key is located on the Local Machine\u9225\u6a9a Personal and Trusted Root stores for the web application server.  For this test the client and web application are being run on the same machine.\n\nI can call this Web API method using Fiddler, attaching the same client certificate, and it works fine.  When using Fiddler it passes the tests in RequireHttpsAttribute and returns a successful status code of 200 and returns the expected value.\n\nHas anybody run into the same issue where HttpClient does not send a client certificate in the request and found a solution?\n\n<strong>Update 1:</strong>\n\nI also tried getting the certificate from the certificate store that includes the private key.  Here is how I retrieved it:\n\n<pre><code>    private static X509Certificate2 GetCert2(string hostname)\n    {\n        X509Store myX509Store = new X509Store(StoreName.My, StoreLocation.LocalMachine);\n        myX509Store.Open(OpenFlags.ReadWrite);\n        X509Certificate2 myCertificate = myX509Store.Certificates.OfType&lt;X509Certificate2&gt;().FirstOrDefault(cert =&gt; cert.GetNameInfo(X509NameType.SimpleName, false) == hostname);\n        return myCertificate;\n    }\n</code></pre>\n\nI verified that this certificate was getting retrieved correctly and it was being added to the client certificate collection.  But I got the same results where the server code does not retrieve any client certificates.\n\nFor completeness here is the code used to retrieve the certificate from a file:\n\n<pre><code>    private static X509Certificate GetCert(string filename)\n    {\n        X509Certificate Cert = X509Certificate.CreateFromCertFile(filename);\n        return Cert;\n\n    }\n</code></pre>\n\nYou will notice that when you get the certificate from a file it returns an object of type X509Certificate and when you retrieve it from the certificate store it is of type X509Certificate2.  The X509CertificateCollection.Add Method is expecting a type of X509Certificate.\n\n<strong>Update 2:</strong>\nI am still trying to figure this out and have tried many different options but to no avail.  \n\n<ul>\n<li>I changed the web application to run on a host name instead of local host.</li>\n<li>I set the web application to require SSL</li>\n<li>I verified that the certificate was set for Client Authentication and that it is in the trusted root</li>\n<li>Besides testing the client certificate in Fiddler I also validated it in Chrome.</li>\n</ul>\n\nAt one point during trying these options it started working.  Then I started backing out changes to see what caused it to work. It continued to work.  Then I tried removing the certificate from the trusted root to validate that this was required and it stopped working and now I cannot get it back to working even though I put the certificate back in the trusted root.  Now Chrome will not even prompt me for a certificate like it used too and it fails in Chrome, but still works in Fiddler.  There must be some magic configuration I am missing.\n\nI also tried enabling \"Negotiate Client Certificate\" in the binding but Chrome still will not prompt me for a client certificate.  Here is the settings using \"netsh http show sslcert\"\n\n<pre><code> IP:port                 : 0.0.0.0:44398\n Certificate Hash        : 429e090db21e14344aa5d75d25074712f120f65f\n Application ID          : {4dc3e181-e14b-4a21-b022-59fc669b0914}\n Certificate Store Name  : MY\n Verify Client Certificate Revocation    : Disabled\n Verify Revocation Using Cached Client Certificate Only    : Disabled\n Usage Check    : Enabled\n Revocation Freshness Time : 0\n URL Retrieval Timeout   : 0\n Ctl Identifier          : (null)\n Ctl Store Name          : (null)\n DS Mapper Usage    : Disabled\n Negotiate Client Certificate    : Enabled\n</code></pre>\n\nHere is the client certificate I am using:\n\n<a href=\"https://i.stack.imgur.com/ejN8h.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/ejN8h.png\" alt=\"enter image description here\"></a>\n\n<a href=\"https://i.stack.imgur.com/byZZR.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/byZZR.png\" alt=\"enter image description here\"></a>\n\n<a href=\"https://i.stack.imgur.com/lMMaF.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/lMMaF.png\" alt=\"enter image description here\"></a>\n\nI am baffled as to what the issue is.  I am adding a bounty for anyone that can help me figure this out.\n",
    "accepted_answer": "Tracing helped me find what the problem was (Thank you Fabian for that suggestion).  I found with further testing that I could get the client certificate to work on another server (Windows Server 2012).  I was testing this on my development machine (Window 7) so I could debug this process.  So by comparing the trace to an IIS Server that worked and one that did not I was able to pinpoint the relevant lines in the trace log.  Here is a portion of a log where the client certificate worked. This is the setup right before the send\n\n<pre><code>System.Net Information: 0 : [17444] InitializeSecurityContext(In-Buffers count=2, Out-Buffer length=0, returned code=CredentialsNeeded).\nSystem.Net Information: 0 : [17444] SecureChannel#54718731 - We have user-provided certificates. The server has not specified any issuers, so try all the certificates.\nSystem.Net Information: 0 : [17444] SecureChannel#54718731 - Selected certificate:\n</code></pre>\n\nHere is what the trace log looked like on the machine where the client certificate failed.\n\n<pre><code>System.Net Information: 0 : [19616] InitializeSecurityContext(In-Buffers count=2, Out-Buffer length=0, returned code=CredentialsNeeded).\nSystem.Net Information: 0 : [19616] SecureChannel#54718731 - We have user-provided certificates. The server has specified 137 issuer(s). Looking for certificates that match any of the issuers.\nSystem.Net Information: 0 : [19616] SecureChannel#54718731 - Left with 0 client certificates to choose from.\nSystem.Net Information: 0 : [19616] Using the cached credential handle.\n</code></pre>\n\nFocusing on the line that indicated the server specified 137 issuers I found this <a href=\"https://stackoverflow.com/questions/9858275/net-application-fails-to-send-client-certificate-win-7-vs-win-xp\">Q&amp;A that seemed similar to my issue</a>.  The solution for me was not the one marked as an answer since my certificate was in the trusted root.  The answer is <a href=\"https://stackoverflow.com/a/19502296/722393\">the one under it</a> where you update the registry.  I just added the value to the registry key.\n\n<strong>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\SCHANNEL</strong>\n\n<strong>Value name: SendTrustedIssuerList Value type: REG_DWORD Value data: 0 (False)</strong>\n\nAfter adding this value to the registry it started to work on my Windows 7 machine.  This appears to be a Windows 7 issue.\n",
    "text_a": "I am trying to use a client certificate to authenticate and authorize devices using a Web API and developed a simple proof of concept to work through issues with the potential solution.  I am running into an issue where the client certificate is not being received by the web application.  A number of people of reported this issue, including in this Q&amp;A, but none of them have an answer.  My hope is to provide more detail to revive this issue and hopefully get an answer for my issue.  I am open to other solutions.  The main requirement is that a standalone process written in C# can call a Web API and be authenticated using a client certificate.   The Web API in this POC is very simple and just returns a single value.  It uses an attribute to validate that HTTPS is used and that a client certificate is present.    [CODE1]  Here is the code for the RequireHttpsAttribute:  [CODE2]  In this POC I am just checking for the availability of the client certificate.  Once this is working I can add checks for information in the certificate to validate against a list of certificates.  Here are the setting in IIS for SSL for this web application.    Here is the code for the client that sends the request with a client certificate.  This is a console application.  [CODE3]  When I run this test app I get back a status code of 403 Forbidden with a reason phrase of \u9225\u6dd0lient Certificate Required\u9225?indicating that it is getting into my RequireHttpsAttribute and it is not finding any client certificates.  Running this through a debugger I have verified that the certificate is getting loaded and added to the WebRequestHandler.  The certificate is exported into a CER file that is being loaded.  The full certificate with the private key is located on the Local Machine\u9225\u6a9a Personal and Trusted Root stores for the web application server.  For this test the client and web application are being run on the same machine.  I can call this Web API method using Fiddler, attaching the same client certificate, and it works fine.  When using Fiddler it passes the tests in RequireHttpsAttribute and returns a successful status code of 200 and returns the expected value.  Has anybody run into the same issue where HttpClient does not send a client certificate in the request and found a solution?  Update 1:  I also tried getting the certificate from the certificate store that includes the private key.  Here is how I retrieved it:  [CODE4]  I verified that this certificate was getting retrieved correctly and it was being added to the client certificate collection.  But I got the same results where the server code does not retrieve any client certificates.  For completeness here is the code used to retrieve the certificate from a file:  [CODE5]  You will notice that when you get the certificate from a file it returns an object of type X509Certificate and when you retrieve it from the certificate store it is of type X509Certificate2.  The X509CertificateCollection.Add Method is expecting a type of X509Certificate.  Update 2: I am still trying to figure this out and have tried many different options but to no avail.     I changed the web application to run on a host name instead of local host. I set the web application to require SSL I verified that the certificate was set for Client Authentication and that it is in the trusted root Besides testing the client certificate in Fiddler I also validated it in Chrome.   At one point during trying these options it started working.  Then I started backing out changes to see what caused it to work. It continued to work.  Then I tried removing the certificate from the trusted root to validate that this was required and it stopped working and now I cannot get it back to working even though I put the certificate back in the trusted root.  Now Chrome will not even prompt me for a certificate like it used too and it fails in Chrome, but still works in Fiddler.  There must be some magic configuration I am missing.  I also tried enabling \"Negotiate Client Certificate\" in the binding but Chrome still will not prompt me for a client certificate.  Here is the settings using \"netsh http show sslcert\"  [CODE6]  Here is the client certificate I am using:        I am baffled as to what the issue is.  I am adding a bounty for anyone that can help me figure this out. ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 23,
    "question": "From Android In App Billing version 3 (TrivialDrive)sample application coming with sdk\n\n<h3>MainActivity.java</h3>\n\n<pre><code>/* base64EncodedPublicKey should be YOUR APPLICATION'S PUBLIC KEY\n * (that you got from the Google Play developer console). This is not your\n * developer public key, it's the *app-specific* public key.\n *\n * Instead of just storing the entire literal string here embedded in the\n * program,  construct the key at runtime from pieces or\n * use bit manipulation (for example, XOR with some other string) to hide\n * the actual key.  The key itself is not secret information, but we don't\n * want to make it easy for an attacker to replace the public key with one\n * of their own and then fake messages from the server.\n */\nString base64EncodedPublicKey = \"CONSTRUCT_YOUR_KEY_AND_PLACE_IT_HERE\";\n</code></pre>\n\nWell I am not sure I understand this security measure. I know how to get the application public key (which is already base 64 encoded) from Google Play Developer Console. \n\nWhat I am not understanding is this part\n\n<pre><code> /* Instead of just storing the entire literal string here embedded in the\n * program,  construct the key at runtime from pieces or\n * use bit manipulation (for example, XOR with some other string) to hide\n * the actual key\n */\n</code></pre>\n\nAs far as I know, this public key is a constant string, which is given from Google during application upload process. \n\nHow can we create the same key programmatically using any bit manipulation process? Has someone done it before? Is there any sample code on how to do this?\n",
    "accepted_answer": "Something like this:\n\n<pre><code>String Base64EncodedPublicKey key = \"Ak3jfkd\" + GetMiddleBit() + \"D349824\";\n</code></pre>\n\nor \n\n<pre><code>String Base64EncodedPublicKey key = \n         DecrementEachletter(\"Bl4kgle\") + GetMiddleBit() + ReverseString(\"D349824\");\n</code></pre>\n\nor anything that doesn't put the key in base64 plaintext in a single string. Probably also something that doesn't store the key in base64 would be a good idea too, since raw base64 text fragments are pretty easy to spot.\n\nIt's not a particularly GOOD way to protect the key. But it protects against a trivial attack where somebody just searches through literal strings in you APK looking for something that looks like a base64-encoded public key. At least you make the #$<em>#</em>$ers work a little bit.\n\nPresumably evil people can do bad things if they identify your public key. Google seems to think so, apparently. I can guess what this step does, but I'm not sure I really want to speculate on that in an open forum, and give anyone any ideas.  You want to do it though.\n\nThe basic plot summary would be that you're making it more difficult for somebody to write an application that programmatically de-LVLs an applciation.\n\nOne assumes that anyone who's doing this makes a living cracking 20 or 30,000 android apps and republishing them. Chances are, I suppose that they're not going to take the extra ten minutes to add your app to the list of 20,000 Android apps that have already been broken by a program, if they actually have to do a little bit of manual work. Unless you have a top tier application. And then the battle is potentially endless, and probably ultimately futile.\n\nSplitting the key into consecutive chunks (as proposed in another answer) probably isn't good enough. Because the key will end up in consecutive strings in the string constant tables in the APK. Too easy to find that with a program.\n",
    "text_a": "From Android In App Billing version 3 (TrivialDrive)sample application coming with sdk  MainActivity.java  [CODE1]  Well I am not sure I understand this security measure. I know how to get the application public key (which is already base 64 encoded) from Google Play Developer Console.   What I am not understanding is this part  [CODE2]  As far as I know, this public key is a constant string, which is given from Google during application upload process.   How can we create the same key programmatically using any bit manipulation process? Has someone done it before? Is there any sample code on how to do this? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 24,
    "question": "I'm using <code>AES/GCM/NoPadding</code> encryption in Java 8 and I'm wondering whether my code has a security flaw.  My code seems to <em>work</em>, in that it encrypts and decrypts text, but a few details are unclear.\nMy main question is this:\n<pre><code>Cipher cipher = Cipher.getInstance(&quot;AES/GCM/NoPadding&quot;);\ncipher.init(Cipher.ENCRYPT_MODE, key);\nbyte[] iv = cipher.getIV(); // ?????\n</code></pre>\n<strong>Does that IV satisfy the requirement of &quot;For a given key, the IV MUST NOT repeat.&quot; from <a href=\"https://www.rfc-editor.org/rfc/rfc4106#section-3.1\" rel=\"nofollow noreferrer\">RFC 4106</a>?</strong>\nI'd also appreciate any answers / insight for my related questions (see below), but that first question is bugging me the most.  I don't know where to find source code or documentation that answers this.\n<hr />\nHere is the full code, roughly.  I apologize in case I introduced errors while writing this post:\n<pre><code>class Encryptor {\n  Key key;\n\n  Encryptor(byte[] key) {\n    if (key.length != 32) throw new IllegalArgumentException();\n    this.key = new SecretKeySpec(key, &quot;AES&quot;);\n  }\n\n  // the output is sent to users\n  byte[] encrypt(byte[] src) throws Exception {\n    Cipher cipher = Cipher.getInstance(&quot;AES/GCM/NoPadding&quot;);\n    cipher.init(Cipher.ENCRYPT_MODE, key);\n    byte[] iv = cipher.getIV(); // See question #1\n    assert iv.length == 12; // See question #2\n    byte[] cipherText = cipher.doFinal(src);\n    assert cipherText.length == src.length + 16; // See question #3\n    byte[] message = new byte[12 + src.length + 16]; // See question #4\n    System.arraycopy(iv, 0, message, 0, 12);\n    System.arraycopy(cipherText, 0, message, 12, cipherText.length);\n    return message;\n  }\n\n  // the input comes from users\n  byte[] decrypt(byte[] message) throws Exception {\n    if (message.length &lt; 12 + 16) throw new IllegalArgumentException();\n    Cipher cipher = Cipher.getInstance(&quot;AES/GCM/NoPadding&quot;);\n    GCMParameterSpec params = new GCMParameterSpec(128, message, 0, 12);\n    cipher.init(Cipher.DECRYPT_MODE, key, params);\n    return cipher.doFinal(message, 12, message.length - 12);\n  }\n}\n</code></pre>\nSuppose that users cracking my secret key = game over.\n<hr />\nMore detailed questions / related questions:\n<ol>\n<li>Is the IV returned by cipher.getIV() safe for me to use in this way?</li>\n</ol>\n<ul>\n<li>Does it avoid the catastrophe of reusing the IV,key combination in Galois/Counter Mode?</li>\n<li>Is it still safe when I have multiple applications running this code at once, all displaying encrypted messages to users from the same src data (possibly in the same millisecond)?</li>\n<li>What's the returned IV made of?  Is it an atomic counter plus some random noise?</li>\n<li>Do I need to avoid <code>cipher.getIV()</code> and construct an IV myself, with my own counter?</li>\n<li>Is the source code implementing <code>cipher.getIV()</code> available online somewhere, assuming I'm using Oracle JDK 8 + JCE Unlimited Strength extension?</li>\n</ul>\n<ol start=\"2\">\n<li>Is that IV always 12 bytes long?\n</li>\n<li>Is the authentication tag always 16 bytes (128 bits) long?\n</li>\n<li>With #2 and #3, and the lack of padding, does that mean my encrypted messages are always <code>12 + src.length + 16</code> bytes long?  (And so I can safely squish them into one byte array, for which I know the correct length?)\n</li>\n<li>Is it safe for me to display an unbounded number of src data encryptions to users, given constant src data that the users know?\n</li>\n<li>Is it safe for me to display an unbounded number of src data encryptions to users, if the src data is different every time (e.g. including <code>System.currentTimeMillis()</code> or random numbers)?\n</li>\n<li>Would it help if I padded the src data with random numbers before encryption?  Say 8 random bytes in front and back, or only on one end?  Or would that not help at all / make my encryption worse?\n</li>\n</ol>\n(Because these questions are all about the same block of my own code, and they are strongly related to each other, and others might/should have the same set of questions when implementing the same functionality, it felt wrong to split the questions into multiple posts.  I can re-post them separately if that is more appropriate for StackOverflow's format.  Let me know!)\n",
    "accepted_answer": "<strong>Q1: Is the IV returned by cipher.getIV() safe for me to use in this way?</strong>\nYes, it is at least for the Oracle provided implementation. It is generated separately using the default <code>SecureRandom</code> implementation. As it is 12 bytes in size (the default for GCM) then you have 96 bits of randomness. The chance that the counter repeats is abysmally small. You can look up the source in the OpenJDK (GPL'ed) which the Oracle JDK is based on.\nI would however still recommend you to generate your own 12 random bytes as other providers may behave differently.\n<hr />\n<strong>Q2: Is that IV always 12 bytes long?</strong>\nIt's extremely likely as it is the GCM default, but other lengths <em>are</em> valid for GCM. The algorithm will however have to do additional calculations for any other size than 12 bytes. Due to weaknesses it is strongly recommended to keep it at 12 bytes / 96 bits and API's <em>may restrict you to that choice of IV size</em>.\n<hr />\n<strong>Q3: Is the authentication tag always 16 bytes (128 bits) long?</strong>\nNo, it can have any size in bytes ranging from 64 bits to 128 bits with 8 bit increments. If it is smaller it simply consists of the leftmost bytes of the authentication tag though. You can specify another size of tag using <a href=\"http://docs.oracle.com/javase/7/docs/api/javax/crypto/spec/GCMParameterSpec.html\" rel=\"nofollow noreferrer\"><code>GCMParameterSpec</code></a> as third parameter for your <code>init</code> call.\nNote that the strength of GCM is strongly dependent on the size of the tag. I would recommend keeping it to 128 bits. 96 bits should be the minimum <em>especially</em> if you want to generate a lot of ciphertext.\n<hr />\n<strong>Q4: With #2 and #3, and the lack of padding, does that mean my encrypted messages are always 12 + src.length + 16 bytes long? (And so I can safely squish them into one byte array, for which I know the correct length?)</strong>\nSee above. For the Oracle provider this is the case. Use <code>GCMParameterSpec</code> to be sure of it.\n<hr />\n<strong>Q5: Is it safe for me to display an unbounded number of src data encryptions to users, given constant src data that the users know?</strong>\n<em>Virtually</em> unbound, yes. I would start worrying after about 2^48 encryptions. In general you should however <em>design for</em> key change.\n<hr />\n<strong>Q6: Is it safe for me to display an unbounded number of src data encryptions to users, if the src data is different every time (e.g. including System.currentTimeMillis() or random numbers)?</strong>\nSee answer to Q5 &amp; Q7\n<hr />\n<strong>Q7: Would it help if I padded the src data with random numbers before encryption? Say 8 random bytes in front and back, or only on one end? Or would that not help at all / make my encryption worse?</strong>\nNo, it would not help at all. GCM uses CTR mode underneath, so it would just be encrypted with the key stream. It would <em>not</em> act as an IV. Nowadays you could look at AES-GCM-SIV if you have an ever changing message to encrypt, but note that that algorithm is not implemented in any of the JCA providers.\n<hr />\nIf you need a lot of ciphertexts (higher than 2^48!, or 2^32 - ~4 billion - for the cautious) then I would suggest you use that random number and your key for a key derivation function or KDF. HKDF is currently best of breed, but you may need to use Bouncy Castle or implement it yourself.\n",
    "text_a": "I'm using AES/GCM/NoPadding encryption in Java 8 and I'm wondering whether my code has a security flaw.  My code seems to work, in that it encrypts and decrypts text, but a few details are unclear. My main question is this: [CODE1] Does that IV satisfy the requirement of &quot;For a given key, the IV MUST NOT repeat.&quot; from RFC 4106? I'd also appreciate any answers / insight for my related questions (see below), but that first question is bugging me the most.  I don't know where to find source code or documentation that answers this.  Here is the full code, roughly.  I apologize in case I introduced errors while writing this post: [CODE2] Suppose that users cracking my secret key = game over.  More detailed questions / related questions:  Is the IV returned by cipher.getIV() safe for me to use in this way?   Does it avoid the catastrophe of reusing the IV,key combination in Galois/Counter Mode? Is it still safe when I have multiple applications running this code at once, all displaying encrypted messages to users from the same src data (possibly in the same millisecond)? What's the returned IV made of?  Is it an atomic counter plus some random noise? Do I need to avoid cipher.getIV() and construct an IV myself, with my own counter? Is the source code implementing cipher.getIV() available online somewhere, assuming I'm using Oracle JDK 8 + JCE Unlimited Strength extension?   Is that IV always 12 bytes long?  Is the authentication tag always 16 bytes (128 bits) long?  With #2 and #3, and the lack of padding, does that mean my encrypted messages are always [CODE3] bytes long?  (And so I can safely squish them into one byte array, for which I know the correct length?)  Is it safe for me to display an unbounded number of src data encryptions to users, given constant src data that the users know?  Is it safe for me to display an unbounded number of src data encryptions to users, if the src data is different every time (e.g. including System.currentTimeMillis() or random numbers)?  Would it help if I padded the src data with random numbers before encryption?  Say 8 random bytes in front and back, or only on one end?  Or would that not help at all / make my encryption worse?   (Because these questions are all about the same block of my own code, and they are strongly related to each other, and others might/should have the same set of questions when implementing the same functionality, it felt wrong to split the questions into multiple posts.  I can re-post them separately if that is more appropriate for StackOverflow's format.  Let me know!) ",
    "tgt_text": "using AES/GCM/NoPadding encryption in Java 8",
    "label": "C5",
    "code": "",
    "insecure_code": "Cipher cipher = Cipher.getInstance(\"AES/GCM/NoPadding\");\ncipher.init(Cipher.ENCRYPT_MODE, key);\nbyte[] iv = cipher.getIV(); // ?????"
  },
  {
    "guid": 25,
    "question": "Let's consider a common-known ASP.NET Core scenario. Firstly we add the middleware:\n<pre class=\"lang-cs prettyprint-override\"><code>public void Configure(IApplicationBuilder app)\n{\n    app.UseCookieAuthentication(new CookieAuthenticationOptions()\n    {\n        AuthenticationScheme = &quot;MyCookie&quot;,\n        CookieName = &quot;MyCookie&quot;,\n        LoginPath = new PathString(&quot;/Home/Login/&quot;),\n        AccessDeniedPath = new PathString(&quot;/Home/AccessDenied/&quot;),\n        AutomaticAuthenticate = true,\n        AutomaticChallenge = true\n    });\n    //...\n}\n</code></pre>\nThen serialize a principal:\n<pre class=\"lang-cs prettyprint-override\"><code>await HttpContext.Authentication.SignInAsync(&quot;MyCookie&quot;, principal);\n</code></pre>\nAfter these two calls an encrypted cookie will be stored at the client side. You can see the cookie (in my case it was chunked) in any browser devtools:\n<img src=\"https://web.archive.org/web/20170809191300im_/https://i.stack.imgur.com/p2Gy8.png\" alt=\"chunked encrypted cookie generated by ASP.NET\" />\nIt's not a problem (and not a question) to work with cookies from application code.\nMy question is: <strong>how to decrypt the cookie outside the application</strong>? I guess a private key is needed for that, how to get it?\nI checked the <a href=\"https://learn.microsoft.com/en-us/aspnet/core/security/authentication/cookie\" rel=\"noreferrer\">docs</a> and found only common words:\n<blockquote>\nThis will create an encrypted cookie and add it to the current\nresponse. The AuthenticationScheme specified during configuration must\nalso be used when calling SignInAsync.\nUnder the covers the encryption used is ASP.NET's Data Protection\nsystem. If you are hosting on multiple machines, load balancing or\nusing a web farm then you will need to configure data protection to\nuse the same key ring and application identifier.\n</blockquote>\nSo, is it possible to decrypt the authentication cookie, and if so how?\n<strong>UPDATE #1:</strong>\nBased on Ron C <a href=\"https://stackoverflow.com/questions/42842511/how-to-manually-decrypt-an-asp-net-core-authentication-cookie/42857830#42857830\">great answer and comments</a>, I've ended up with code:\n<pre class=\"lang-cs prettyprint-override\"><code>public class Startup\n{\n    //constructor is omitted...\n    \n    public void ConfigureServices(IServiceCollection services)\n    {\n        services.AddDataProtection().PersistKeysToFileSystem(\n            new DirectoryInfo(@&quot;C:\\temp-keys\\&quot;));\n\n        services.AddMvc();\n    }\n\n    public void Configure(IApplicationBuilder app)\n    {\n        app.UseCookieAuthentication(new CookieAuthenticationOptions()\n        {\n            AuthenticationScheme = &quot;MyCookie&quot;,\n            CookieName = &quot;MyCookie&quot;,\n            LoginPath = new PathString(&quot;/Home/Index/&quot;),\n            AccessDeniedPath = new PathString(&quot;/Home/AccessDenied/&quot;),\n            AutomaticAuthenticate = true,\n            AutomaticChallenge = true\n        });\n\n        app.UseStaticFiles();\n        app.UseMvcWithDefaultRoute();\n    }\n}\n\npublic class HomeController : Controller\n{\n    public async Task&lt;IActionResult&gt; Index()\n    {\n        await HttpContext.Authentication.SignInAsync(&quot;MyCookie&quot;, new ClaimsPrincipal());\n\n        return View();\n    }\n\n    public IActionResult DecryptCookie()\n    {\n        var provider = DataProtectionProvider.Create(new DirectoryInfo(@&quot;C:\\temp-keys\\&quot;));\n\n        string cookieValue = HttpContext.Request.Cookies[&quot;MyCookie&quot;];\n\n        var dataProtector = provider.CreateProtector(\n            typeof(CookieAuthenticationMiddleware).FullName, &quot;MyCookie&quot;, &quot;v2&quot;);\n\n        UTF8Encoding specialUtf8Encoding = new UTF8Encoding(false, true);\n        byte[] protectedBytes = Base64UrlTextEncoder.Decode(cookieValue);\n        byte[] plainBytes = dataProtector.Unprotect(protectedBytes);\n        string plainText = specialUtf8Encoding.GetString(plainBytes);\n\n        return Content(plainText);\n    }\n}\n</code></pre>\nUnfortunately this code always produces exception on <code>Unprotect</code> method call:\n<blockquote>\nCryptographicException in Microsoft.AspNetCore.DataProtection.dll:\nAdditional information: The payload was invalid.\n</blockquote>\nI tested different variations of this code on several machines without positive result. Probably I made a mistake, but where?\n<strong>UPDATE #2:</strong> My mistake was the <code>DataProtectionProvider</code> hasn't been set in <code>UseCookieAuthentication</code>. Thanks to @RonC again.\n",
    "accepted_answer": "<h2>Decrypting the Authentication Cookie without needing the keys</h2>\n\nIt's worth noting that you don't need to gain access to the keys to decrypt the authentication cookie.  You simply need to use the right <code>IDataProtector</code>  created with the right purpose parameter, and subpurpose parameters. \n\nBased on the <code>CookieAuthenticationMiddleware</code> source code <a href=\"https://github.com/aspnet/Security/blob/rel/1.1.1/src/Microsoft.AspNetCore.Authentication.Cookies/CookieAuthenticationMiddleware.cs#L4\" rel=\"noreferrer\">https://github.com/aspnet/Security/blob/rel/1.1.1/src/Microsoft.AspNetCore.Authentication.Cookies/CookieAuthenticationMiddleware.cs#L4</a> it looks like the purpose you need to pass is <code>typeof(CookieAuthenticationMiddleware)</code>. And since they are passing additional parameters to the <code>IDataProtector</code> you will need to match them.  So this line of code should get you an <code>IDataProtector</code> that can be used to decrypt the authentication cookie:\n\n<pre class=\"lang-cs prettyprint-override\"><code>var dataProtector = provider.CreateProtector(typeof(CookieAuthenticationMiddleware).FullName, Options.AuthenticationScheme, \"v2\");\n</code></pre>\n\nNote that<code>Options.AuthenticationScheme</code> is just \"MyCookie\" in this case since that's what it was set to in the <code>Configure</code> method of the startup.cs file.\n\nHere is an example action method for decrypting your authentication cookie two different ways:\n\n<pre class=\"lang-cs prettyprint-override\"><code>public IActionResult DecryptCookie() {\n\n    //Get the encrypted cookie value\n    string cookieValue = HttpContext.Request.Cookies[\"MyCookie\"];\n\n    //Get a data protector to use with either approach\n    var dataProtector = provider.CreateProtector(typeof(CookieAuthenticationMiddleware).FullName, \"MyCookie\", \"v2\");\n\n\n    //Get the decrypted cookie as plain text\n    UTF8Encoding specialUtf8Encoding = new UTF8Encoding(encoderShouldEmitUTF8Identifier: false, throwOnInvalidBytes: true);\n    byte[] protectedBytes = Base64UrlTextEncoder.Decode(cookieValue);\n    byte[] plainBytes = dataProtector.Unprotect(protectedBytes);\n    string plainText = specialUtf8Encoding.GetString(plainBytes);\n\n\n    //Get the decrypted cookie as a Authentication Ticket\n    TicketDataFormat ticketDataFormat = new TicketDataFormat(dataProtector);\n    AuthenticationTicket ticket = ticketDataFormat.Unprotect(cookieValue);\n\n    return View();\n}\n</code></pre>\n\nThis method uses an <code>IDataProtectionProvider</code> called <code>provider</code> that is constructor injected.\n<br>\n<br>\n<br>\n\n<h2>Decrypting the Authentication Cookie when persisting keys to a directory</h2>\n\nIf you want to share cookies between applications then you might decide to persist the data protection keys to a directory.  This can be done by adding the following to the <code>ConfigureServices</code> method of the startup.cs file:\n\n<pre class=\"lang-cs prettyprint-override\"><code>services.AddDataProtection().PersistKeysToFileSystem(\n        new DirectoryInfo(@\"C:\\temp-keys\\\")); \n</code></pre>\n\n<strong>BE CAREFUL</strong> though because the keys are not encrypted so it's up to you to protect them!!!  Only persist the keys to a directory if you absolutely must, (or if you are just trying to understand how the system works).  You will <em>also</em> need to specify a cookie <code>DataProtectionProvider</code> that uses those keys.  This can be done with the help of the <code>UseCookieAuthentication</code> configuration in the <code>Configure</code> method of the startup.cs class like so:\n\n<pre class=\"lang-cs prettyprint-override\"><code>app.UseCookieAuthentication(new CookieAuthenticationOptions() {\n        DataProtectionProvider = DataProtectionProvider.Create(new DirectoryInfo(@\"C:\\temp-keys\\\")),\n        AuthenticationScheme = \"MyCookie\",\n        CookieName = \"MyCookie\",\n        LoginPath = new PathString(\"/Home/Login\"),\n        AccessDeniedPath = new PathString(\"/Home/AccessDenied\"),\n        AutomaticAuthenticate = true,\n        AutomaticChallenge = true\n    });\n</code></pre>\n\nWith that configuration done.  You can now decrypt the authentication cookie with the following code:\n\n<pre class=\"lang-cs prettyprint-override\"><code> public IActionResult DecryptCookie() {\n        ViewData[\"Message\"] = \"This is the decrypt page\";\n        var user = HttpContext.User;        //User will be set to the ClaimsPrincipal\n\n        //Get the encrypted cookie value\n        string cookieValue = HttpContext.Request.Cookies[\"MyCookie\"];\n\n\n        var provider = DataProtectionProvider.Create(new DirectoryInfo(@\"C:\\temp-keys\\\"));\n\n        //Get a data protector to use with either approach\n        var dataProtector = provider.CreateProtector(typeof(CookieAuthenticationMiddleware).FullName, \"MyCookie\", \"v2\");\n\n\n        //Get the decrypted cookie as plain text\n        UTF8Encoding specialUtf8Encoding = new UTF8Encoding(encoderShouldEmitUTF8Identifier: false, throwOnInvalidBytes: true);\n        byte[] protectedBytes = Base64UrlTextEncoder.Decode(cookieValue);\n        byte[] plainBytes = dataProtector.Unprotect(protectedBytes);\n        string plainText = specialUtf8Encoding.GetString(plainBytes);\n\n\n        //Get teh decrypted cookies as a Authentication Ticket\n        TicketDataFormat ticketDataFormat = new TicketDataFormat(dataProtector);\n        AuthenticationTicket ticket = ticketDataFormat.Unprotect(cookieValue);\n\n        return View();\n    }\n</code></pre>\n\nYou can learn more about this latter scenario here: <a href=\"https://learn.microsoft.com/en-us/aspnet/core/security/data-protection/compatibility/cookie-sharing\" rel=\"noreferrer\">https://learn.microsoft.com/en-us/aspnet/core/security/data-protection/compatibility/cookie-sharing</a>\n",
    "text_a": "Let's consider a common-known ASP.NET Core scenario. Firstly we add the middleware: [CODE1] Then serialize a principal: [CODE2] After these two calls an encrypted cookie will be stored at the client side. You can see the cookie (in my case it was chunked) in any browser devtools:  It's not a problem (and not a question) to work with cookies from application code. My question is: how to decrypt the cookie outside the application? I guess a private key is needed for that, how to get it? I checked the docs and found only common words:  This will create an encrypted cookie and add it to the current response. The AuthenticationScheme specified during configuration must also be used when calling SignInAsync. Under the covers the encryption used is ASP.NET's Data Protection system. If you are hosting on multiple machines, load balancing or using a web farm then you will need to configure data protection to use the same key ring and application identifier.  So, is it possible to decrypt the authentication cookie, and if so how? UPDATE #1: Based on Ron C great answer and comments, I've ended up with code: [CODE3] Unfortunately this code always produces exception on Unprotect method call:  CryptographicException in Microsoft.AspNetCore.DataProtection.dll: Additional information: The payload was invalid.  I tested different variations of this code on several machines without positive result. Probably I made a mistake, but where? UPDATE #2: My mistake was the DataProtectionProvider hasn't been set in UseCookieAuthentication. Thanks to @RonC again. ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 26,
    "question": "Is it possible to reverse a SHA-1?\nI'm thinking about using a SHA-1 to create a simple lightweight system to authenticate a small embedded system that communicates over an unencrypted connection.\nLet's say that I create a sha1 like this with input from a &quot;secret key&quot; and spice it with a timestamp so that the SHA-1 will change all the time.\n<pre><code>sha1(&quot;My Secret Key&quot;+&quot;a timestamp&quot;)\n</code></pre>\nThen I include this SHA-1 in the communication and the server, which can do the same calculation. And hopefully, nobody would be able to figure out the &quot;secret key&quot;.\nBut is this really true?\nIf you know that this is how I did it, you would know that I did put a timestamp in there and you would see the SHA-1.\nCan you then use those two and figure out the &quot;secret key&quot;?\n<pre><code>secret_key = bruteforce_sha1(sha1, timestamp)\n</code></pre>\n<hr />\n<em>Note1</em>:\nI guess you could brute force in some way, but how much work would that actually be?\n<em>Note2</em>:\nI don't plan to encrypt any data, I just would like to know who sent it.\n",
    "accepted_answer": "No, you cannot reverse SHA-1, that is exactly why it is called a Secure Hash Algorithm.\n\nWhat you should definitely be doing though, is include the message that is being transmitted into the hash calculation. Otherwise a man-in-the-middle could intercept the message, and use the signature (which only contains the sender's key and the timestamp) to attach it to a fake message (where it would still be valid).\n\nAnd you should probably be using SHA-256 for new systems now.\n\n<pre><code>sha(\"My Secret Key\"+\"a timestamp\" + the whole message to be signed)\n</code></pre>\n\nYou also need to additionally transmit the timestamp in the clear, because otherwise you have no way to verify the digest (other than trying a lot of plausible timestamps).\n\nIf a brute force attack is feasible depends on the length of your secret key.\n\nThe security of your whole system would rely on this shared secret (because both sender and receiver need to know, but no one else). An attacker would try to go after the key (either but brute-force guessing or by trying to get it from your device) rather than trying to break SHA-1.\n",
    "text_a": "Is it possible to reverse a SHA-1? I'm thinking about using a SHA-1 to create a simple lightweight system to authenticate a small embedded system that communicates over an unencrypted connection. Let's say that I create a sha1 like this with input from a &quot;secret key&quot; and spice it with a timestamp so that the SHA-1 will change all the time. [CODE1] Then I include this SHA-1 in the communication and the server, which can do the same calculation. And hopefully, nobody would be able to figure out the &quot;secret key&quot;. But is this really true? If you know that this is how I did it, you would know that I did put a timestamp in there and you would see the SHA-1. Can you then use those two and figure out the &quot;secret key&quot;? [CODE2]  Note1: I guess you could brute force in some way, but how much work would that actually be? Note2: I don't plan to encrypt any data, I just would like to know who sent it. ",
    "tgt_text": "create a sha1 like this with input from a &quot;secret key&quot; and spice it with a timestamp",
    "label": "C1",
    "code": "<code>sha1(&quot;My Secret Key&quot;+&quot;a timestamp&quot;)\n</code>",
    "insecure_code": "sha1(&quot;My Secret Key&quot;+&quot;a timestamp&quot;)"
  },
  {
    "guid": 27,
    "question": "I am trying to hide 2 secrets that I am using in one of my apps.\n\nAs I understand the keychain is a good place but I can not add them before I submit the app.\n\nI thought about this scenario -\n\n<ul>\n<li>Pre seed the secrets in my app's CoreData Database by spreading them in other entities to obscure them. (I already have a seed DB in that app).</li>\n<li>As the app launches for the first time, generate and move the keys to the keychain.</li>\n<li>Delete the records from CoreData.</li>\n</ul>\n\nIs that safe or can the hacker see this happening and get those keys?\n\n*THIRD EDIT**\nSorry for not explaining this scenario from the beginning - The App has many levels, each level contains files (audio, video, images). The user can purchase a level (IAP) and after the purchase is completed I need to download the files to his device.\n\nFor iOS6 the files are stored with Apple new \"Hosted Content\" feature. For iOS5 the files are stored in amazon S3.\n\nSo in all this process I have 2 keys:\n1. IAP key, for verifying the purchase at Apple IAP.\n2. S3 keys, for getting the files from S3 for iOS5 users:\n\n<pre><code>NSString *secretAccessKey = @\"xxxxxxxxx\";\nNSString *accessKey = @\"xxxxxxxxx\";\n</code></pre>\n\nDo I need to protect those keys at all? I am afraid that people will be able to get the files from S3 with out purchasing the levels. Or that hackers will be able to build a hacked version with all the levels pre-downloaded inside.\n",
    "accepted_answer": "Let me try to break down your question to multiple subquestions/assumption:\n\n<h1>Assumptions:</h1>\n\n<strong>a) Keychain is safe place</strong>\n\nActually, it's not that safe. If your application is installed on jailbroked device, a hacker will be able to get your keys from the keychain\n\n<h1>Questions:</h1>\n\n<strong>a) Is there a way to put some key into an app (binary which is delivered form AppStore) and be completely secure?</strong>\n\nShort answer is NO. As soon as there is something in your binary, it could be reverse engineered.\n\n<strong>b) Will obfuscation help?</strong>\n\nYes. It will increase time for a hacker to figure it out. If the keys which you have in app will \"cost\" less than a time spend on reverse engineering - generally speaking, you are good.\n\nHowever, in most cases, security through obscurity is bad practice, It gives you a feeling that you are secure, but you aren't.\n\nSo, this could be one of security measures, but you need to have other security measures in place too.\n\n<strong>c) What should I do in such case?*</strong>\n\nIt's hard to give you a good solution without knowing background what you are trying to do.\n\nAs example, why everybody should have access to the same Amazon S3? Do they need to read-only or write (as pointed out by Kendall Helmstetter Gein). \n\nI believe one of the most secure scenarios would be something like that:\n\n<ul>\n<li>Your application should be passcode protected </li>\n<li>First time you enter your application it requests a user to authenticate (enter his username, password) to the server</li>\n<li>This authenticates against your server or other authentication provider (e.g. Google)</li>\n<li>The server sends some authentication token to a device (quite often it's some type of cookie).</li>\n<li>You encrypt this token based on hash of your application passcode and save it in keychain in this form</li>\n<li>And now you can do one of two things:\n\n<ul>\n<li>hand over specific keys from the server to the client (so each client will have their own keys) and encrypt them with the hash of your application passcode</li>\n<li>handle all operation with S3 on the server (and require client to send)</li>\n</ul></li>\n</ul>\n\nThis way your protect from multiple possible attacks.\n\n<strong>c) Whoooa.... I don't plan to implement all of this stuff which you just wrote, because it will take me  months. Is there anything simpler?</strong>\n\nI think it would be useful, if you have one set of keys per client.\n\nIf even this is too much then download encrypted keys from the server and save them in encrypted form on the device and have decryption key hardcoded into your app. I would say it's minimally invasive and at least your binary doesn't have keys in it.\n\nP.S. Both Kendall and Rob are right.\n\n<h1>Update 1 (based on new info)</h1>\n\nFirst of all, have you seen <a href=\"http://developer.apple.com/library/ios/#documentation/NetworkingInternet/Conceptual/StoreKitGuide/APIOverview/OverviewoftheStoreKitAPI.html#//apple_ref/doc/uid/TP40008267-CH100-SW1\" rel=\"noreferrer\">in app purchase programming guide</a>.\n\nThere is very good drawing under Server Product Model. This model protects against somebody who didn't buy new levels. There will be no amazon keys embedded in your application and your server side will hand over levels when it will receive receipt of purchase. \n\nThere is no perfect solution to protect against somebody who purchased the content (and decided to rip it off from your application), because at the end of days your application will have the content downloaded to a device and will need it in plain (unencrypted form) at some point of time.\n\nIf you are really concerned about this case, I would recommend to encrypt all your assets and hand over it in encrypted form from the server together with encryption key. Encryption key should be generated per client and asset should be encrypted using it.\n\nThis won't stop any advanced hacker, but at least it will protect from somebody using iExplorer and just copying files (since they will be encrypted).\n\n<h1>Update 2</h1>\n\nOne more thing regarding update 1. You should store files unencrypted and store encryption key somewhere (e.g. in keychain).\n\nIn case your game requires internet connection, the best idea is to not store encryption key on the device at all. You can get it from the server each time when your app is started.\n",
    "text_a": "I am trying to hide 2 secrets that I am using in one of my apps.  As I understand the keychain is a good place but I can not add them before I submit the app.  I thought about this scenario -   Pre seed the secrets in my app's CoreData Database by spreading them in other entities to obscure them. (I already have a seed DB in that app). As the app launches for the first time, generate and move the keys to the keychain. Delete the records from CoreData.   Is that safe or can the hacker see this happening and get those keys?  *THIRD EDIT** Sorry for not explaining this scenario from the beginning - The App has many levels, each level contains files (audio, video, images). The user can purchase a level (IAP) and after the purchase is completed I need to download the files to his device.  For iOS6 the files are stored with Apple new \"Hosted Content\" feature. For iOS5 the files are stored in amazon S3.  So in all this process I have 2 keys: 1. IAP key, for verifying the purchase at Apple IAP. 2. S3 keys, for getting the files from S3 for iOS5 users:  [CODE1]  Do I need to protect those keys at all? I am afraid that people will be able to get the files from S3 with out purchasing the levels. Or that hackers will be able to build a hacked version with all the levels pre-downloaded inside. ",
    "tgt_text": "IAP key, for verifying the purchase at Apple IAP",
    "label": "C1",
    "code": "<code>NSString *secretAccessKey = @\"xxxxxxxxx\";\nNSString *accessKey = @\"xxxxxxxxx\";\n</code>",
    "insecure_code": "NSString *secretAccessKey = @\"xxxxxxxxx\""
  },
  {
    "guid": 28,
    "question": "Why was it decided that using <strong>XMLHTTPRequest</strong> for doing XML calls should not do calls across the domain boundary?  You can retrieve JavaScript, images, CSS, iframes, and just about any other content I can think of from other domains. Why are the Ajax HTTP requests not allowed to cross the domain boundaries?  It seems like an odd limitation to put, considering the only way I could see it being abused, would be if someone were to inject Javascript into the page.  However, in this case, you could simply add an img, script, or iframe element to the document to get it to request the third party URL and send it to the server.  \n\n[Edit] \n\nSome of the answers point out the following reasons, let's point out the reasons they don't  create a major reason to disallow this.\n\n<h2>XSRF (Cross Site Request Forgery, also known as CSRF, XSRF)</h2>\n\nYour can do XSRF attacks without using this at all.  As a general rule, XMLHTTPRequest isn't used at all, simply because it's so hard to make an XMLHTTPRequest in a way that's compatible with all major browsers.  It's much easier to just add an img tag to the URL if you want them to load your URL.\n\n<h2>Posting to third party site</h2>\n\n<pre><code>&lt;script type=\"text/javascript\"&gt;\n  $.post(\"http://some-bank.com/transfer-money.php\", \n         { amount: \"10000\", to_account: \"xxxx\" })\n&lt;/script&gt;\n</code></pre>\n\nCould be accomplished with\n\n<pre><code>&lt;body onload=\"document.getElementById('InvisbleForm').submit()\"\n    &lt;div style=\"display:none\"&gt;\n        &lt;form id=\"InvisbleForm\" action=\"http://some-bank.com/transfer-money.php\" method=\"POST\"&gt;\n            &lt;input type=\"hidden\" name=\"amount\" value=\"10000\"&gt;\n            &lt;input type=\"hidden\" name=\"to_account\" value=\"xxxxx\"&gt;\n        &lt;/form&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n</code></pre>\n\n<h2>JPunyon: why would you leave the vulnerability in a new feature</h2>\n\nYou aren't creating any more insecurities.  You are just inconveniencing developers who want to use it in a way for good.  Anybody who wants to use this feature for evil (aka awesome) could just use some other method of doing it.\n\n<h2>Conclusion</h2>\n\nI'm marking the answer from <strong>bobince</strong> as correct because he pointed out the critical problem.  Because XMLHTTPRequest allows you to post, with credentials (cookies) to the destination site, and read the data sent back from the site, along with sending the persons credentials, you could orchestrate some javascript that would submit a series of forms, including confirmation forms, complete with any random keys generated that were put in place to try to prevent a XSRF.  In this way, you could browse through the target site, like a bank, and the bank's webserver would be unable to tell that it wasn't just a regular user submitting all these forms.\n",
    "accepted_answer": "<blockquote>\n  Why are Ajax HTTP Requests not allowed to cross domain boundaries.\n</blockquote>\n\nBecause AJAX requests are (a) submitted with user credentials, and (b) allow the caller to read the returned data.\n\nIt is a combination of these factors that can result in a vulnerability. There are proposals to add a form of cross-domain AJAX that omits user credentials.\n\n<blockquote>\n  you could simply add an img, script, or iframe element to the document\n</blockquote>\n\nNone of those methods allow the caller to read the returned data.\n\n(Except scripts where either it's deliberately set up to allow that, for permitted cross-domain scripting - or where someone's made a terrible cock-up.)\n\n<blockquote>\n  Your can do XSS attacks without using this at all. Posting to third party site\n</blockquote>\n\nThat's not an XSS attack. That's a cross-site request forgery attack (XSRF). There are known ways to solve XSRF attacks, such as including one-time or cryptographic tokens to verify that the submission came deliberately from the user and was not launched from attacker code.\n\nIf you allowed cross-domain AJAX you would lose this safeguard. The attacking code could request a page from the banking site, read any authorisation tokens on it, and submit them in a second AJAX request to perform the transfer. And that <em>would</em> be a cross-site scripting attack.\n",
    "text_a": "Why was it decided that using XMLHTTPRequest for doing XML calls should not do calls across the domain boundary?  You can retrieve JavaScript, images, CSS, iframes, and just about any other content I can think of from other domains. Why are the Ajax HTTP requests not allowed to cross the domain boundaries?  It seems like an odd limitation to put, considering the only way I could see it being abused, would be if someone were to inject Javascript into the page.  However, in this case, you could simply add an img, script, or iframe element to the document to get it to request the third party URL and send it to the server.    [Edit]   Some of the answers point out the following reasons, let's point out the reasons they don't  create a major reason to disallow this.  XSRF (Cross Site Request Forgery, also known as CSRF, XSRF)  Your can do XSRF attacks without using this at all.  As a general rule, XMLHTTPRequest isn't used at all, simply because it's so hard to make an XMLHTTPRequest in a way that's compatible with all major browsers.  It's much easier to just add an img tag to the URL if you want them to load your URL.  Posting to third party site  [CODE1]  Could be accomplished with  [CODE2]  JPunyon: why would you leave the vulnerability in a new feature  You aren't creating any more insecurities.  You are just inconveniencing developers who want to use it in a way for good.  Anybody who wants to use this feature for evil (aka awesome) could just use some other method of doing it.  Conclusion  I'm marking the answer from bobince as correct because he pointed out the critical problem.  Because XMLHTTPRequest allows you to post, with credentials (cookies) to the destination site, and read the data sent back from the site, along with sending the persons credentials, you could orchestrate some javascript that would submit a series of forms, including confirmation forms, complete with any random keys generated that were put in place to try to prevent a XSRF.  In this way, you could browse through the target site, like a bank, and the bank's webserver would be unable to tell that it wasn't just a regular user submitting all these forms. ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 29,
    "question": "Celery defaults to using pickle as its serialization method for tasks.  As noted in the <a href=\"http://ask.github.com/celery/faq.html#isn-t-using-pickle-a-security-concern\" rel=\"noreferrer\">FAQ</a>, this represents a security hole.  Celery allows you to configure how tasks get serialized using the <code>CELERY_TASK_SERIALIZER</code> configuration parameter.  \n\nBut this doesn't solve the security problem.  Even if tasks are serialized with JSON or similar, the workers will still execute tasks inserted into the queue with pickle serialization -- they just respond to the <code>content-type</code> parameter in the message.  So anybody who can write to the task queue can effectively pown the worker processes by writing malicious pickled objects.\n\nHow can I prevent the worker threads from running tasks serialized with pickle?\n",
    "accepted_answer": "I got an answer from the celery-users mailing list (From Ask Solem to be specific).  Add these two lines to the config (celeryconfig/settings):\n\n<pre><code>from kombu import serialization\nserialization.registry._decoders.pop(\"application/x-python-serialize\")\n</code></pre>\n",
    "text_a": "Celery defaults to using pickle as its serialization method for tasks.  As noted in the FAQ, this represents a security hole.  Celery allows you to configure how tasks get serialized using the [CODE1] configuration parameter.    But this doesn't solve the security problem.  Even if tasks are serialized with JSON or similar, the workers will still execute tasks inserted into the queue with pickle serialization -- they just respond to the content-type parameter in the message.  So anybody who can write to the task queue can effectively pown the worker processes by writing malicious pickled objects.  How can I prevent the worker threads from running tasks serialized with pickle? ",
    "tgt_text": "Celery allows you to configure how tasks get serialized using the CELERY_TASK_SERIALIZER configuration parameter",
    "label": "C1",
    "code": "<code>CELERY_TASK_SERIALIZER</code>",
    "insecure_code": "CELERY_TASK_SERIALIZER"
  },
  {
    "guid": 30,
    "question": "I am trying to encode a message with <code>SH1 RSA</code> but I have no experience with security subject except some base information about <code>RSA</code>. I have been given a private key as <code>String</code>. I have managed to write following code block to do the job but I am not sure if I am doing the job securely and correctly. \n\nI am not an expert but putting my private key as String in code is not secure I guess. Can anyone guide me?\n\n<pre><code>String privateKeyString = \"mykeyhere...\";\nbyte[] privateKeyBytes = privateKeyString.getBytes();\nString encodedPrivateKey = Base64.encodeToString(privateKeyBytes, Base64.URL_SAFE);\n\nKeyFactory factory = KeyFactory.getInstance(RSA);\nPKCS8EncodedKeySpec keySpec = new PKCS8EncodedKeySpec(encodedPrivateKey.getBytes());\nRSAPrivateKey privateKey = (RSAPrivateKey) factory.generatePrivate(keySpec);\n\nSignature instance = Signature.getInstance(ALGORITHM);\ninstance.initSign(privateKey);\ninstance.update(content.getBytes());\nreturn new String(instance.sign());\n</code></pre>\n\nMy private key is in form as:\n\n<pre><code>\"-----BEGIN PRIVATE KEY-----\\n\"+\n\"MIIE...\\n\"+\n\"cH0iRj...\\n\"+\n\"O0Hhj...\\n\"+\n.\n.\n.\n\"fG6...\\n\"+\n\"B6/hF...\\n\"+\n\"3Mq38...\\n\"+\n\"-----END PRIVATE KEY-----\\n\"\n</code></pre>\n",
    "accepted_answer": "Your key format is an <a href=\"https://stackoverflow.com/a/48960291/4982691\">unencrypted base64-encoded PKCS8-encoded private key</a>. Here is an example of how to decode it into a private key. (Don't worry about the security of the private key in this example, it is just a throwaway for the example).\n<pre><code>import java.io.*;\nimport java.security.KeyFactory;\nimport java.security.PrivateKey;\nimport java.security.spec.PKCS8EncodedKeySpec;\nimport android.util.Base64;\n\npublic class ReadPKCS8Pem {\n\n    private final static String PRIVATE_KEY = \n            &quot;-----BEGIN PRIVATE KEY-----\\n&quot;\n            + &quot;MIICdQIBADANBgkqhkiG9w0BAQEFAASCAl8wggJbAgEAAoGBAM7t8Ub1DP+B91NJ\\n&quot;\n            + &quot;nC45zqIvd1QXkQ5Ac1EJl8mUglWFzUyFbhjSuF4mEjrcecwERfRummASbLoyeMXl\\n&quot;\n            + &quot;eiPg7jvSaz2szpuV+afoUo9c1T+ORNUzq31NvM7IW6+4KhtttwbMq4wbbPpBfVXA\\n&quot;\n            + &quot;IAhvnLnCp/VyY/npkkjAid4c7RoVAgMBAAECgYBcCuy6kj+g20+G5YQp756g95oN\\n&quot;\n            + &quot;dpoYC8T/c9PnXz6GCgkik2tAcWJ+xlJviihG/lObgSL7vtZMEC02YXdtxBxTBNmd\\n&quot;\n            + &quot;upkruOkL0ElIu4S8CUwD6It8oNnHFGcIhwXUbdpSCr1cx62A0jDcMVgneQ8vv6vB\\n&quot;\n            + &quot;/YKlj2dD2SBq3aaCYQJBAOvc5NDyfrdMYYTY+jJBaj82JLtQ/6K1vFIwdxM0siRF\\n&quot;\n            + &quot;UYqSRA7G8A4ga+GobTewgeN6URFwWKvWY8EGb3HTwFkCQQDgmKtjjJlX3BotgnGD\\n&quot;\n            + &quot;gdxVgvfYG39BL2GnotSwUbjjce/yZBtrbcClfqrrOWWw7lPcX1d0v8o3hJfLF5dT\\n&quot;\n            + &quot;6NAdAkA8qAQYUCSSUwxJM9u0DOqb8vqjSYNUftQ9dsVIpSai+UitEEx8WGDn4SKd\\n&quot;\n            + &quot;V8kupy/gJlau22uSVYI148fJSCGRAkBz+GEHFiJX657YwPI8JWHQBcBUJl6fGggi\\n&quot;\n            + &quot;t0F7ibceOkbbsjU2U4WV7sHyk8Cei3Fh6RkPf7i60gxPIe9RtHVBAkAnPQD+BmND\\n&quot;\n            + &quot;By8q5f0Kwtxgo2+YkxGDP5bxDV6P1vd2C7U5/XxaN53Kc0G8zu9UlcwhZcQ5BljH\\n&quot;\n            + &quot;N24cUWZOo+60\\n&quot;\n            + &quot;-----END PRIVATE KEY-----&quot;;\n    \n    public static void main(String[] args) throws Exception {\n        // Read in the key into a String\n        StringBuilder pkcs8Lines = new StringBuilder();\n        BufferedReader rdr = new BufferedReader(new StringReader(PRIVATE_KEY));\n        String line;\n        while ((line = rdr.readLine()) != null) {\n            pkcs8Lines.append(line);\n        }\n        \n        // Remove the &quot;BEGIN&quot; and &quot;END&quot; lines, as well as any whitespace\n        \n        String pkcs8Pem = pkcs8Lines.toString();\n        pkcs8Pem = pkcs8Pem.replace(&quot;-----BEGIN PRIVATE KEY-----&quot;, &quot;&quot;);\n        pkcs8Pem = pkcs8Pem.replace(&quot;-----END PRIVATE KEY-----&quot;, &quot;&quot;);\n        pkcs8Pem = pkcs8Pem.replaceAll(&quot;\\\\s+&quot;,&quot;&quot;);\n        \n        // Base64 decode the result\n        \n        byte [] pkcs8EncodedBytes = Base64.decode(pkcs8Pem, Base64.DEFAULT);\n        \n        // extract the private key\n        \n        PKCS8EncodedKeySpec keySpec = new PKCS8EncodedKeySpec(pkcs8EncodedBytes);\n        KeyFactory kf = KeyFactory.getInstance(&quot;RSA&quot;);\n        PrivateKey privKey = kf.generatePrivate(keySpec);\n        System.out.println(privKey);\n    }\n\n}\n</code></pre>\n",
    "text_a": "I am trying to encode a message with SH1 RSA but I have no experience with security subject except some base information about RSA. I have been given a private key as String. I have managed to write following code block to do the job but I am not sure if I am doing the job securely and correctly.   I am not an expert but putting my private key as String in code is not secure I guess. Can anyone guide me?  [CODE1]  My private key is in form as:  [CODE2] ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 31,
    "question": "I'm new to PHP and this is also my first log in system so it would be great if you guys could look over my code and see if you can spot any security holes:\n\nnote: I am sanitizing all user input although it's not shown here.\n\n<h2>Sign Up:</h2>\n\n<strong>Step 1:</strong> I take the password the user chose and run it through this function:\n<strong>Step 2:</strong> I then store the hash and the salt (<code>$password['hash']</code> and <code>$password['salt']</code>) in the users table in the database:\n\n\n<h2>Log In:</h2>\n\n<strong>Step 1:</strong> I take the username the user entered and do a look up on the database to see if any rows are returned. On my site no 2 users can share the same\nusername so the username field always has a unique value. If I get 1 row returned I grab the salt for that user.\n\n<strong>Step 2:</strong> Then I run the user entered password through the encrypt function (as previously posted above) but this time I also supply the salt retrieved from the database:\n\n<strong>Step 3:</strong> I now have the proper password to match against in this variable: <code>$password['hash']</code>. So I so a second lookup on the database to see if the\nusername entered and the hashed password together return a single row. If so then the user's credentials are correct.\n\n<strong>Step 4:</strong> In order to log the user in after their credentials passed I generate a random unique string and hash it:\n\n<strong>Step 5:</strong>\n\nI take the unencrypted unique string generated in the last step (<code>$random_string</code>) and set that as the value of a cookie which I call <code>active_session</code>:\n\n<strong>Step 6:</strong>\nAt the top of my <code>header.php</code> include there is this check:\n\nThe <code>get_userinfo()</code> function does a lookup on the <code>users</code> table in the database and returns an associative array which is stored in a session called <code>userinfo</code>:\n\n// first this function takes the value of the active_session cookie and hashes it to get the session_key:\n\n<pre><code>encrypt($user_chosen_password, $salt);\n\nfunction encrypt($plain_text, $salt) {\n    if(!$salt) {\n        $salt = uniqid(rand(0, 1000000));\n    }\n    return array(\n        'hash' =&gt; $salt.hash('sha512', $salt.$plain_text),\n        'salt' =&gt; $salt\n    );\n}\nencrypt($user_entered_password, $salt);\n$random_string = uniqid(rand(0, 1000000));\n$session_key = hash('sha512', $random_string);\nsetcookie('active_session', $random_string, time()+3600*48, '/');\nif(isset($_COOKIE['active_session']) &amp;&amp; !isset($_SESSION['userinfo'])) {\n   get_userinfo();\n}\nhash('sha512', $random_string);\n$_SESSION['userinfo'] = array(\n        'user_id'           =&gt; $row-&gt;user_id,\n        'username'          =&gt; $row-&gt;username,\n        'dob'               =&gt; $row-&gt;dob,\n        'country'           =&gt; $row-&gt;country,\n        'city'              =&gt; $row-&gt;city,\n        'zip'               =&gt; $row-&gt;zip,\n        'email'             =&gt; $row-&gt;email,\n        'avatar'            =&gt; $row-&gt;avatar,\n        'account_status'    =&gt; $row-&gt;account_status,\n        'timestamp'         =&gt; $row-&gt;timestamp,\n    ); \n</code></pre>\n\nNotes: The only issue I can see (and perhaps there are many others), is if the user fakes that <code>active_session</code> cookie by creating it themselves in their browser. Of course they must set as that cookie's value a string which after it is encrypted must match a record in the <code>active_sessions</code> table from where I will retrieve the <code>user_id</code> to create that session. I am not sure what the chances of this is realistically, for a user (perhaps using an automated program) to guess a string correctly which they don't know will then be sha512 encrypted and matched against the string in the <code>active_sessions</code> table in the database to get the user id to build that session.\n\nSorry for the big essay but since this is such a critical part of my site and due to my inexperience I just wanted to run it by more experienced developers to make sure it's actually safe. \n\nSo do you see any security holes in this route and how can it be improved?\n",
    "accepted_answer": "You should include some kind of timeout or failover to prevent against brute-force attacks. There are a number of ways to do this, including IP-based blocking, incremental timeouts, etc. None of these will ever <strong>stop</strong> a hacker, but they can make it much more difficult.\n\nAnother point (which you haven't mentioned, so I don't know your plan) is failure messages. Make failure messages as vague as possible. Providing an error message like 'That username exists, but the passwords did not match' might be helpful to the end-user, but it <em>kills</em> login functionality. You just converted a brute-force attack that should take <code>O(n^2)</code> time to <code>O(n)</code> + <code>O(n)</code>. Instead of needed to try every permutation in a rainbow table (for example), the hacker just tries all values for username (with a set password) first, until the failure message changes. Then, it <em>knows</em> a valid user, and just has to brute force the password.\n\nAlong those lines, you should also make sure that the same amount of time elapses when a username exists and doesn't exist. You are running additional processes when a username actually exists. As such the response time would be longer when a username exists vs when it doesn't. An incredibly skilled hacker could time page requests to find a valid username.\n\nSimilarly, you should make sure that, in addition to expiring cookies, you also expire the sessions table.\n\nLastly, in the <code>get_user_info()</code> call, you should terminate all open sessions if there are multiple concurrent, active logins. Make sure you timeout sessions after a set amount of inactivity (like 30 minutes).\n\nAlong the lines of what @Greg Hewgill mentioned, you haven't included any of the following:\n\n<ul>\n<li>SSL/encrypted connection between Server-Client</li>\n<li>Other transport protocols you much be using to process authentication (like OAuth)</li>\n</ul>\n\nYou <em>server</em> is secure, but it doesn't matter how awesomely secure your algorithm is if someone can read the data that's exchanged (MITM). You should make sure you are only communicating over an encrypted protocol. \n",
    "text_a": "I'm new to PHP and this is also my first log in system so it would be great if you guys could look over my code and see if you can spot any security holes:  note: I am sanitizing all user input although it's not shown here.  Sign Up:  Step 1: I take the password the user chose and run it through this function: Step 2: I then store the hash and the salt ($password['hash'] and $password['salt']) in the users table in the database:   Log In:  Step 1: I take the username the user entered and do a look up on the database to see if any rows are returned. On my site no 2 users can share the same username so the username field always has a unique value. If I get 1 row returned I grab the salt for that user.  Step 2: Then I run the user entered password through the encrypt function (as previously posted above) but this time I also supply the salt retrieved from the database:  Step 3: I now have the proper password to match against in this variable: $password['hash']. So I so a second lookup on the database to see if the username entered and the hashed password together return a single row. If so then the user's credentials are correct.  Step 4: In order to log the user in after their credentials passed I generate a random unique string and hash it:  Step 5:  I take the unencrypted unique string generated in the last step ($random_string) and set that as the value of a cookie which I call active_session:  Step 6: At the top of my header.php include there is this check:  The get_userinfo() function does a lookup on the users table in the database and returns an associative array which is stored in a session called userinfo:  // first this function takes the value of the active_session cookie and hashes it to get the session_key:  [CODE1]  Notes: The only issue I can see (and perhaps there are many others), is if the user fakes that active_session cookie by creating it themselves in their browser. Of course they must set as that cookie's value a string which after it is encrypted must match a record in the active_sessions table from where I will retrieve the user_id to create that session. I am not sure what the chances of this is realistically, for a user (perhaps using an automated program) to guess a string correctly which they don't know will then be sha512 encrypted and matched against the string in the active_sessions table in the database to get the user id to build that session.  Sorry for the big essay but since this is such a critical part of my site and due to my inexperience I just wanted to run it by more experienced developers to make sure it's actually safe.   So do you see any security holes in this route and how can it be improved? ",
    "tgt_text": "The get_userinfo() function does a lookup on the users table in the database and returns an associative array",
    "label": "C1",
    "code": "<code>encrypt($user_chosen_password, $salt);\n\nfunction encrypt($plain_text, $salt) {\n    if(!$salt) {\n        $salt = uniqid(rand(0, 1000000));\n    }\n    return array(\n        'hash' =&gt; $salt.hash('sha512', $salt.$plain_text),\n        'salt' =&gt; $salt\n    );\n}\nencrypt($user_entered_password, $salt);\n$random_string = uniqid(rand(0, 1000000));\n$session_key = hash('sha512', $random_string);\nsetcookie('active_session', $random_string, time()+3600*48, '/');\nif(isset($_COOKIE['active_session']) &amp;&amp; !isset($_SESSION['userinfo'])) {\n   get_userinfo();\n}\nhash('sha512', $random_string);\n$_SESSION['userinfo'] = array(\n        'user_id'           =&gt; $row-&gt;user_id,\n        'username'          =&gt; $row-&gt;username,\n        'dob'               =&gt; $row-&gt;dob,\n        'country'           =&gt; $row-&gt;country,\n        'city'              =&gt; $row-&gt;city,\n        'zip'               =&gt; $row-&gt;zip,\n        'email'             =&gt; $row-&gt;email,\n        'avatar'            =&gt; $row-&gt;avatar,\n        'account_status'    =&gt; $row-&gt;account_status,\n        'timestamp'         =&gt; $row-&gt;timestamp,\n    ); \n</code>",
    "insecure_code": "if(isset($_COOKIE['active_session']) &amp;&amp; !isset($_SESSION['userinfo'])) {\n   get_userinfo();\n}"
  },
  {
    "guid": 32,
    "question": "I have to write a Windows service that handles at some point confidential data (such as PIN codes, passwords, and so on). Those informations are needed for a very short amount of time: usually they are sent almost immediately to a smart card reader.\n\nLets consider this piece of code:\n\n<pre><code>{\n  std::string password = getPassword(); // Get the password from the user\n\n  writePasswordToSmartCard(password);\n\n  // Okay, here we don't need password anymore.\n  // We set it all to '\\0' so it doesn't stay in memory.\n  std::fill(password.begin(), password.end(), '\\0');\n}\n</code></pre>\n\nNow my concern is about compiler optimizations. Here the compiler might detect that password is about to be deleted and that changing its value at this point is useless and just remove the call.\n\nI don't expect my compiler to care about the value of future-unreferenced memory.\n\nAre my concerns legitimate ? How can I be sure that such a piece of code won't be optimized-out ?\n",
    "accepted_answer": "Yes, your concerns are legitimate. You need to use specifically designed function like <a href=\"http://msdn.microsoft.com/en-us/library/aa366877(VS.85).aspx\" rel=\"noreferrer\">SecureZeroMemory()</a> to prevent optimizations from modifying your code behavior.\n\nDon't forget that the string class should have been specifically designed for handling passwords. For example, if the class reallocates the buffer to hold a longer string it has to erase the buffer before retunring it to the memory allocator. I'm not sure, but it's likely <code>std::string</code> doesn't do that (at least by default). Using an unsuitable string handling class makes all your concerns worthless - you'll have the password copied all over the program memory befoe you even know.\n",
    "text_a": "I have to write a Windows service that handles at some point confidential data (such as PIN codes, passwords, and so on). Those informations are needed for a very short amount of time: usually they are sent almost immediately to a smart card reader.  Lets consider this piece of code:  [CODE1]  Now my concern is about compiler optimizations. Here the compiler might detect that password is about to be deleted and that changing its value at this point is useless and just remove the call.  I don't expect my compiler to care about the value of future-unreferenced memory.  Are my concerns legitimate ? How can I be sure that such a piece of code won't be optimized-out ? ",
    "tgt_text": "",
    "label": "C1",
    "code": "<code>{\n  std::string password = getPassword(); // Get the password from the user\n\n  writePasswordToSmartCard(password);\n\n  // Okay, here we don't need password anymore.\n  // We set it all to '\\0' so it doesn't stay in memory.\n  std::fill(password.begin(), password.end(), '\\0');\n}\n</code>",
    "insecure_code": "std::string password = getPassword(); // Get the password from the user"
  },
  {
    "guid": 33,
    "question": "I've been trying to get some working Java code to use for encrypting Paypal buttons. This is no easy task! Even when I get some code, from Paypal, I'm faced with errors..ugh..\n\nSo here is what I have so far, that I think will work eventually.\n\nI downloaded the Java.zip file from Paypal's website. Within it are two classes - ClientSide.java and ButtonEncryption.java\n\n<strong>The Problem -</strong> I'm getting an <code>InvalidKeyException : Illegal key size</code> error.\n\n<strong>Questions</strong><br/>\n1) How do I resolve this issue? 2) What line of code is throwing the error?\n\n<pre><code>C:\\jakarta-tomcat\\webapps\\PlanB\\WEB-INF\\classes&gt;java palmb.servlets.paypal.ButtonEncryption\njava.io.IOException: exception decrypting data - java.security.InvalidKeyException: Illegal key size\n        at org.bouncycastle.jce.provider.JDKPKCS12KeyStore.cryptData(Unknown Source)\n        at org.bouncycastle.jce.provider.JDKPKCS12KeyStore.engineLoad(Unknown Source)\n        at java.security.KeyStore.load(Unknown Source)\n        at palmb.servlets.paypal.ClientSide.getButtonEncryptionValue(ClientSide.java:63)\n        at palmb.servlets.paypal.ButtonEncryption.main(ButtonEncryption.java:81)\n</code></pre>\n\n<br/>\n\n<h1>ClientSide class</h1>\n\n<pre><code>package palmb.servlets.paypal;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.FileInputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.security.InvalidAlgorithmParameterException;\nimport java.security.KeyStore;\nimport java.security.KeyStoreException;\nimport java.security.NoSuchAlgorithmException;\nimport java.security.NoSuchProviderException;\nimport java.security.PrivateKey;\nimport java.security.UnrecoverableKeyException;\nimport java.security.cert.CertStore;\nimport java.security.cert.CertStoreException;\nimport java.security.cert.CertificateException;\nimport java.security.cert.CertificateFactory;\nimport java.security.cert.CollectionCertStoreParameters;\nimport java.security.cert.X509Certificate;\nimport java.util.ArrayList;\nimport java.util.Enumeration;\n\nimport org.bouncycastle.cms.CMSEnvelopedData;\nimport org.bouncycastle.cms.CMSEnvelopedDataGenerator;\nimport org.bouncycastle.cms.CMSException;\nimport org.bouncycastle.cms.CMSProcessableByteArray;\nimport org.bouncycastle.cms.CMSSignedData;\nimport org.bouncycastle.cms.CMSSignedDataGenerator;\nimport org.bouncycastle.openssl.PEMReader;\nimport org.bouncycastle.util.encoders.Base64;\n\n/**\n */\npublic class ClientSide \n{\n    private String  keyPath;\n    private String  certPath;\n    private String  paypalCertPath;\n    private String  keyPass;\n\n    public ClientSide( String keyPath, String certPath, String paypalCertPath, String keyPass )\n    {\n        this.keyPath = keyPath;\n        this.certPath = certPath;\n        this.paypalCertPath = paypalCertPath;\n        this.keyPass = keyPass;\n    }   \n\n    public String getButtonEncryptionValue(String _data, String _privateKeyPath, String _certPath, String _payPalCertPath,\n                                            String _keyPass) throws IOException,CertificateException,KeyStoreException,\n                                            UnrecoverableKeyException,InvalidAlgorithmParameterException,NoSuchAlgorithmException,\n                                            NoSuchProviderException,CertStoreException,CMSException {\n        _data = _data.replace(',', '\\n');\n        CertificateFactory cf = CertificateFactory.getInstance(\"X509\", \"BC\");\n\n        // Read the Private Key\n        KeyStore ks = KeyStore.getInstance(\"PKCS12\", \"BC\");\n        ks.load( new FileInputStream(_privateKeyPath), _keyPass.toCharArray() );\n\n        String keyAlias = null;\n        Enumeration aliases = ks.aliases();\n        while (aliases.hasMoreElements()) {\n            keyAlias = (String) aliases.nextElement();\n        }\n\n        PrivateKey privateKey = (PrivateKey) ks.getKey( keyAlias, _keyPass.toCharArray() );\n\n        // Read the Certificate\n        X509Certificate certificate = (X509Certificate) cf.generateCertificate( new FileInputStream(_certPath) );\n\n        // Read the PayPal Cert\n        X509Certificate payPalCert = (X509Certificate) cf.generateCertificate( new FileInputStream(_payPalCertPath) );\n\n        // Create the Data\n        byte[] data = _data.getBytes();\n\n        // Sign the Data with my signing only key pair\n        CMSSignedDataGenerator signedGenerator = new CMSSignedDataGenerator();\n\n        signedGenerator.addSigner( privateKey, certificate, CMSSignedDataGenerator.DIGEST_SHA1 );\n\n        ArrayList certList = new ArrayList();\n        certList.add(certificate);\n        CertStore certStore = CertStore.getInstance( \"Collection\", new CollectionCertStoreParameters(certList) );\n        signedGenerator.addCertificatesAndCRLs(certStore);\n\n        CMSProcessableByteArray cmsByteArray = new CMSProcessableByteArray(data);\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        cmsByteArray.write(baos);\n        System.out.println( \"CMSProcessableByteArray contains [\" + baos.toString() + \"]\" );\n\n        CMSSignedData signedData = signedGenerator.generate(cmsByteArray, true, \"BC\");\n\n        byte[] signed = signedData.getEncoded();\n\n        CMSEnvelopedDataGenerator envGenerator = new CMSEnvelopedDataGenerator();\n        envGenerator.addKeyTransRecipient(payPalCert);\n        CMSEnvelopedData envData = envGenerator.generate( new CMSProcessableByteArray(signed),\n                CMSEnvelopedDataGenerator.DES_EDE3_CBC, \"BC\" );\n\n        byte[] pkcs7Bytes = envData.getEncoded();\n\n\n        return new String( DERtoPEM(pkcs7Bytes, \"PKCS7\") );\n\n    }\n\n    public static byte[] DERtoPEM(byte[] bytes, String headfoot) \n    {\n        ByteArrayOutputStream pemStream = new ByteArrayOutputStream();\n        PrintWriter writer = new PrintWriter(pemStream);\n\n        byte[] stringBytes = Base64.encode(bytes);\n\n        System.out.println(\"Converting \" + stringBytes.length + \" bytes\");\n\n        String encoded = new String(stringBytes);\n\n        if (headfoot != null) {\n            writer.print(\"-----BEGIN \" + headfoot + \"-----\\n\");\n        }\n\n        // write 64 chars per line till done\n        int i = 0;\n        while ((i + 1) * 64 &lt; encoded.length()) {\n            writer.print(encoded.substring(i * 64, (i + 1) * 64));\n            writer.print(\"\\n\");\n            i++;\n        }\n        if (encoded.length() % 64 != 0) {\n            writer.print(encoded.substring(i * 64)); // write remainder\n            writer.print(\"\\n\");\n        }\n        if (headfoot != null) {\n            writer.print(\"-----END \" + headfoot + \"-----\\n\");\n        }\n        writer.flush();\n        return pemStream.toByteArray();\n    }\n\n}\n</code></pre>\n\n<br/>\n\n<h1>ButtonEncryption class</h1>\n\n<pre><code>package palmb.servlets.paypal;\n\n//import com.paypal.crypto.sample.*;\n\nimport palmb.servlets.paypal.ClientSide;\n\nimport java.io.*;\nimport java.security.InvalidAlgorithmParameterException;\nimport java.security.KeyStoreException;\nimport java.security.NoSuchAlgorithmException;\nimport java.security.NoSuchProviderException;\nimport java.security.Security;\nimport java.security.UnrecoverableKeyException;\nimport java.security.cert.CertStoreException;\nimport java.security.cert.CertificateException;\nimport org.bouncycastle.cms.CMSException;\n\n/**\n */\npublic class ButtonEncryption {\n\n\n    //path to public cert\n    private static String certPath = \"C:/jakarta-tomcat/webapps/PlanB/Certs/public-cert.pem\";\n\n    //path to private key in PKCS12 format\n    private static String keyPath = \"C:/jakarta-tomcat/webapps/PlanB/Certs/my_pkcs12.p12\";\n\n    //path to Paypal's public cert\n    private static String paypalCertPath = \"C:/jakarta-tomcat/webapps/PlanB/Certs/paypal_cert_pem.txt\";\n\n    //private key password\n    private static String keyPass = \"password\"; //will be replaced with actual password when compiled and executed\n\n    //the button command, properties/parameters\n    private static String cmdText = \"cmd=_xclick\\nbusiness=buyer@hotmail.com\\nitem_name=vase\\nitemprice=25.00\";  //cmd=_xclick,business=sample@paypal.com,amount=1.00,currency_code=USD\n\n    //output file for form code\n    private static String output = \"test.html\";\n\n\n    public static void main(String[] args) \n    {\n        Security.addProvider(new org.bouncycastle.jce.provider.BouncyCastleProvider()); \n\n\n        String stage = \"sandbox\";\n\n        try \n        {\n            ClientSide client_side = new ClientSide( keyPath, certPath, paypalCertPath, keyPass );\n\n            String result = client_side.getButtonEncryptionValue( cmdText, keyPath, certPath, paypalCertPath, keyPass );\n\n            File outputFile = new File( output );\n            if ( outputFile.exists() )\n                outputFile.delete();\n\n            if ( result != null &amp;&amp; result != \"\")\n            {\n                try {        \n                    OutputStream fout= new FileOutputStream( output );\n                    OutputStream bout= new BufferedOutputStream(fout);\n                    OutputStreamWriter out = new OutputStreamWriter(bout, \"US-ASCII\");\n\n                    out.write( \"&lt;form action=\\\"https://www.\" );\n                    out.write( stage );\n                    out.write( \"paypal.com/cgi-bin/webscr\\\" method=\\\"post\\\"&gt;\" );  \n                    out.write( \"&lt;input type=\\\"hidden\\\" name=\\\"cmd\\\" value=\\\"_s-xclick\\\"&gt;\" );  ;\n                    out.write( \"&lt;input type=\\\"image\\\" src=\\\"https://www.\" );\n                    out.write( stage );\n                    out.write( \"paypal.com/en_US/i/btn/x-click-but23.gif\\\" border=\\\"0\\\" name=\\\"submit\\\" \" );\n                    out.write( \"alt=\\\"Make payments with PayPal - it's fast, free and secure!\\\"&gt;\" );\n                    out.write( \"&lt;input type=\\\"hidden\\\" name=\\\"encrypted\\\" value=\\\"\" );\n                    out.write( result );\n                    out.write( \"\\\"&gt;\" );\n                    out.write( \"&lt;/form&gt;\");\n\n                    out.flush();  // Don't forget to flush!\n                    out.close();\n                  }\n                  catch (UnsupportedEncodingException e) {\n                    System.out.println(\n                     \"This VM does not support the ASCII character set.\"\n                    );\n                  }\n                  catch (IOException e) {\n                    System.out.println(e.getMessage());        \n                  }\n            }\n        } \n        catch (NoSuchAlgorithmException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        } \n        catch (NoSuchProviderException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        } \n        catch (IOException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        } \n        catch (CMSException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        } \n        catch (CertificateException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        } \n        catch (KeyStoreException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        } \n        catch (UnrecoverableKeyException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        } \n        catch (InvalidAlgorithmParameterException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        } \n        catch (CertStoreException e) \n        {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n    }\n}\n</code></pre>\n\n<br/>\n\n<h1>Edited : info about keys/certificates</h1>\n\nI generated the Private Key and Public Certificate with OpenSSL via the following commands.\n<br/>\n<strong>Private Key</strong><br/>\nopenssl genrsa -out private-key.pem 1024\n<br/>\n<strong>Public Certificate</strong>\n<br/>openssl req -new -key private-key.pem -x509 -days 1095 -out public-cert.pem\n<br/>\n<strong>Created PKCS12 File</strong><br/>\nopenssl pkcs12 -export -in public-cert.pem -inkey private-key.pem -out my_pkcs12.p12\n\n<br/>\nAdditionally, I had to download the Paypal Public Certificate from the Paypal website.\n\n<br/>\n\n<h1>Edited - adding compilation warnings - BouncyCastle</h1>\n\n<pre><code>C:\\jakarta-tomcat\\webapps\\PlanB\\WEB-INF\\classes&gt;javac .\\palmb\\servlets\\paypal\\ClientSide.java -Xlint\n.\\palmb\\servlets\\paypal\\ClientSide.java:85: warning: [deprecation] addSigner(java.security.PrivateKey,java.security.cert.X509Certificate,java.lang.String) in org.bouncycastle.cms.CMSSignedDataGenerator has been deprecated\n                signedGenerator.addSigner( privateKey, certificate, CMSSignedDat\naGenerator.DIGEST_SHA1 );\n                               ^\n.\\palmb\\servlets\\paypal\\ClientSide.java:88: warning: [unchecked] unchecked call\nto add(E) as a member of the raw type java.util.ArrayList\n                certList.add(certificate);\n                            ^\n.\\palmb\\servlets\\paypal\\ClientSide.java:90: warning: [deprecation] addCertificatesAndCRLs(java.security.cert.CertStore) in org.bouncycastle.cms.CMSSignedGenerat\nor has been deprecated\n                signedGenerator.addCertificatesAndCRLs(certStore);\n                               ^\n.\\palmb\\servlets\\paypal\\ClientSide.java:97: warning: [deprecation] generate(org.\nbouncycastle.cms.CMSProcessable,boolean,java.lang.String) in org.bouncycastle.cm\ns.CMSSignedDataGenerator has been deprecated\n                CMSSignedData signedData = signedGenerator.generate(cmsByteArray, true, \"BC\");\n                                                          ^\n.\\palmb\\servlets\\paypal\\ClientSide.java:102: warning: [deprecation] addKeyTransR\necipient(java.security.cert.X509Certificate) in org.bouncycastle.cms.CMSEnvelope\ndGenerator has been deprecated\n                envGenerator.addKeyTransRecipient(payPalCert);\n                            ^\n.\\palmb\\servlets\\paypal\\ClientSide.java:103: warning: [deprecation] generate(org.bouncycastle.cms.CMSProcessable,java.lang.String,java.lang.String) in org.bouncycastle.cms.CMSEnvelopedDataGenerator has been deprecated\n                CMSEnvelopedData envData = envGenerator.generate( new CMSProcess\nableByteArray(signed),\n                                                       ^\n6 warnings\n</code></pre>\n\n<br/>\n\n<h1>JCE policy file installation steps</h1>\n\nThese are the steps I took to installing the JCE Unlimited Strength Policy files:<br/>\n1) Went to <a href=\"https://cds.sun.com/is-bin/INTERSHOP.enfinity/WFS/CDS-CDS_Developer-Site/en_US/-/USD/ViewProductDetail-Start?ProductRef=jce_policy-6-oth-JPR@CDS-CDS_Developer\" rel=\"noreferrer\">Java JCE Download</a> Page on Oracle.<br/>\n2) Extracted files from zip.<br/>\n3) Placed local_policy.jar and US_export_policy.jar files in C:\\Java\\jdk1.6.0_22\\jre\\lib\\security folder. <br/>\nNote: C:\\Java\\jdk1.6.0_22 is set as %JAVA_HOME% \n<br/>\n4) Updated system classpath to include location of jars.\n<br/>\nNote: There are other files, that came with the JDK 1.6 within the security folder, including : java.policy, java.security, javaws.policy, trusted.libraries - but those probably have nothing to do with the JCE files, right?\n<br/>\n\n<hr/>\n\n<h1>Edit 6/23/2011 - results after further configuration</h1>\n\nI went to Bouncy Castle page at <a href=\"http://www.bouncycastle.org/specifications.html#install\" rel=\"noreferrer\">http://www.bouncycastle.org/specifications.html#install</a><br/>\nScroll down to <strong>5.0 Bouncy Castle Provider</strong> then read info under <strong>5.1 Example</strong>. It makes mention of adding a parameter for the Bouncy Castle Provider to the <code>java.security</code> file. My file is under C:\\Java\\jdk1.6.0_22\\jre\\lib\\security.<br/><br/>\nI added the following line to my file - <code>security.provider.10=org.bouncycastle.jce.provider.BouncyCastleProvider</code> <br/>\n\nIn addition, I discovered that I hadn't added the Bouncy Castle jars to the classpath, so I went ahead and did so.\n<br/>\n\nNow after making these changes, recompiling and attempting to execute <code>ClientSide.java</code> I'm given the same exception : but maybe the focus should be on the part of the exception where it says this about bouncycastle provider -\n\n<pre><code>at org.bouncycastle.jce.provider.JDKPKCS12KeyStore.cryptData(Unknown Source)\nat org.bouncycastle.jce.provider.JDKPKCS12KeyStore.engineLoad(Unknown Source)\n</code></pre>\n\n<strong>@PeteyB - I'm certain that I installed the policy files correctly. Based on what I've stated here, is there anything else you can suggest I try? Can you look at the Bouncy Castle site @ <a href=\"http://www.bouncycastle.org/specifications.html#install\" rel=\"noreferrer\">http://www.bouncycastle.org/specifications.html#install</a> and see if there is something I'm missing?</strong>\n",
    "accepted_answer": "So the problem must be with your JCE Unlimited Strength installation. \n\nBe sure you overwrite the <code>local_policy.jar</code> and <code>US_export_policy.jar</code> in both your JDK's <code>jdk1.6.0_25\\jre\\lib\\security\\</code> and in your JRE's <code>lib\\security\\</code> folder.\n\nIn my case I would place the new .jars in:\n\n<code>C:\\Program Files\\Java\\jdk1.6.0_25\\jre\\lib\\security</code>\n\nand\n\n<code>C:\\Program Files\\Java\\jre6\\lib\\security</code>\n\n<hr>\n\nIf you are running <strong>Java 8</strong> and you encounter this issue. Below steps should help!\n\nGo to your JRE installation (e.g - jre1.8.0_181\\lib\\security\\policy\\unlimited) copy <strong>local_policy.jar</strong> and replace it with 'local_policy.jar' in your JDK installation directory (e.g - jdk1.8.0_141\\jre\\lib\\security). \n",
    "text_a": "I've been trying to get some working Java code to use for encrypting Paypal buttons. This is no easy task! Even when I get some code, from Paypal, I'm faced with errors..ugh..  So here is what I have so far, that I think will work eventually.  I downloaded the Java.zip file from Paypal's website. Within it are two classes - ClientSide.java and ButtonEncryption.java  The Problem - I'm getting an [CODE1] error.  Questions 1) How do I resolve this issue? 2) What line of code is throwing the error?  [CODE2]    ClientSide class  [CODE3]    ButtonEncryption class  [CODE4]    Edited : info about keys/certificates  I generated the Private Key and Public Certificate with OpenSSL via the following commands.  Private Key openssl genrsa -out private-key.pem 1024  Public Certificate openssl req -new -key private-key.pem -x509 -days 1095 -out public-cert.pem  Created PKCS12 File openssl pkcs12 -export -in public-cert.pem -inkey private-key.pem -out my_pkcs12.p12   Additionally, I had to download the Paypal Public Certificate from the Paypal website.    Edited - adding compilation warnings - BouncyCastle  [CODE5]    JCE policy file installation steps  These are the steps I took to installing the JCE Unlimited Strength Policy files: 1) Went to Java JCE Download Page on Oracle. 2) Extracted files from zip. 3) Placed local_policy.jar and US_export_policy.jar files in C:\\Java\\jdk1.6.0_22\\jre\\lib\\security folder.  Note: C:\\Java\\jdk1.6.0_22 is set as %JAVA_HOME%   4) Updated system classpath to include location of jars.  Note: There are other files, that came with the JDK 1.6 within the security folder, including : java.policy, java.security, javaws.policy, trusted.libraries - but those probably have nothing to do with the JCE files, right?     Edit 6/23/2011 - results after further configuration  I went to Bouncy Castle page at http://www.bouncycastle.org/specifications.html#install Scroll down to 5.0 Bouncy Castle Provider then read info under 5.1 Example. It makes mention of adding a parameter for the Bouncy Castle Provider to the java.security file. My file is under C:\\Java\\jdk1.6.0_22\\jre\\lib\\security. I added the following line to my file - security.provider.10=org.bouncycastle.jce.provider.BouncyCastleProvider   In addition, I discovered that I hadn't added the Bouncy Castle jars to the classpath, so I went ahead and did so.   Now after making these changes, recompiling and attempting to execute ClientSide.java I'm given the same exception : but maybe the focus should be on the part of the exception where it says this about bouncycastle provider -  [CODE6]  @PeteyB - I'm certain that I installed the policy files correctly. Based on what I've stated here, is there anything else you can suggest I try? Can you look at the Bouncy Castle site @ http://www.bouncycastle.org/specifications.html#install and see if there is something I'm missing? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 34,
    "question": "From what i understand the purpose of the Authorization Code flow is to exchange the auth code for access token. This exchange happens between the server which serves the page and authorization server so that the actual access token is not exposed to the client user.\n\nHow should the page server store the access token once it is obtained? I was learning from a Pluralsight example in which there is this part of code:\n\n<pre><code>    public static HttpClient GetClient()\n    {\n        HttpClient client = new HttpClient();\n        var accessToken = RequestAccessTokenAuthorizationCode();\n        client.SetBearerToken(accessToken);\n\n        client.BaseAddress = new Uri(IdentityConstants.API);\n        client.DefaultRequestHeaders.Accept.Clear();\n        client.DefaultRequestHeaders.Accept.Add(\n            new MediaTypeWithQualityHeaderValue(\"application/json\"));\n\n        return client;\n    }\n\n    private static string RequestAccessTokenAuthorizationCode()\n    {\n        // did we store the token before?\n        var cookie = HttpContext.Current.Request.Cookies.Get(\"ClientMVCCookie.AuthCode\");\n        if (cookie != null &amp;&amp; cookie[\"access_token\"] != null &amp;&amp; !string.IsNullOrEmpty(cookie[\"access_token\"]))\n        {\n            return cookie[\"access_token\"];\n        }\n\n        // no token found - request one\n\n        // we'll pass through the URI we want to return to as state\n        var state = HttpContext.Current.Request.Url.OriginalString;\n\n        var authorizeRequest = new IdentityModel.Client.AuthorizeRequest(\n            IdentityConstants.AuthEndoint);\n\n        var url = authorizeRequest.CreateAuthorizeUrl(IdentityConstants.MVCClientSecret, \"code\", \"management secret\",\n            IdentityConstants.MVCAuthCodeCallback, state);\n\n        HttpContext.Current.Response.Redirect(url);\n\n        return null;\n    }\n}\n</code></pre>\n\nThis will cause each request to check if there is an access token stored in the cookie. If not then the flow will be initiated. The callback looks like this:\n\n<pre><code>public class CallbackController : Controller\n{\n    // GET: STSCallback\n    public async Task&lt;ActionResult&gt; Index()\n    {\n        // get the authorization code from the query string\n        var authCode = Request.QueryString[\"code\"];\n\n        // with the auth code, we can request an access token.\n        var client = new TokenClient(\n            IdentityConstants.TokenEndoint,\n            \"mvc_client_auth_code\",\n             IdentityConstants.MVCClientSecretAuthCode);\n\n        var tokenResponse = await client.RequestAuthorizationCodeAsync(\n            authCode,\n            IdentityConstants.MVCAuthCodeCallback);\n\n        // we save the token in a cookie for use later on\n        var cookie = Response.Cookies[\"ClientMVCCookie.AuthCode\"];\n        cookie.Expires = DateTime.Now.AddMinutes(1);\n        cookie[\"access_token\"] = tokenResponse.AccessToken;\n\n        // get the state (uri to return to)\n        var state = Request.QueryString[\"state\"];\n\n        // redirect to the URI saved in state\n        return Redirect(state);\n    }\n}\n</code></pre>\n\nDoesn't storing the access token in the cookie defeath the whole purpose of the authorization code flow? The cookie will be transmitted to the client browser thus exposing it to the client? Am i missing something? It this is not the correct way to store the token, how should it be stored?\n",
    "accepted_answer": "The client, in OAuth terminology, is the component that makes requests to the resource server, in your case, the client is the server of a web application (NOT the browser).\nTherefore, the access token should be stored on the web application server only. It should not be exposed to the browser, and it doesn't need to, because the browser never makes any direct requests to the resource server. It talks to the web application server instead, which in turn makes requests to the resource server using the access token.\nHow the browser authenticates itself with the web application server has nothing to do with OAuth 2.0. For example, it might be a regular session cookie, and the web application server might associate each session or each user with an access token.\nThe token request, which exchanges the authentication code for an access token, is done by the web application server, and the web application server should authenticate itself with the authorization server (e.g., using a shared <code>client_secret</code>).\nAuthorization code flow ensures that the client can be authenticated, which protects against malicious clients posing as legitimate clients. Not all web application clients have a server component, and in some cases, requests to the resource server are made directly by JavaScript code in the browser. In such situations, the browser is the client, and the access token must be stored by the browser (in a JavaScript variable, local storage or a cookie). In this case, the client cannot be authenticated (but a reasonable amount of security may be achieved by using TLS and the server redirecting only to registered endpoint URLs).\nRecommended reading regarding OAuth 2.0 security: <a href=\"https://www.rfc-editor.org/rfc/rfc6819#section-4.3.3\" rel=\"noreferrer\">https://www.rfc-editor.org/rfc/rfc6819#section-4.3.3</a> (RFC 6819)\n",
    "text_a": "From what i understand the purpose of the Authorization Code flow is to exchange the auth code for access token. This exchange happens between the server which serves the page and authorization server so that the actual access token is not exposed to the client user.  How should the page server store the access token once it is obtained? I was learning from a Pluralsight example in which there is this part of code:  [CODE1]  This will cause each request to check if there is an access token stored in the cookie. If not then the flow will be initiated. The callback looks like this:  [CODE2]  Doesn't storing the access token in the cookie defeath the whole purpose of the authorization code flow? The cookie will be transmitted to the client browser thus exposing it to the client? Am i missing something? It this is not the correct way to store the token, how should it be stored? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 35,
    "question": "I am inheriting from <strong>System.Web.Http.AuthorizeAttribute</strong> to create a custom authorization/authentication routine to meet some unusual requirements for a web application developed using ASP.NET MVC 4. This adds security to the Web API used for Ajax calls from the web client. The requirements are:\n\n<ol>\n<li>The user must logon each time they perform a transaction to verify\nsomeone else has not walked up to the workstation after someone has\nlogged on and walked away.</li>\n<li>Roles cannot be assigned to the web service methods at program time.\nThey must be assigned at run time so that an administrator can\nconfigure this. This information is stored in the system database.</li>\n</ol>\n\nThe web client is a <a href=\"http://en.wikipedia.org/wiki/Single-page_application\">single page application (SPA)</a> so the typical forms authentication does not work so well, but I am trying reuse as much of the ASP.NET security framework as I can to meet the requirements.  The customized <strong>AuthorizeAttribute</strong> works great for requirement 2 on determining what roles are associated with a web service method. I accept three parameters, application name, resource name and operation to determine which roles are associated with a method.\n\n<pre><code>public class DoThisController : ApiController\n{\n    [Authorize(Application = \"MyApp\", Resource = \"DoThis\", Operation = \"read\")]\n    public string GetData()\n    {\n        return \"We did this.\";\n    }\n}\n</code></pre>\n\nI override the <strong>OnAuthorization</strong> method to get the roles and authenticate the user. Since the user has to be authenticated for each transaction I reduce the back and forth chatter by performing authentication and authorization in the same step.  I get the users credentials from the web client by using basic authentication which passes the encrypted credentials in the HTTP header. So my <strong>OnAuthorization</strong> method looks like this:\n\n<pre><code>public override void OnAuthorization(HttpActionContext actionContext)\n{\n\n     string username;\n     string password;\n     if (GetUserNameAndPassword(actionContext, out username, out password))\n     {\n         if (Membership.ValidateUser(username, password))\n         {\n             FormsAuthentication.SetAuthCookie(username, false);\n             base.Roles = GetResourceOperationRoles();\n         }\n         else\n         {\n             FormsAuthentication.SignOut();\n             base.Roles = \"\";\n         }\n     }\n     else\n     {\n         FormsAuthentication.SignOut();\n         base.Roles = \"\";\n     }\n     base.OnAuthorization(actionContext);\n }\n</code></pre>\n\n<strong>GetUserNameAndPassword</strong> retrieves the credentials from the HTTP header. I then use the <strong>Membership.ValidateUser</strong> to validate the credentials. I have a custom membership provider and role provider plugged in to hit a custom database. If the user is authenticated I then retrieve the roles for the resource and operation. From there I use the base <strong>OnAuthorization</strong> to complete the authorization process.  Here is where it breaks down.\n\nIf the user is authenticated I use the standard forms authentication methods to log the user in (FormsAuthentication.SetAuthCookie) and if they fail I log them out (FormsAuthentication.SignOut).  But the problem seems to be that base <strong>OnAuthorization</strong> class does not have access to <strong>Principal</strong> that is updated so that <strong>IsAuthenticated</strong> is set to the correct value. It is always one step behind. And my guess is that it is using some cached value that does not get updated until there is a round trip to the web client.\n\nSo all of this leads up to my specific question which is, is there another way to set <strong>IsAuthenticated</strong> to the correct value for the current <strong>Principal</strong> without using cookies? It seems to me that cookies do not really apply in this specific scenario where I have to authenticate every time.  The reason I know <strong>IsAuthenticated</strong> is not set to the correct value is I also override the <strong>HandleUnauthorizedRequest</strong> method to this:\n\n<pre><code> protected override void HandleUnauthorizedRequest(HttpActionContext filterContext)\n {\n     if (((System.Web.HttpContext.Current.User).Identity).IsAuthenticated)\n     {\n         filterContext.Response = new HttpResponseMessage(System.Net.HttpStatusCode.Forbidden);\n     }\n     else\n     {\n         base.HandleUnauthorizedRequest(filterContext);\n     }\n }\n</code></pre>\n\nThis allows me to return a status code of Forbidden to the web client if the failure was because of authorization instead of authentication and it can respond accordingly.\n\nSo what is the proper way to set <strong>IsAuthenticated</strong> for the current <strong>Principle</strong> in this scenario?\n",
    "accepted_answer": "The best solution for my scenario appears to be bypass the base <strong>OnAuthorization</strong> completely. Since I have to authenticate each time cookies and caching the principle are not of much use. So here is the solution I came up with:\n\n<pre><code>public override void OnAuthorization(HttpActionContext actionContext)\n{\n    string username;\n    string password;\n\n    if (GetUserNameAndPassword(actionContext, out username, out password))\n    {\n        if (Membership.ValidateUser(username, password))\n        {\n            if (!isUserAuthorized(username))\n                actionContext.Response = \n                    new HttpResponseMessage(System.Net.HttpStatusCode.Forbidden);\n        }\n        else\n        {\n            actionContext.Response = \n                new HttpResponseMessage(System.Net.HttpStatusCode.Unauthorized);\n        }\n    }\n    else\n    {\n        actionContext.Response = \n            new HttpResponseMessage(System.Net.HttpStatusCode.BadRequest);\n    }\n}\n</code></pre>\n\nI developed my own method for validating the roles called <strong>isUserAuthorized</strong> and I am not using the base <strong>OnAuthorization</strong> any more since it checks the current <strong>Principle</strong> to see if it <strong>isAuthenticated</strong>.  <strong>IsAuthenticated</strong> only allows gets so I am not sure how else to set it, and I do not seem to need the current <strong>Principle</strong>.  Tested this out and it works fine.\n\nStill interested if anyone has a better solution or can see any issues with this this one.\n",
    "text_a": "I am inheriting from System.Web.Http.AuthorizeAttribute to create a custom authorization/authentication routine to meet some unusual requirements for a web application developed using ASP.NET MVC 4. This adds security to the Web API used for Ajax calls from the web client. The requirements are:   The user must logon each time they perform a transaction to verify someone else has not walked up to the workstation after someone has logged on and walked away. Roles cannot be assigned to the web service methods at program time. They must be assigned at run time so that an administrator can configure this. This information is stored in the system database.   The web client is a single page application (SPA) so the typical forms authentication does not work so well, but I am trying reuse as much of the ASP.NET security framework as I can to meet the requirements.  The customized AuthorizeAttribute works great for requirement 2 on determining what roles are associated with a web service method. I accept three parameters, application name, resource name and operation to determine which roles are associated with a method.  [CODE1]  I override the OnAuthorization method to get the roles and authenticate the user. Since the user has to be authenticated for each transaction I reduce the back and forth chatter by performing authentication and authorization in the same step.  I get the users credentials from the web client by using basic authentication which passes the encrypted credentials in the HTTP header. So my OnAuthorization method looks like this:  [CODE2]  GetUserNameAndPassword retrieves the credentials from the HTTP header. I then use the Membership.ValidateUser to validate the credentials. I have a custom membership provider and role provider plugged in to hit a custom database. If the user is authenticated I then retrieve the roles for the resource and operation. From there I use the base OnAuthorization to complete the authorization process.  Here is where it breaks down.  If the user is authenticated I use the standard forms authentication methods to log the user in (FormsAuthentication.SetAuthCookie) and if they fail I log them out (FormsAuthentication.SignOut).  But the problem seems to be that base OnAuthorization class does not have access to Principal that is updated so that IsAuthenticated is set to the correct value. It is always one step behind. And my guess is that it is using some cached value that does not get updated until there is a round trip to the web client.  So all of this leads up to my specific question which is, is there another way to set IsAuthenticated to the correct value for the current Principal without using cookies? It seems to me that cookies do not really apply in this specific scenario where I have to authenticate every time.  The reason I know IsAuthenticated is not set to the correct value is I also override the HandleUnauthorizedRequest method to this:  [CODE3]  This allows me to return a status code of Forbidden to the web client if the failure was because of authorization instead of authentication and it can respond accordingly.  So what is the proper way to set IsAuthenticated for the current Principle in this scenario? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 36,
    "question": "I want to store a secret key (\"abc123\") that I will use in the header of my REST API requests.  My server will check this secret key. If it matches \"abc123\", then allow the request to be made.\n\nI'm thinking about a simple solution like:\n\n<pre><code>let secret = \"abc123\" \n</code></pre>\n\nBut are there going to be any downfalls to this?\n",
    "accepted_answer": "Crazy as it sounds, this is probably the best solution. Everything else is more complicated, but not much more secure. Any fancy obfuscation techniques you use are just going to be reverse engineered almost as quickly as they'll find this key. But this static key solution, while wildly insecure, is nearly as secure than the other solutions while imposing nearly no extra complexity. I love it.\n\nIt will be broken almost immediately, but so will all the other solutions. So keep it simple.\n\nThe one thing that you really want to do here is use HTTPS and <a href=\"https://github.com/rnapier/RNPinnedCertValidator\" rel=\"noreferrer\">pin your certificates</a>. And I'd pick a long, random key that isn't a word. Ideally, it should be a completely random string of bytes, stored as raw values (not characters) so that it doesn't stand out so obviously in your binary. If you want to get crazy, apply a SHA256 to it before sending it (so the actual key never shows up in your binary). Again, this is trivial to break, but it's easy, and won't waste a lot of time developing.\n\nIt is unlikely that any effort longer than an hour will be worth the trouble to implement this feature. If you want lots more on the topic, see <a href=\"https://stackoverflow.com/questions/9181186/secure-https-encryption-for-iphone-app-to-webpage\">Secure https encryption for iPhone app to webpage</a> and its links. \n",
    "text_a": "I want to store a secret key (\"abc123\") that I will use in the header of my REST API requests.  My server will check this secret key. If it matches \"abc123\", then allow the request to be made.  I'm thinking about a simple solution like:  [CODE1]  But are there going to be any downfalls to this? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 37,
    "question": "On my Java EE6, REST service, I want to use authentication tokens for login from mobile devices, User will send their username, password and server will send back a token, which will be used to authorize the user on their further requests for a given time.\nCan I simply create a token myself like this?(I guess I do not need to encrypt this since I will use HTTPS.)\n<pre><code>String token = UUID.randomUUID().toString().toUpperCase() \n            + &quot;|&quot; + &quot;userid&quot; + &quot;|&quot;\n            + cal.getTimeInMillis();\n</code></pre>\nOr there is a more standard way to create these tokens? maybe it exists in one of the API`s?\n",
    "accepted_answer": "The scheme you are proposing effectively allows a client unlimited access to your service. After an initial login, the UID and 'userid' will be made available to the client, which can be simply combined with an always valid timestamp.\n\nIf you need a service with 'login' and a session token, then why not just use an HttpSession?\n",
    "text_a": "On my Java EE6, REST service, I want to use authentication tokens for login from mobile devices, User will send their username, password and server will send back a token, which will be used to authorize the user on their further requests for a given time. Can I simply create a token myself like this?(I guess I do not need to encrypt this since I will use HTTPS.) [CODE1] Or there is a more standard way to create these tokens? maybe it exists in one of the API`s? ",
    "tgt_text": "create a token myself like this with HTTPS",
    "label": "C1",
    "code": "<code>String token = UUID.randomUUID().toString().toUpperCase() \n            + &quot;|&quot; + &quot;userid&quot; + &quot;|&quot;\n            + cal.getTimeInMillis();\n</code>",
    "insecure_code": "String token = UUID.randomUUID().toString().toUpperCase() \n            + &quot;|&quot; + &quot;userid&quot; + &quot;|&quot;\n            + cal.getTimeInMillis();"
  },
  {
    "guid": 38,
    "question": "I'm making SPA, and decided to use JWT for Authentication/Authorization, and I have read some blogs about Tokens vs Cookies. I understand how cookie authorization works, and understand how basic token authorization works. The problem is, I don't see how refresh token fits into it, seems to me it decreases security. Let me explain, as I see it:\n<h1>Cookie approach</h1>\nWhen you authenticate user via username &amp; password, you create session ID associated with that user. And set it as cookie, every time that client calls to your server it sends that cookie, and server can look up associated user in database or some other server side storage.\n<ul>\n<li>This approach is vulnerable to CSRF (Cross Site Request Forgery) To prevent CSRF You can use tokens with cookie\n</li>\n<li>Server also needs to constantly look up storage to see to what user, the cookie points.\n</li>\n</ul>\n<h1>Token approach</h1>\nWhen you authenticate user via username &amp; password, you create a signed Token, with expiration date, email address or userID, role, etc. in payload. For security tokens should have short expiration time. Tokens can be stored anywhere Local storage, Session storage, cookies. I will be using local storage, or session storage, to prevent XSRF.\n<ul>\n<li>This vulnerable to XSS (Cross Site Scripting), but you can prevent this by validating HTML input.</li>\n<li>Because tokens have short lifecycle, user must login again, when token expires.</li>\n</ul>\n<h2>Access Token &amp; Refresh Token</h2>\nSo I want to use Refresh tokens to prevent user from needing to login constantly. So lets say on Authentication, I give user Access token and Refresh token, when users Access token expires, user can use Refresh token to get New Access token, <strong>This is what I don't get.</strong>\n<ul>\n<li>lets say I store access token in local storage. If I also store Refresh token in local storage, I don't see any use for it. Because if attacker can access local storage and get Access token he can also get Refresh token. So in this case why not just make Access token long lived.</li>\n<li>If you store Refresh token as a cookie, it is vulnerable to XSRF, and then attacker can get new access token, and use that. Also at this point, why not just use Cookie authorization ? Because you already have to look up local storage to for refresh token, though this will happen less frequently than with pure cookie authorization.</li>\n</ul>\n<h1>What's the best practice ?</h1>\nCurrently I'm thinking about using:\n<ul>\n<li>Access Token (local storage, short lived)</li>\n<li>Refresh Token (Cookie, Long lived)</li>\n<li>Token for Refresh Token (To protect against XSFR, Local storage, expires after one use)</li>\n</ul>\nLet's say it looks like this:\n<pre><code>  +--------+                                           +---------------+\n  |        |------------ Authorization Grant ---------&gt;|               |\n  |        |                                           |               |\n  |        |&lt;--------------- Access Token -------------|               |\n  |        |               &amp; Refresh Token (cookie)    |               |\n  |        |               &amp; XSRF Token                |               |\n  |        |                                           |               |\n  |        |                                           |               |\n  |        |--------- Access Token -------------------&gt;|               |\n  |        |                                           |               |\n  |        |&lt;----- Protected Resource -----------------|               |\n  | Client |                                           |     Server    |\n  |        |--------- Access Token -------------------&gt;|               |\n  |        |                                           |               |\n  |        |&lt;----- Invalid Token Error ----------------|               |\n  |        |                                           |               |\n  |        |                                           |               |\n  |        |---------------- Refresh Token -----------&gt;|               |\n  |        |               &amp; XSRF Token                |               |\n  |        |                                           |               |\n  |        |&lt;--------------- Access Token -------------|               |\n  |        |               &amp; XSRF Token                |               |\n  +--------+               &amp; Optional Refresh Token    +---------------+\n</code></pre>\nServer would issue new XSRF Token every time Refresh token is used(after one XSRF token is used it stops working and server issues new one). <strong>What you think about this implementation ?</strong> In my eyes this limits server lookups to database, as it uses access tokens, access tokens is short lived, and user don't have to login constantly as it uses refresh token/cookie witch is protected by XSRF token.\n<strong>Is this OK ?</strong>\nThanks !\n",
    "accepted_answer": "<h1>Regarding access token and refresh token</h1>\nConsider the access token to be a &quot;dirty&quot; token. Token you share a lot. I does not have to be one server you pass the token to, can be many. Because of this the attack surface rises. If one server does something stupid like writing tokens into server logs and then exposing the logs to the world, you want to limit the negative impact, therefore the access tokens are short lived, to limit the time the attacker can do something malicious.\nOn the other hand a refresh token is a &quot;clean&quot; token. Something you store for yourself to remember and use it only if you must. Of course if the attacker gains physical access to your computer and the user agent, then it is game over. But here we try to protect from the remote attacker. The refresh token should only be used when talking to an auth server or an auth endpoint. If you decide to make it a cookie - you can - just remember to limit the directory path to just the REST endpoints the token is to be passed to.\n<h1>Regarding your solution</h1>\nIt looks good to my eye. Maybe I would not implement the XSRF Token just to save effort. I mean, what is the worst thing that can happen, if someone tries to attack over CSRF? He might be able to make you refresh your token. But the token will not be exposed to the attacker only because of CSRF.\n<h1>One more thing</h1>\nI like your question. It is really well written! : )\n",
    "text_a": "I'm making SPA, and decided to use JWT for Authentication/Authorization, and I have read some blogs about Tokens vs Cookies. I understand how cookie authorization works, and understand how basic token authorization works. The problem is, I don't see how refresh token fits into it, seems to me it decreases security. Let me explain, as I see it: Cookie approach When you authenticate user via username &amp; password, you create session ID associated with that user. And set it as cookie, every time that client calls to your server it sends that cookie, and server can look up associated user in database or some other server side storage.  This approach is vulnerable to CSRF (Cross Site Request Forgery) To prevent CSRF You can use tokens with cookie  Server also needs to constantly look up storage to see to what user, the cookie points.   Token approach When you authenticate user via username &amp; password, you create a signed Token, with expiration date, email address or userID, role, etc. in payload. For security tokens should have short expiration time. Tokens can be stored anywhere Local storage, Session storage, cookies. I will be using local storage, or session storage, to prevent XSRF.  This vulnerable to XSS (Cross Site Scripting), but you can prevent this by validating HTML input. Because tokens have short lifecycle, user must login again, when token expires.  Access Token &amp; Refresh Token So I want to use Refresh tokens to prevent user from needing to login constantly. So lets say on Authentication, I give user Access token and Refresh token, when users Access token expires, user can use Refresh token to get New Access token, This is what I don't get.  lets say I store access token in local storage. If I also store Refresh token in local storage, I don't see any use for it. Because if attacker can access local storage and get Access token he can also get Refresh token. So in this case why not just make Access token long lived. If you store Refresh token as a cookie, it is vulnerable to XSRF, and then attacker can get new access token, and use that. Also at this point, why not just use Cookie authorization ? Because you already have to look up local storage to for refresh token, though this will happen less frequently than with pure cookie authorization.  What's the best practice ? Currently I'm thinking about using:  Access Token (local storage, short lived) Refresh Token (Cookie, Long lived) Token for Refresh Token (To protect against XSFR, Local storage, expires after one use)  Let's say it looks like this: [CODE1] Server would issue new XSRF Token every time Refresh token is used(after one XSRF token is used it stops working and server issues new one). What you think about this implementation ? In my eyes this limits server lookups to database, as it uses access tokens, access tokens is short lived, and user don't have to login constantly as it uses refresh token/cookie witch is protected by XSRF token. Is this OK ? Thanks ! ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 39,
    "question": "I have a Rails 5 API app (<code>ApplicationController &lt; ActionController::API</code>). The need came up to add a simple GUI form for one endpoint of this API.\nInitially, I was getting <code>ActionView::Template::Error undefined method protect_against_forgery?</code> when I tried to render the form. I added <code>include ActionController::RequestForgeryProtection</code> and <code>protect_from_forgery with:exception </code> to that endpoint. Which solved that issue as expected.\nHowever, when I try to submit this form I get: <code>422</code> <code>Unprocessable Entity</code> <code>ActionController::InvalidAuthenticityToken</code>. I've added <code>&lt;%= csrf_meta_tags %&gt;</code> and verified that <code>meta: csrf-param</code> and <code>meta: csrf-token</code> are present in my headers, and that <code>authenticity_token</code> is present in my form. (The tokens themselves are different from each other.)\nI've tried, <code>protect_from_forgery prepend: true, with:exception</code>, no effect. I can &quot;fix&quot; this issue by commenting out: <code>protect_from_forgery with:exception</code>. But my understanding is that that is turning off CSRF protection on my form. (I want CSRF protection.)\nWhat am I missing?\n<strong>UPDATE:</strong>\nTo try to make this clear, 99% of this app is a pure JSON RESTful API. The need came up to add one HTML view and form to this app. So <em>for one Controller</em> I want to enable full CSRF protection. The rest of the app doesn't need CSRF and can remain unchanged.\n<strong>UPDATE 2:</strong>\nI just compared the page source of this app's HTML form and Header with another conventional Rails 5 app I wrote. The <code>authenticity_token</code> in the Header and the <code>authenticity_token</code> in the form are <em>the same</em>. In the API app I'm having the problem with, they're <em>different</em>. Maybe that's something?\n<strong>UPDATE 3:</strong>\nOk, I don't the the mismatch is the issue. However, in further comparisons between the working and non-working apps I noticed that there's nothing in Network &gt; Cookies. I see a bunch of things like <code>_my_app-session</code> in the cookies of the working app.\n",
    "accepted_answer": "Here's what the issue was: Rails 5, when in API mode, logically doesn't include the Cookie middleware. Without it, there's no Session <code>key</code> stored in a Cookie to be used when validating the token I passed with my form. \n\nSomewhat confusingly, changing things in <code>config/initializers/session_store.rb</code> had no effect. \n\nI eventually found the answer to that problem here: <a href=\"https://stackoverflow.com/questions/15342710/adding-cookie-session-store-back-to-rails-api-app\">Adding cookie session store back to Rails API app</a>, which led me here: <a href=\"https://github.com/rails/rails/pull/28009/files\" rel=\"noreferrer\">https://github.com/rails/rails/pull/28009/files</a> which mentioned exactly the lines I needed to add to application.rb to get working Cookies back:\n\n<pre><code>config.session_store :cookie_store, key: \"_YOUR_APP_session_#{Rails.env}\"\nconfig.middleware.use ActionDispatch::Cookies # Required for all session management\nconfig.middleware.use ActionDispatch::Session::CookieStore, config.session_options\n</code></pre>\n\nThose three lines coupled with:\n\n<pre><code>class FooController &lt; ApplicationController\n  include ActionController::RequestForgeryProtection\n  protect_from_forgery with: :exception, unless: -&gt; { request.format.json? }\n  ...\n</code></pre>\n\nAnd of course a form generated through the proper helpers:\n\n<pre><code>form_tag(FOO_CREATE_path, method: :post)\n  ...\n</code></pre>\n\nGot me a CSRF protected form in the middle of my Rails API app.\n",
    "text_a": "I have a Rails 5 API app (ApplicationController &lt; ActionController::API). The need came up to add a simple GUI form for one endpoint of this API. Initially, I was getting ActionView::Template::Error undefined method protect_against_forgery? when I tried to render the form. I added include ActionController::RequestForgeryProtection and protect_from_forgery with:exception  to that endpoint. Which solved that issue as expected. However, when I try to submit this form I get: 422 Unprocessable Entity ActionController::InvalidAuthenticityToken. I've added [CODE1] and verified that meta: csrf-param and meta: csrf-token are present in my headers, and that authenticity_token is present in my form. (The tokens themselves are different from each other.) I've tried, [CODE2], no effect. I can &quot;fix&quot; this issue by commenting out: protect_from_forgery with:exception. But my understanding is that that is turning off CSRF protection on my form. (I want CSRF protection.) What am I missing? UPDATE: To try to make this clear, 99% of this app is a pure JSON RESTful API. The need came up to add one HTML view and form to this app. So for one Controller I want to enable full CSRF protection. The rest of the app doesn't need CSRF and can remain unchanged. UPDATE 2: I just compared the page source of this app's HTML form and Header with another conventional Rails 5 app I wrote. The authenticity_token in the Header and the authenticity_token in the form are the same. In the API app I'm having the problem with, they're different. Maybe that's something? UPDATE 3: Ok, I don't the the mismatch is the issue. However, in further comparisons between the working and non-working apps I noticed that there's nothing in Network &gt; Cookies. I see a bunch of things like _my_app-session in the cookies of the working app. ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 40,
    "question": "What's the need of to put CSRF token name and value inside <strong>&lt;head&gt;</strong> tag using <strong>&lt;meta&gt;</strong> like:\n\n<strong>e.g:</strong>\n\n<pre><code>&lt;meta content=\"authenticity_token\" name=\"csrf-param\" /&gt;\n&lt;meta content=\"4sWPhTlJAmt1IcyNq1FCyivsAVhHqjiDCKRXOgOQock=\" name=\"csrf-token\" /&gt;\n</code></pre>\n\nI've read about concept to keep CSRF value in cookie but does not find about why to keep inside <strong>&lt;head&gt;</strong> tag.\n",
    "accepted_answer": "To <a href=\"https://www.owasp.org/index.php/Cross-Site_Request_Forgery_%28CSRF%29_Prevention_Cheat_Sheet\">prevent CSRF</a> you need a value that is submitted with the request that cannot be sent by a malicious site. Authentication cookies are not suitable because if an attacker can make the browser send a request to the victim site, the cookies will automatically be submitted.\n\nFor example, by submitting a form via JavaScript contained on <code>www.evil.com</code> to attack the user's session on <code>www.example.com</code>:\n\n<pre><code>&lt;form method=\"post\" action=\"https://www.example.com/executeAction\"&gt;\n    &lt;input type=\"hidden\" name=\"action\" value=\"deleteAllUsers\"&gt;\n&lt;/form&gt;\n\n&lt;script&gt;document.forms[0].submit()&lt;/script&gt;\n</code></pre>\n\nStoring an anti CRSF token within the page is the <a href=\"https://www.owasp.org/\">OWASP</a> recommended solution for preventing another website from submitting the form, as the random token in the user's session cannot be read by <code>www.evil.com</code> due to the <a href=\"http://en.wikipedia.org/wiki/Same-origin_policy\">Same Origin Policy</a> preventing JavaScript on <code>www.evil.com</code> reading the page content of <code>www.example.com</code>.\n\nThese tokens can be stored anywhere within the page. Most commonly it will be within hidden form fields, but they could also be stored within <a href=\"http://ejohn.org/blog/html-5-data-attributes/\">HTML 5 data- attributes</a>. It seems like using <code>meta</code> tags is simply another way it can be stored where the JavaScript can include it in any form submissions the page makes.\n",
    "text_a": "What's the need of to put CSRF token name and value inside &lt;head&gt; tag using &lt;meta&gt; like:  e.g:  [CODE1]  I've read about concept to keep CSRF value in cookie but does not find about why to keep inside &lt;head&gt; tag. ",
    "tgt_text": "use Authentication cookies to prevent CSRF",
    "label": "C1",
    "code": "<code>&lt;meta content=\"authenticity_token\" name=\"csrf-param\" /&gt;\n&lt;meta content=\"4sWPhTlJAmt1IcyNq1FCyivsAVhHqjiDCKRXOgOQock=\" name=\"csrf-token\" /&gt;\n</code>",
    "insecure_code": "&lt;meta content=\"authenticity_token\" name=\"csrf-param\" /&gt;"
  },
  {
    "guid": 41,
    "question": "I'm using the RNG crypto provider to generate numbers in a range the truly naive way:\n<pre><code>byte[] bytes = new byte[4];\nint result = 0;\nwhile(result &lt; min || result &gt; max)\n{\n   RNG.GetBytes(bytes);\n   result = BitConverter.ToInt32(bytes);\n}  \n</code></pre>\nThis is great when the range is wide enough such that there is a decent chance of getting a result, but earlier today I hit a scenario where the range is sufficiently small (within 10,000 numbers) that it can take an age.\nSo I've been trying to think of a better way that will achieve a decent distribution but will be faster.  But now I'm getting into deeper maths and statistics that I simply didn't do at school, or at least if I did I have forgotten it all!\nMy idea is:\n<ul>\n<li>get the highest set bit positions of the min and max, e.g. for 4 it would be 3 and for 17 it would be 5</li>\n<li>select a number of bytes from the prng that could contain at least the high bits, e.g.1 in this case for 8 bits</li>\n<li>see if any of the upper bits in the allowed range (3-5) are set</li>\n<li>if yes, turn that into a number up to and including the high bit</li>\n<li>if that number is between min and max, return.</li>\n<li>if any of the previous tests fail, start again.</li>\n</ul>\nLike I say, this could be exceedingly naive, but I am sure it will return a match in a narrow range faster than the current implementation.  I'm not in front of a computer at the moment so can't test, will be doing that tomorrow morning UK time.\nBut of course speed isn't my only concern, otherwise I would just use <em>Random</em> (needs a couple of tick marks there to format correctly if someone would be kind enough - they're not on the Android keyboard!).\nThe biggest concern I have with the above approach is that I am always throwing away up to 7 bits that were generated by the prng, which seems bad.  I thought of ways to factor them in (e.g. a simple addition) but they seem terribly unscientific hacks!\nI know about the mod trick, where you only have to generate one sequence, but I also know about its weaknesses.\nIs this a dead end?  Ultimately if the best solution is going to be to stick with the current implementation I will, I just feel that there must be a better way!\n",
    "accepted_answer": "Stephen Toub and Shawn Farkas has co-written an excellent article on MSDN called <a href=\"http://msdn.microsoft.com/en-us/magazine/cc163367.aspx\" rel=\"noreferrer\">Tales From The CryptoRandom</a> that you should definitely read if you're experimenting with <a href=\"http://msdn.microsoft.com/en-us/library/system.security.cryptography.rngcryptoserviceprovider.aspx\" rel=\"noreferrer\">RNGCryptoServiceProviders</a>\n\nIn it they provide an implementation that inherits from System.Random (which contains the nice range-random method that you're looking for) but instead of using pseudo random numbers their implementation uses the <a href=\"http://msdn.microsoft.com/en-us/library/system.security.cryptography.rngcryptoserviceprovider.aspx\" rel=\"noreferrer\">RNGCryptoServiceProvider</a>.\n\nThe way he has implemented the Next(min, max) method is as follows:\n\n<pre><code>public override Int32 Next(Int32 minValue, Int32 maxValue)\n{\n    if (minValue &gt; maxValue) \n        throw new ArgumentOutOfRangeException(\"minValue\");\n    if (minValue == maxValue) return minValue;\n    Int64 diff = maxValue - minValue;\n    while (true)\n    {\n        _rng.GetBytes(_uint32Buffer);\n        UInt32 rand = BitConverter.ToUInt32(_uint32Buffer, 0);\n\n        Int64 max = (1 + (Int64)UInt32.MaxValue);\n        Int64 remainder = max % diff;\n        if (rand &lt; max - remainder)\n        {\n            return (Int32)(minValue + (rand % diff));\n        }\n    }\n}\n</code></pre>\n\nThe reasoning for the choice of implementation as well as a detailed analysis about loss of randomness and what steps they are taking to produce high-quality random numbers is in <a href=\"https://web.archive.org/web/20090304194122/http://msdn.microsoft.com:80/en-us/magazine/cc163367.aspx\" rel=\"noreferrer\">their article</a>.\n\n<strong>Thread safe bufferred CryptoRandom</strong>\n\nI've written an extended implementation of Stephen's class which utilized a random buffer in order to minimize any overhead of calling out to GetBytes(). My implementation also uses synchronization to provide thread safety, making it possible to share the instance between all your threads to make full use of the buffer. \n\nI wrote this for a very specific scenario so you should of course profile whether or not is makes sense for you given the specific contention and concurrency attributes of your application. I threw the code up on github if you wan't to check it out.\n\n<a href=\"https://gist.github.com/1017834\" rel=\"noreferrer\">Threadsafe buffered CryptoRandom based on Stephen Toub and Shawn Farkas' implementation</a>\n\nWhen I wrote it (a couple of years back) I seem to have done some profiling as well\n\n<pre><code>Results produced by calling Next() 1 000 000 times on my machine (dual core 3Ghz)\n\nSystem.Random completed in 20.4993 ms (avg 0 ms) (first: 0.3454 ms)\nCryptoRandom with pool completed in 132.2408 ms (avg 0.0001 ms) (first: 0.025 ms)\nCryptoRandom without pool completed in 2 sec 587.708 ms (avg 0.0025 ms) (first: 1.4142 ms)\n\n|---------------------|------------------------------------|\n| Implementation      | Slowdown compared to System.Random |\n|---------------------|------------------------------------|\n| System.Random       | 0                                  |\n| CryptoRand w pool   | 6,6x                               |\n| CryptoRand w/o pool | 19,5x                              |\n|---------------------|------------------------------------|\n</code></pre>\n\nPlease note that theese measurements only profile a very specific non-real-world scenario and should only be used for guidance, measure your scenario for proper results.\n",
    "text_a": "I'm using the RNG crypto provider to generate numbers in a range the truly naive way: [CODE1] This is great when the range is wide enough such that there is a decent chance of getting a result, but earlier today I hit a scenario where the range is sufficiently small (within 10,000 numbers) that it can take an age. So I've been trying to think of a better way that will achieve a decent distribution but will be faster.  But now I'm getting into deeper maths and statistics that I simply didn't do at school, or at least if I did I have forgotten it all! My idea is:  get the highest set bit positions of the min and max, e.g. for 4 it would be 3 and for 17 it would be 5 select a number of bytes from the prng that could contain at least the high bits, e.g.1 in this case for 8 bits see if any of the upper bits in the allowed range (3-5) are set if yes, turn that into a number up to and including the high bit if that number is between min and max, return. if any of the previous tests fail, start again.  Like I say, this could be exceedingly naive, but I am sure it will return a match in a narrow range faster than the current implementation.  I'm not in front of a computer at the moment so can't test, will be doing that tomorrow morning UK time. But of course speed isn't my only concern, otherwise I would just use Random (needs a couple of tick marks there to format correctly if someone would be kind enough - they're not on the Android keyboard!). The biggest concern I have with the above approach is that I am always throwing away up to 7 bits that were generated by the prng, which seems bad.  I thought of ways to factor them in (e.g. a simple addition) but they seem terribly unscientific hacks! I know about the mod trick, where you only have to generate one sequence, but I also know about its weaknesses. Is this a dead end?  Ultimately if the best solution is going to be to stick with the current implementation I will, I just feel that there must be a better way! ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 42,
    "question": "A hypothetical web-site currently connects using:\n\n<pre><code>public SqlConnection CreateConnection()\n{\n   DbConnection connection = new SqlConnection();\n   connection.ConnectionString = GetConnectionString();\n   connection.Open();\n\n   return connection;\n}\n</code></pre>\n\nWhere the magical connection string is stored in <code>web.config</code>:\n\n<pre><code>String GetConnectionString()\n{\n   //Get the connection string info from web.config\n   ConnectionStringSettings cs = ConfigurationManager.ConnectionStrings[\"db\"];\n\n   if (cs == null)\n      throw new Exception(\"Could not locate DB connection string\");\n\n   return cs.ConnectionString;\n}\n</code></pre>\n\nNow i'd like to move the connection string out of the web.config file into Azure KeyVault. How do you retrieve anything out of the Azure key vault?\n\n<pre><code>String GetConnectionString()\n{\n   //Get the connection string info from Azure KeyVault\n   String connectionString = GetAzureSecret(\"dbConnectionString\");\n\n   if (String.IsNullOrWhitespace(connectionString)\n      throw new Exception.Create(\"Could not connection string of Azure Key Vault\");\n\n   return connectionString;\n}\n</code></pre>\n\nExcept i just made up the easy-to-use Azure API. What is the <em>actual</em> api?\n\n<h2>Untested attempt</h2>\n\n<pre><code>string GetAzureSecret(string key)\n{\n    KeyVaultClient vault = new KeyVaultClient();\n    vault.OnAuthenticate += VaultClientAuthenticate;\n\n    var sec = await vault.GetSecretAsync(Key);\n    return sec.Value;\n}\n\npublic static async Task&lt;string&gt; VaultClientAuthenticate(string authority, string resource, string scope)\n{\n   String clientID = \"8675209\";\n   String clientSecret = \"correct battery horse pencil\";\n\n   var authContext = new AuthenticationContext(authority);\n   ClientCredential clientCred = new ClientCredential(clientID, clientSecret);\n   AuthenticationResult result = await authContext.AcquireTokenAsync(resource, clientCred);\n\n   if (result == null)\n      throw new Exception(\"Could not acquire token\");\n\n   return result.AccessToken;\n}\n</code></pre>\n\n<h2>Bonus Reading</h2>\n\n<ul>\n<li><a href=\"https://social.msdn.microsoft.com/Forums/azure/en-US/56bed4bd-6320-4f1f-9af5-556ae91bdf0f/storing-sql-connection-string-passwords-in-key-vault-for-my-cloud-services?forum=AzureKeyVault\" rel=\"noreferrer\">MSDN Forums: Storing sql connection string passwords in Key Vault for my Cloud Services</a></li>\n<li><a href=\"https://stackoverflow.com/questions/40706406/how-to-properly-store-connection-strings-in-azure\">How to properly store connection strings in Azure?</a></li>\n<li><a href=\"https://stackoverflow.com/questions/2997903/easily-switching-connectionstrings-on-publish-to-azure?rq=1\">Easily switching ConnectionStrings on publish to Azure</a></li>\n</ul>\n",
    "accepted_answer": "<blockquote>\n  What is the actual api?\n</blockquote>\n\nWe could use the <a href=\"https://learn.microsoft.com/en-us/rest/api/keyvault/getsecret\" rel=\"noreferrer\">GetSecret API</a> to get value.\n\n<strong>Preparation:</strong>\n\n<a href=\"https://learn.microsoft.com/en-us/azure/azure-resource-manager/resource-group-create-service-principal-portal#create-an-azure-active-directory-application\" rel=\"noreferrer\">Registry Azure Active Directory application and assign Role</a>\n\n<strong>Steps:</strong>\n\n1.Create KeyVault and add secret from Azure portal\n\n<a href=\"https://i.stack.imgur.com/vuuO7.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/vuuO7.png\" alt=\"enter image description here\"></a>\n\n2.Config Access policy\n\n<a href=\"https://i.stack.imgur.com/nbiWA.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/nbiWA.png\" alt=\"enter image description here\"></a>\n\n3.Get Access token\n\n<pre><code> var context = new AuthenticationContext(\"https://login.windows.net/\" + tenantId);\n            ClientCredential clientCredential = new ClientCredential(appId, secretKey);\n            var tokenResponse =await context.AcquireTokenAsync(\"https://vault.azure.net\", clientCredential);\n            var accessToken = tokenResponse.AccessToken;\n            return accessToken;\n</code></pre>\n\n<strong>Note</strong>: The resource for Keyvault is <code>https://vault.azure.net</code>\n\n4.Test with Fiddler\n\n<a href=\"https://i.stack.imgur.com/wqNNW.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/wqNNW.png\" alt=\"enter image description here\"></a>  \n\n<strong>We also can do that easily with SDK:</strong>\n\n1.Create a console project and a Utils.cs file\n\n<pre><code>public static string EncryptSecret { get; set; }\n        static string appId = \"Application ID\";\n        static string secretKey = \"Secert key\";\n        static string tenantId = \"TenantId\";\n\n        public static async Task&lt;string&gt; GetAccessToken(string azureTenantId,string azureAppId,string azureSecretKey)\n        {\n\n            var context = new AuthenticationContext(\"https://login.windows.net/\" + tenantId);\n            ClientCredential clientCredential = new ClientCredential(appId, secretKey);\n            var tokenResponse =await context.AcquireTokenAsync(\"https://vault.azure.net\", clientCredential);\n            var accessToken = tokenResponse.AccessToken;\n            return accessToken;\n        }\n</code></pre>\n\n2.Add the follow code in the main function and test it.\n\n<a href=\"https://i.stack.imgur.com/9kcoq.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/9kcoq.png\" alt=\"enter image description here\"></a>\n\npackages.config file\n\n<pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;packages&gt;\n  &lt;package id=\"Hyak.Common\" version=\"1.0.2\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Microsoft.Azure.Common\" version=\"2.0.4\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Microsoft.Azure.Common.Dependencies\" version=\"1.0.0\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Microsoft.Azure.KeyVault\" version=\"1.0.0\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Microsoft.Bcl\" version=\"1.1.9\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Microsoft.Bcl.Async\" version=\"1.0.168\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Microsoft.Bcl.Build\" version=\"1.0.14\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Microsoft.IdentityModel.Clients.ActiveDirectory\" version=\"3.13.9\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Microsoft.Net.Http\" version=\"2.2.22\" targetFramework=\"net452\" /&gt;\n  &lt;package id=\"Newtonsoft.Json\" version=\"6.0.4\" targetFramework=\"net452\" /&gt;\n&lt;/packages&gt;\n</code></pre>\n\nWe also can get more information from CtrlDot mentioned <a href=\"https://learn.microsoft.com/en-us/azure/key-vault/key-vault-use-from-web-application\" rel=\"noreferrer\">document</a>.\n",
    "text_a": "A hypothetical web-site currently connects using:  [CODE1]  Where the magical connection string is stored in web.config:  [CODE2]  Now i'd like to move the connection string out of the web.config file into Azure KeyVault. How do you retrieve anything out of the Azure key vault?  [CODE3]  Except i just made up the easy-to-use Azure API. What is the actual api?  Untested attempt  [CODE4]  Bonus Reading   MSDN Forums: Storing sql connection string passwords in Key Vault for my Cloud Services How to properly store connection strings in Azure? Easily switching ConnectionStrings on publish to Azure  ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  },
  {
    "guid": 43,
    "question": "I have read about CSRF and how the Unpredictable Synchronizer Token Pattern is used to prevent it. I didn't quite understand how it works.\n\nLet's take this scenario :\n\nA user is logged into a site with this form:\n\n<pre><code>&lt;form action=\"changePassword\" method=\"POST\"&gt;\n   &lt;input type=\"text\" name=\"password\"&gt;&lt;br&gt;\n   &lt;input type=\"hidden\" name=\"token\" value='asdjkldssdk22332nkadjf' &gt;\n&lt;/form&gt;\n</code></pre>\n\nThe server also stores the token in the session. When the request is sent it compares the token in the form data to the token in the session.\n\nHow does that prevent CSRF when the hacker can write JavaScript code that will:\n\n<ol>\n<li>Send a GET request to the site</li>\n<li>Receive html text containing the request form.</li>\n<li>Search the html text for the CSRF token.</li>\n<li>Make the malicious request using that token.</li>\n</ol>\n\nAm missing something?\n",
    "accepted_answer": "The attacker can't use JavaScript to read the token from the site, because it would be a cross-origin request and access to the data from it is blocked (by default) by the Same Origin Policy (<a href=\"https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy\">MDN</a>, <a href=\"http://www.w3.org/Security/wiki/Same_Origin_Policy\">W3C</a>).\n\nTake this for example:\n\n<div class=\"snippet\" data-lang=\"js\" data-hide=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-js lang-js prettyprint-override\"><code>var xhr = new XMLHttpRequest();\nxhr.open(\"GET\", \"http://google.com\");\nxhr.addEventListener('load', function (ev) {\n    console.log(this.responseText);  \n});\nxhr.send();</code></pre>\n</div>\n</div>\n\n\nThe JS console reports:\n\n<blockquote>\n  XMLHttpRequest cannot load <code>http://google.com/</code>. No '<code>Access-Control-Allow-Origin</code>' header is present on the requested resource.\n</blockquote>\n",
    "text_a": "I have read about CSRF and how the Unpredictable Synchronizer Token Pattern is used to prevent it. I didn't quite understand how it works.  Let's take this scenario :  A user is logged into a site with this form:  [CODE1]  The server also stores the token in the session. When the request is sent it compares the token in the form data to the token in the session.  How does that prevent CSRF when the hacker can write JavaScript code that will:   Send a GET request to the site Receive html text containing the request form. Search the html text for the CSRF token. Make the malicious request using that token.   Am missing something? ",
    "tgt_text": "",
    "label": "C5",
    "code": "",
    "insecure_code": ""
  }
]