[
  {
    "guid": 0,
    "text_a": "In Swing, the password field has a [CODE1] (returns [CODE2]) method instead of the usual [CODE3] (returns [CODE4]) method.  Similarly, I have come across a suggestion not to use [CODE5] to handle passwords. \n\nWhy does [CODE6] pose a threat to security when it comes to passwords?\nIt feels inconvenient to use [CODE7]. \nStrings are immutable.  That means once you've created the [CODE8], if another process can dump memory, there's no way (aside from reflection). \n\nWith an array, you can explicitly wipe the data after you're done with it.  You can overwrite the array with anything you like, and the password won't be present anywhere in the system,. \n\nSo yes, this is a security concern - but even using [CODE9] only reduces the window of opportunity for an. \n\nAs noted in the comments, it's possible that arrays being moved by the garbage collector will leave stray copies of.  I believe this is implementation-specific - the garbage collector may clear all memory as it goes, to avoid this.  Even if it does, there's still the time during which the [CODE10] contains the actual characters as an attack. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 1,
    "text_a": "Section 4. 2 of the draft OAuth 2. 0 protocol indicates that an authorization server can return both an [CODE1] (which is used to authenticate oneself with a. rfc-editor. org/rfc/rfc6749#section-4. 2\nWhy have both? Why not just make the [CODE2] last as long as the [CODE3] and not have a [CODE4]?\nThe. \n\nRefresh tokens, if compromised, are useless because the attacker requires the client id and secret in addition to the refresh. \n\nHaving said that, because every call to both the authorization server and the resource server is done over SSL -. \n\nThis of course is different to implementations where you don't control both the authorization and resource servers. \n\nHere is a good thread talking about uses of refresh tokens: OAuth Archives. \n\nA quote from the above, talking about the security purposes of the refresh token:\n\n\n  Refresh tokens. . .  mitigates the risk of a long-lived access_token leaking (query param in a log file on an insecure resource server,",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 2,
    "text_a": "I have two apps that use Integrated Security.  One assigns [CODE1] in the connection string,  and the other sets [CODE2]. \n\nWhat is the difference between [CODE3] and [CODE4] in the context of Integrated Security?\nAccording to Microsoft they are the same. \n\n\n  When [CODE5], User ID and Password are specified in the connection.  When true, the current Windows account credentials are used for authentication. \n  Recognized values are [CODE6], [CODE7], [CODE8], [CODE9], and [CODE10] (strongly recommended), which is equivalent to [CODE11]. \n\n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 3,
    "text_a": "I'm trying to support JWT bearer token (JSON Web Token) in my web API application and I'm getting lost. \n\nI see support for . NET Core and for OWIN applications. \nI'm currently hosting my application in IIS. \n\nHow can I achieve this authentication module in my application? Is there any way I can use the [CODE1] configuration. NET Web API 4 years ago using HMAC. \nNow, lots of things changed in security, especially that JWT is getting popular.  In this answer, I will try to explain how to use JWT in the simplest and basic way that. NET Identity, etc. . \nIf you don't know about JWT tokens, you need to take a look at:\nhttps://www. rfc-editor. org/rfc/rfc7519\nBasically, a JWT token looks like this:\n[CODE2]\nExample:\n\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9. eyJ1bmlxdWVfbmFtZSI6ImN1b25nIiwibmJmIjoxNDc3NTY1NzI0LCJleHAiOjE0Nzc1NjY5MjQsImlhdCI6MTQ3NzU2NTcyNH0. 6MzD1VwA5AcOcajkFyKhLYybr3h13iZjDyHm9zysDFQ\n\nA JWT token has three sections:\n\nHeader: JSON format which is encoded in Base64\nClaims: JSON format which is encoded in Base64. \nSignature: Created and signed based on Header and Claims which is encoded in Base64. \n\nIf you use the website jwt. io with the token above, you can decode the token and see it like below:\n\nTechnically, JWT uses a signature which.  Therefore, JWT must be transferred over HTTPs if you store any sensitive information in its claims. \nNow, in order to use JWT authentication, you don't really need an OWIN middleware if you have a legacy Web.  The simple concept is how to provide JWT token and how to validate the token when the request comes.  That's it. \nIn the demo I've created (github), to keep the JWT token lightweight, I only store [CODE3] and [CODE4].  But this way, you have to re-build new local identity (principal) to add more information like roles, if you.  But, if you want to add more information into JWT, it's up to you: it's very flexible. \nInstead of using OWIN middleware, you can simply provide a JWT token endpoint by using a controller action:\n[CODE5]\nThis is a. \nHow to generate the token based on [CODE6]?\nYou can use the NuGet package called [CODE7] from Microsoft to generate the.  In the demo, I use [CODE8] with [CODE9]:\n[CODE10]\nThe endpoint to provide the JWT token is done. \nHow to validate the JWT when the request comes?\nIn the demo, I have built\n[CODE11] which inherits from [CODE12] (more detail. \nWith this attribute, you can authenticate any action: you just have to put this attribute on that action",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 4,
    "text_a": "I am setting up my first [CODE1] server on a [CODE2] and I am fairly new to the details of.  (BTW I am not trying to use Apache at the same time. ) \n\nEverything is installed correctly, but I found that unless I use the [CODE3], I am not able to listen.  However I would rather not run it as root for security reason.  \n\nWhat is the best practice to:\n\n\nSet good permissions / user for node so that it is secure / sandboxed?\nAllow. \nStart up node and run it automatically. \nHandle log information sent to console. \nAny other general maintenance and security concerns. \n\n\nShould I be forwarding port 80 traffic to a different listening port?\n\nThanks\nPort 80\nWhat I do on my cloud instances is. js on port 3000.  Requests to port 80 will get mapped to port 3000. \nYou should also edit your [CODE4] file and add that line minus the [CODE5].   That will add the redirect when the machine boots up.  You don't need [CODE6] in [CODE7] because the commands there are run as [CODE8] when the system boots. \nLogs\nUse the forever module to launch your Node. js with.   It will make sure that it restarts if it ever crashes and it will redirect console logs to. \nLaunch on Boot\nAdd your Node. js start script to the file you edited for port redirection, [CODE9].   That will run your Node. js launch script when the system starts. \nDigital Ocean &amp; other VPS\nThis not only applies to Linode, but Digital Ocean, AWS EC2 and other VPS providers as.  However, on RedHat based systems [CODE10] is [CODE11]. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 5,
    "text_a": "Feel free to correct me if my assumptions are wrong here, but let me explain why I'm asking. \n\nTaken from MSDN, a [CODE1]:\n\n\n  Represents text that should be kept confidential.  The text is encrypted for privacy when being used, and deleted from computer memory when no longer needed. \n\n\nI get this, it makes complete sense to store a password or other private information in a [CODE2] over a.  Consequently, if a String object contains sensitive information such as a password, credit card number, or personal data, there. \n\n\nHowever, in the case of a GUI application (for example, an ssh client), the [CODE3] has to be built from.  All of the text controls use a string as its underlying data type. \n\nSo, this means that every time the user presses a key, the old string that was there is discarded, and.  And we can't control when or if any of those values are discarded from memory. \n\nNow it's time to log in to the server.  Guess what? You need to pass a string over the connection for authentication.  So let's convert our [CODE4] into a [CODE5]. . . .  and now we have a string on the heap with no way to force it to go through garbage. \n\nMy point is: no matter what you do, somewhere along the line, that [CODE6] is going to be converted into. \n\nMy point is not: whether there are ways of circumventing sending a string to an ssh connection, or circumventing having.  For this question, you can replace \"ssh connection\" with \"login form\", \"registration form\", \"payment form\", \"foods-you-would-feed-your-puppy-but-not-your-children form\", etc. \n\n\nSo, at what point does using a [CODE7] actually become\npractical?\nIs it ever worth the extra development time to completely eradicate\nthe. . .  So would using a [CODE8] prevent him from getting to the data anyways?\nIs this just \"security through obscurity\"?\n\n\nSorry if.  Feel free to answer any or all of my questions (or tell me that my assumptions are completely wrong).  :)\nThere are actually very practical uses of [CODE9].  \n\nDo you know how many times I've seen such scenarios? (the answer is: many!):\n\n\nA password appears in a log. \nA password is being shown at somewhere - once a GUI did show a command line of application that was.  Oops. \nUsing memory profiler to profile software with your colleague.  Colleague sees your password in memory",
    "tgt_text": "A password appears in a log file accidentally.\nA password is being shown at somewhere - once a GUI did show a command line of application that was being run, and the command line consisted of password. Oops.\nUsing memory profiler to profile software with your colleague. Colleague sees your password in memory. Sounds unreal? Not at all.\nI once used RedGate software that could capture the \"value\" of local variables in case of exceptions, amazingly useful. Though, I can imagine that it will log \"string passwords\" accidentally.\nA crash dump that includes string password.",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 6,
    "text_a": "My team got handed over some server side code (in Java) that generates random tokens and I have a question.  So they do need to be cryptographically random to avoid somebody guessing them or brute force them feasibly.  The token is a \"long\" so it is 64 bits long. \n\nThe code currently uses the [CODE1] class to generate these tokens.  The documentation for [CODE2] clearly states the following: \n\n\n  Instances of java. util. Random are not cryptographically secure.  Consider instead using SecureRandom to get a cryptographically secure pseudo-random number generator for use by security-sensitive applications. \n\n\nHowever, the way the code is currently using [CODE3] is this - It instantiates the [CODE4] class and then uses.  Then it uses [CODE5] method to generate the token. \n\nSo my question now - Is it still insecure given that the [CODE6] is being seeded using [CODE7]? Do I.  \n\nTaken from [CODE8] source code (JDK 7u2), from a comment on the method [CODE9], which is the one that.  H.  Lehmer and described by Donald E.  Knuth in\n    The Art of Computer Programming, Volume 3:\n    Seminumerical Algorithms, section 3. 2. 1. \n\n\nPredictability of Linear Congruential Generators\n\nHugo Krawczyk wrote a pretty good paper about how these LCGs can be predicted (\"How to.  If you're lucky and interested, you may still find a free, downloadable version of it on the web.  And there's plenty more research that clearly shows that you should never use an LCG for security-critical purposes.  This also means that your random numbers are predictable right now, something you don't want for session IDs and. \n\nHow to break a Linear Congruential Generator\n\nThe assumption that an attacker would have to wait for the LCG to repeat.  Even with an optimal cycle (the modulus m in its recurrence relation) it is very easy to predict future.  After all, it's just a bunch of modular equations that need to be solved, which becomes easy as soon.  \n\nThe security doesn't improve with a \"better\" seed.  It simply doesn't matter if you seed with a random value generated by [CODE10] or even produce the value.  \n\nAn attacker will simply compute the seed from the output values observed.  This takes significantly less time than 2^48 in the case of [CODE11].  Disbelievers may try out this experiment, where it is shown that you can predict future [CODE12] outputs observing only.  It takes not even a second on a modern computer to predict the output of your random numbers right",
    "tgt_text": "The purpose of these tokens is fairly sensitive - used for session id, password reset links etc. So they do need to be cryptographically random to avoid somebody guessing them or brute force them feasibly. The token is a \"long\" so it is 64 bits long.",
    "label": "C3",
    "code": "<code>java.util.Random</code>"
  },
  {
    "guid": 7,
    "text_a": "I am wondering wether the Password Hasher that is default implemented in the UserManager that comes with MVC 5 and. NET Identity Framework, is secure enough? And if so, if you could explain to me how it works?\n\nIPasswordHasher interface looks. net Identity password hashing\"\n that it does infact salt it behind the scenes.  So I am wondering how does it do this? And where does this salt come from?\n\nMy concern is that. \nHere is how the default implementation (ASP. NET Framework or ASP. NET Core) works.  It uses a Key Derivation Function with random salt to produce the hash.  The salt is included as part of the output of the KDF.  Thus, each time you \"hash\" the same password you will get different hashes.  To verify the hash the output is split back to the salt and the rest, and the KDF is.  If the result matches to the rest of the initial output the hash is verified. \n\nHashing:\n\n[CODE1]\n\nVerifying:\n\n[CODE2]\n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 8,
    "text_a": "I've just read on the net about a newly discovered security vulnerability in ASP. NET.  You can read the details here. \n\n\n  The problem lies in the way that\n  ASP. NET implements the AES encryption\n  algorithm to protect the integrity of\n  the cookies these applications\n  generate to. \n\n\nThis is a bit vague, but here is a more frightening part:\n\n\n  The first stage of the attack takes. The\n  cryptographic knowledge required is\n  very basic. \n\n\nAll in all, I'm not familiar enough with the security/cryptograpy subject to know if this is really that serious. \n\nSo, should all ASP. NET developers fear this technique that can own any ASP. NET website in seconds or what?\n\nHow does this issue affect the average ASP. NET developer? Does it affect us at all?\nIn real life, what are the consequences of this vulnerability? And, finally: is.  @Sri provided a great explanation about what does this type of attack mean.  Here is a shocking video about the issue!\n\nAbout the seriousness of this vulnerability: Yes, it is indeed serious.  It lets the attacker to get to know the machine key of an application.  Thus, he can do some very unwanted things. \n\n\nIn posession of the app's machine key, the attacker can decrypt authentication cookies. \nEven worse than that, he can generate authentication cookies with the name of any user.  Thus, he can appear as anyone on the site.  The application is unable to differentiate between you or the hacker who generated an authentication cookie with your name. \nIt also lets him to decrypt (and also generate) session cookies, although this is not as dangerous as the previous. \nNot so serious: He can decrypt the encrypted ViewState of pages.  (If you use ViewState to store confidental data, you shouldn't do this anyways!)\nQuite unexpected: With the knowledge of the. Config, etc. )\n\n\nHere is a bunch of good practices I got that don't solve the issue but help improve the general security. \n\n\nYou can encrypt sensitive data with Protected Configuration\nUse HTTP Only cookies\nPrevent DoS attacks\n\n\nNow, let's focus on this issue. \n\n\nScott Guthrie published an entry about it on his blog\nScottGu's FAQ blog post about the vulnerability\nScottGu's update on the vulnerability\nMicrosoft.  Yes, even 404s.  (ScottGu said that differentiating between 404s and 500s are essential for this attack. ) Also, into your [CODE1] or [CODE2] put some code that makes a random delay",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 9,
    "text_a": "I'm trying to grok the purpose of . NET's SecureString.   From MSDN:\n\nAn instance of the System. String class is both immutable and, when no longer needed, cannot be programmatically scheduled for garbage collection; that is, the.  Consequently, if a String object contains sensitive information such as a password, credit card number, or personal data, there. \nA SecureString object is similar to a String object in that it has a text value.  However, the value of a SecureString object is automatically encrypted, can be modified until your application marks it as. NET Framework garbage collector. \nThe value of an instance of SecureString is automatically encrypted when the instance is initialized or when the value is.  Your application can render the instance immutable and prevent further modification by invoking the MakeReadOnly method. \n\nIs the automatic encryption the big payoff?\nAnd why can't I just say:\n[CODE1]\ninstead of\n[CODE2]\nWhat aspect of SecureString am I missing?\nI would.   Looks like PG guys are dropping support for it.   Possibly even pull it in the future - https://github. com/dotnet/apireviews/tree/master/2015-07-14-securestring . \n\n\n  We should remove encryption from  SecureString  across all platforms in . NET Core - We should obsolete  SecureString - We probably shouldn't expose  SecureString  in . NET Core\n\n",
    "tgt_text": "I'm trying to grok the purpose of .NET's SecureString.",
    "label": "C2",
    "code": "<code>SecureString pass = new SecureString();\nforeach (char c in &quot;password&quot;.ToCharArray())\n    pass.AppendChar(c);\n</code>"
  },
  {
    "guid": 10,
    "text_a": "I came across a discussion in which I learned that what I'd been doing wasn't in fact salting passwords but.  As each password has its own salt, they must all be brute-forced individually in order to crack them; however,. \nA pepper is a site-wide static value stored separately from the database (usually hard-coded in the application's source code) which.  It is used so that a compromise of the database would not cause the entire application's password table to. \n\n\nIs there anything I'm missing and is salting &amp; peppering my passwords the best option to protect my user's security?.  so a breach of the database server does not automatically mean a breach of the application server. \nOk.  Seeing as I need to write about this over and over, I'll do one last canonical answer on pepper. \n\nThe Apparent Upside Of Peppers\n\nIt seems quite obvious that peppers should make hash functions more secure.  I mean, if the attacker only gets your database, then your users passwords should be secure, right? Seems logical,.  It \"makes sense\".  \n\nThe Reality Of Peppers\n\nIn the security and cryptography realms, \"make sense\" isn't enough.  Something has to be provable and make sense in order for it to be considered secure.  Additionally, it has to be implementable in a maintainable way.  The most secure system that can't be maintained is considered insecure (because if any part of that security breaks. \n\nAnd peppers fit neither the provable or the maintainable models. . . \n\nTheoretical Problems With Peppers\n\nNow that we've set the stage, let's look at what's wrong with peppers. \n\n\nFeeding one hash into another can be dangerous. \n\nIn your example, you do [CODE1]. \n\nWe know from past experience that \"just feeding\" one hash result into another hash function can decrease the overall security.  The reason is that both hash functions can become a target of attack.  \n\nThat's why algorithms like PBKDF2 use special operations to combine them (hmac in that case). \n\nThe point is that while it's not a big deal, it is also not a trivial thing to just throw.  Crypto systems are designed to avoid \"should work\" cases, and instead focus on \"designed to work\" cases. \n\nWhile this may seem purely theoretical, it's in fact not.  For example, Bcrypt cannot accept arbitrary passwords.  So passing [CODE2] can indeed result in a far weaker hash than [CODE3] if [CODE4] returns a binary string. \nWorking Against Design\n\nThe way bcrypt (and other password hashing algorithms) were designed is to work with a salt",
    "tgt_text": "Ignoring the chosen hash algorithm (I want this to be a discussion of salts &amp; peppers and not specific algorithms but I'm using a secure one), is this a secure option or should I be doing something different?",
    "label": "C1",
    "code": "<code>hash_function($salt.hash_function($pepper.$password)) [multiple iterations]\n</code>"
  },
  {
    "guid": 11,
    "text_a": "I've heard that exposing database IDs (in URLs, for example) is a security risk, but I'm having trouble understanding why. \n\nAny opinions or links on why it's a risk, or why it isn't?\n\nEDIT: of course the access is scoped, e. g.  if you can't see resource [CODE1] you'll get an error page.  Otherwise the URL itself should be secret. \n\nEDIT: if the URL is secret, it will probably contain a generated token that has a limited lifetime, e. g.  valid for 1 hour and can only be used once. \n\nEDIT (months later): my current preferred practice for this is to use UUIDS for IDs and expose them.  If I'm using sequential numbers (usually for performance on some DBs) as IDs I like generating a UUID token. \nThere are risks associated with exposing database identifiers.  On the other hand, it would be extremely burdensome to design a web application without exposing them at all.  Thus, it's important to understand the risks and take care to address them. \nThe first danger is what OWASP called &quot;insecure direct object references. &quot; If someone discovers the id of an entity, and your application lacks sufficient authorization controls to prevent it, they. \nHere are some good rules to follow:\n\nUse role-based security to control access to an operation.  How this is done depends on the platform and framework you've chosen, but many support a declarative security model. \nUse programmatic security to control access to an object.  This is harder to do at a framework level.  More often, it is something you have to write into your code and is therefore more error prone.  This check goes beyond role-based checking by ensuring not only that the user has authority for the operation, but.  In a role-based system, it's easy to check that only managers can give raises, but beyond that, you need. \n\nThere are schemes to hide the real identifier from an end user (e. g. , map between the real identifier and a temporary, user-specific identifier on the server), but I would argue that this.  I want to focus on keeping real cryptographic secrets, not trying to conceal application data.  In a web context, it also runs counter to widely used REST design, where identifiers commonly show up in. \nAnother challenge is prediction or discovery of the identifiers.  The easiest way for an attacker to discover an unauthorized object is to guess it from a numbering sequence.  The following guidelines can help mitigate that:\n\nExpose only unpredictable identifiers",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 12,
    "text_a": "I am going to use oAuth to fetch mails and contacts from google.  I don't want to ask the user each time to log in to obtain an access token and secret.  From what I understood, I need to store them with my application either in a database or [CODE1].  But I am a bit worried about security aspects with that.  I read that you can encrypt and decrypt the tokens but it is easy for an attacker to just. \nWhat's the best method to securely store these tokens in Android?\nStore them as shared preferences.  Those are by default private, and other apps cannot access them.  On a rooted devices, if the user explicitly allows access to some app that is trying to read them,.  As for encryption, you have to either require the user to enter the decrypt passphrase every time (thus defeating.  \n\nThere are a few benefits of storing tokens instead of the actual username password:\n\n\nThird party apps don't need to. )\nEven if someone steals a token, they don't get to see the password (which the user might be using on",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 13,
    "text_a": "This question is about protecting against Cross Site Request Forgery attacks only. \nIt is specifically about: Is protection via the Origin header (CORS) as good as the protection via a CSRF token?\nExample:\n\nAlice.  I assume, that she uses a modern browser. \nAlice visits [CODE1], and evil. example's client side code performs some kind of request to [CODE2] (classic CSRF scenario). \n\nSo:\n\nIf we don't check the Origin header (server-side), and no CSRF token, we have a CSRF security hole. \nIf we check a CSRF token, we're safe (but it's a bit tedious). \nIf we do check the Origin header, the request from evil. example's client side code should be blocked just as well as it would when using a CSRF token - except,. example's code to set the Origin header. \n\nI know, that this should not be possible with XHR (see e. g.  Security for cross-origin resource sharing), at least not, if we trust the W3C spec to be implemented correctly in. g.  form submit? Loading a script/img/. . .  tag? Or any other way a page can use to (legally) create a request? Or maybe some known JS. com's page,\n. . . \n\n\nknow, that this should not be possible with XHR (see e. g.  Security for cross-origin resource sharing), at least not, if we trust the W3C spec to be implemented correctly in.  If you don't trust the client browser, then you should stop using the web at all for anything other.  Even with using CSRF tokens, you are trusting the client browser to correctly obey the Same Origin Policy. \nWhile there have been previous browser vulnerabilities such as those in IE 5. 5/6. 0 where it has been possible for attackers to bypass the Same Origin Policy and execute attacks, you can typically. \n\nBut what about other kinds of requests - e",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 14,
    "text_a": "I've been getting the same old error every time I test a new [CODE1] from my browser's address bar when.  To allow [CODE2], set [CODE3] to [CODE4]. \n\n\nRather than grunt in acknowledgement and fire up Fiddler to do a post request, this time, I'm wondering exactly what.  Note that unless you have implemented CORS, the browser will protect the data from other domains making this request. \n\nHowever, if you allowed GET requests then as well as making an AJAX request similar to the above with GET.  e. g.  on [CODE5]:\n\n\n[CODE6]\n\nThis JavaScript should be useless to [CODE7] because there should be no way of reading the object returned.  However, due to bugs in old versions of browsers (e. g.  Firefox 3), it is possible for JavaScript prototype objects to be redefined and make it possible for [CODE8] to.  This is known as JSON Hijacking. \n\nSee this post for some methods of preventing this.  However, it is not a known problem with the later versions of modern browsers (Firefox, Chrome, IE). \n",
    "tgt_text": "allowed GET requests then as well as making an AJAX request similar to the above with GET instead of POS. This JavaScript should be useless because there should be no way of reading the object returned by your web method.",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 15,
    "text_a": "I am trying to use one-time passwords that can be generated using Google Authenticator application. \nWhat Google Authenticator does\nBasically, Google Authenticator implements two types of passwords:\n\nHOTP - HMAC-based One-Time Password, which means the password is. \n\nGoogle Authenticator is also available as Open Source here: code. google. com/p/google-authenticator\nCurrent code\nI was looking for existing solutions to generate HOTP and TOTP passwords, but did not find much.  The code I have is the following snippet responsible for generating HOTP:\n[CODE1]\nThe problem I am facing is that the.  Even though I tried multiple [CODE2] values (exactly first 10000, beginning with [CODE3]), with [CODE4] being equal to key. \nQuestions I have\nMy questions are:\n\nWhat am I doing wrong?\nHow can I generate HOTP and/or TOTP in Python?\nAre there any existing. \nI wanted to set a bounty on my question, but I have succeeded in creating solution.  My problem seemed to be connected with incorrect value of [CODE5] key (it must be correct parameter for [CODE6]. \n\nBelow I post full working solution with explanation on how to use it. \n\nCode\n\nThe following code is enough.  I have also uploaded it to GitHub as separate module called onetimepass (available here: https://github. com/tadeck/onetimepass). \n\n[CODE7]\n\nIt has two functions:\n\n\n[CODE8] generates one-time token (that should invalidate after single use),\n[CODE9] generates token based on time (changed in. \nUse [CODE10] if you want one-time passwords invalidated after each use.  In Google Authenticator this type of passwords i  mentioned as based on the counter.  For checking it on the server you will need to check several values of [CODE11] (as you have no. \nUse [CODE12], if you want a token working in 30-second intervals.  You have to make sure both systems have correct time set (meaning that they both generate the same Unix. \nMake sure to protect yourself from brute-force attack.  If time-based password is used, then trying 1000000 values in less than 30 seconds gives 100% chance of guessing.  In case of HMAC-based passowrds (HOTPs) it seems to be even worse. \n\n\nExample\n\nWhen using the following code for one-time HMAC-based password:\n\n[CODE13]\n\nyou will get the following result:\n\n[CODE14]\n\nwhich is corresponding to the tokens generated. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 16,
    "text_a": "I am trying to add some security to the forms on my website.  One of the forms uses AJAX and the other is a straightforward &quot;contact us&quot; form.  I'm trying to add a CSRF token.  The problem I'm having is that the token is only showing up in the HTML &quot;value&quot; some of the.  The rest of the time, the value is empty.  Here is the code I am using on the AJAX form:\nPHP :\n[CODE1]\nHTML :\n[CODE2]\nAny suggestions?\nFor security code, please don't generate.  It's MIT licensed and available on Github and Composer as paragonie/random_compat. \n\nPHP 5. 3+ (or with ext-mcrypt)\n\n[CODE3]\n\nVerifying the CSRF Token\n\nDon't just use [CODE4] or even [CODE5], use [CODE6] (PHP 5. 6+ only, but available to earlier versions with the hash-compat library). \n\n[CODE7]\n\n\n\nGoing Further with Per-Form Tokens\n\nYou can further restrict tokens to only be available for a particular form by using [CODE8].  HMAC is a particular keyed hash function that is safe to use, even with weaker hash functions (e. g.  MD5).  However, I recommend using the SHA-2 family of hash functions instead. \n\nFirst, generate a second token for use as an HMAC key, then use logic like this to render it:\n\n[CODE9]\n\nAnd then.  It is important that you use a separate token as an HMAC key than the one you just drop. \n\nBonus: Hybrid Approach + Twig Integration\n\nAnyone who uses the Twig templating engine can benefit from a simplified dual strategy by.  In my opinion, the Twig strategy offers greater flexibility and simplicity, while maintaining the possibility for maximum security. \n\n\n\nSingle-Use CSRF Tokens\n\nIf you have a security requirement that each CSRF token is allowed to be usable exactly once, the.  However, doing so will invalidate every previous token which doesn't mix well with people who browse multiple tabs at. \n\nParagon Initiative Enterprises maintains an Anti-CSRF library for these corner cases.  It works with one-use per-form tokens, exclusively.  When enough tokens are stored in the session data (default configuration: 65535), it will cycle out the oldest unredeemed. \n",
    "tgt_text": "rand() is predictable\nuniqid() only adds up to 29 bits of entropy\nmd5() doesn't add entropy, it just mixes it deterministically",
    "label": "C3",
    "code": "<code>$token = md5(uniqid(rand(), TRUE));</code>"
  },
  {
    "guid": 17,
    "text_a": "I need to store sensitive information (a symmetric encryption key that I want to keep private) in my C++ application.  The simple approach is to do this:\n[CODE1]\nHowever, running the application through the [CODE2] process (or any other that extracts. \nWhat techniques should be used to obscure such sensitive data?\nEdit:\nOK, so pretty much all of you have said &quot;your executable. \nThe point is that you pick your position on that sliding scale depending on what you're trying to do and.  I'm not writing an app for a military installation, I'm writing an app for a home PC.  I need to encrypt data across an untrusted network with a pre-known encryption key.  In these cases, &quot;security through obscurity&quot; is probably good enough! Sure, someone with enough time, energy and skill could.  This blue-sky &quot;lets do it the absolute best way possible&quot; trend in programming amongst new programmers is foolish to. \nThank you for taking the time to answer this question - they were most helpful.  Unfortunately I can only accept one answer, but I've up-voted all the useful answers. \nBasically, anyone with access to your program and a debugger can and will find the key in the application if. \n\nBut, if you just want to make sure the key doesn't show up when running [CODE3] on your binary, you. \n\nObscuring key with XOR\n\nFor instance, you could use XOR to split the key into two byte arrays:\n\n[CODE4]\n\nIf you create key1. \n\nProtecting your binary\n\nAnother approach is to use a tool to protect your binary.   For instance, there are several security tools that can make sure your binary is obfuscated and starts a.   This makes it hard(er) to debug, and is also the convential way many commercial grade secure applications (also,. \n\nOne of the premier tools is Themida, which does an awesome job of protecting your binaries.   It is often used by well known programs, such as Spotify, to protect against reverse engineering.   It has features to prevent debugging in programs such as OllyDbg and Ida Pro. \n\nThere is also a larger list, maybe somewhat outdated, of tools to protect your binary. \nSome of them are free. \n\nPassword matching\n\nSomeone here discussed hashing password+salt.   \n\nIf you need to store the key to match it against some kind of user submitted password, you.   The problem with this, though, is that your application has to know the salt to be able to.   So therefore you still need to store the salt somewhere in your application.  But, as @Edward points out in the comments below, this will effectively protect against a dictionary attack using, e. g, rainbow tables. \n\nFinally, you can use a combination of all the techniques above. \n",
    "tgt_text": "store sensitive information (a symmetric encryption key that I want to keep private) in my C++ application",
    "label": "C1",
    "code": "<code>std::string myKey = &quot;mysupersupersecretpasswordthatyouwillneverguess&quot;;\n</code>"
  },
  {
    "guid": 18,
    "text_a": "The more I learned about the power of [CODE1], the more astonished I am at what it can do.  This is adapted from my answer to the question (Using reflection to change static final File. separatorChar for unit testing). \n\n[CODE2]\n\nYou can do truly outrageous stuff:\n\n[CODE3]\n\nPresumably the API designers realize how abusable [CODE4] can be, but must have conceded that.  So my questions are:\n\n\nWhat are the truly legitimate uses for [CODE5]?\n\n\nCould Java has been designed as to NOT have.  The singleton pattern (putting doubts about its merits aside) is now impossible to enforce.  As my snippets above show, even some basic assumptions of how Java fundamental works is not even close to. \n\nARE THESE PROBLEMS NOT REAL???\n\n\n\nOkay, I just confirmed: thanks to [CODE6], Java strings are NOT immutable. \n\n[CODE7]\n\nAm I the only one who thinks this is a HUGE concern?\nDO I NEED TO WORRY ABOUT THIS???\n\nThat depends entirely. \n\nIf you're distributing a software component called foo. jar to the people of the world, you're completely at their mercy anyway.  They could modify the class definitions inside your . jar (through reverse engineering or direct bytecode manipulation).  They could run your code in their own JVM, etc.  In this case worrying will do you no good. \n\nIf you're writing a web-application that only interfaces with people and systems via HTTP and you control the application server,.  Sure the fellow coders at your company may create code that breaks your singleton pattern, but only if they. \n\nIf your future job is writing code at Sun Microsystems/Oracle and you're tasked with writing code for the Java core.  Worrying, however, will just make you lose your hair.  In any case they'll probably make you read the Secure Coding Guidelines along with internal documentation. \n\nIf you're going to be writing Java applets, the security framework is something you should be aware of.  You'll find that unsigned applets trying to call setAccessible will just result in a SecurityException. \n\nsetAccessible is not the only thing that goes around conventional integrity checks.  There's a non-API, core Java class called sun. misc. Unsafe that can do pretty much anything at all it wants to, including accessing memory directly.  Native code (JNI) can go around this kind of control as well. \n\nIn a sandboxed environment (for example Java Applets, JavaFX), each class has a set of permissions and access to Unsafe,. \n\n\"Java access modifiers are not intended to be a security mechanism. \"\n\nThat very much depends on where the Java code is being run",
    "tgt_text": "",
    "label": "C2",
    "code": "<code>import java.lang.reflect.*;\n\npublic class EverythingIsTrue {\n   static void setFinalStatic(Field field, Object newValue) throws Exception {\n      field.setAccessible(true);\n\n      Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n      modifiersField.setAccessible(true);\n      modifiersField.setInt(field, field.getModifiers() &amp; ~Modifier.FINAL);\n\n      field.set(null, newValue);\n   }\n   public static void main(String args[]) throws Exception {      \n      setFinalStatic(Boolean.class.getField(\"FALSE\"), true);\n\n      System.out.format(\"Everything is %s\", false); // \"Everything is true\"\n   }\n}\n</code>"
  },
  {
    "guid": 19,
    "text_a": "When trying to read a RSA private key from a file using the method\n\n[CODE1]\n\nI get the exception\n\n[CODE2]\n\nat the fac. generatePrivate(privKeySpec) call. \n\nWhat does this error mean?\n\nThanks\n\nDmitri\nIt means your key is not in PKCS#8 format.  The easiest thing to do is to use the [CODE3] command to convert the key once.  Alternatively you can use the [CODE4] class of the Bouncycastle lightweight API. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 20,
    "text_a": "The last week I read a lot articles about password hashing and Blowfish seems to be (one of) the best.  Twitter is using blowfish aka bcrypt to store their passwords (https://shouldichangemypassword. com/twitter-hacked. php) and guess what: change your twitter password to a long password with more than 72 characters and you can. \n\nBlowfish and Pepper\n\nThere are a lot different opinions about \"peppering\" passwords.  Some people say it's unnecessary, because you have to assume that the secret pepper-string is also known/published so it.  I have a separate database server so it's quite possible that only the database is leaked and not the. \n\nIn this case (pepper not leaked) you make an attack based on a dictionary more difficult (correct me if this.  If your pepper-string is also leaked: not that bad - you still have the salt and it's as good.   \n\nSo I think peppering the password is at least no bad choice. \n\nSuggestion\n\nMy suggestion to get a Blowfish hash for a password with more than 72 characters (and pepper) is:\n\n[CODE1]\n\nThis is based.   \n\nThe Question\n\nWhat is the safer way? Getting an SHA-256 hash first (which returns 64 characters) or consider only.  Thank's for the comments!\nNote: if you choose to do this, use a library.  For PHP, I strongly recommend Zend Framework 2's Zend\\Crypt package.  It's actually the only one I'd recommend at this current point in time.  It's been strongly reviewed, and it makes all the decisions for you (which is a very good thing). . . \n\nSomething like:\n\n[CODE2]\n\nAnd it's beneficial because you're using all of the algorithms in ways that are well understood and well studied.  Remember:\n\n\n  Anyone, from the most clueless amateur to the best cryptographer, can create an algorithm that he himself. \n\n\n\nBruce Schneier\n\n",
    "tgt_text": "hash password with Blowfish",
    "label": "C1",
    "code": "<code>&lt;?php\n$password = \"Wow. This is a super secret and super, super long password. Let's add some special ch4r4ct3rs a#d everything is fine :)\";\n$hash = password_hash($password, PASSWORD_BCRYPT);\nvar_dump($password);\n\n$input = substr($password, 0, 72);\nvar_dump($input);\n\nvar_dump(password_verify($input, $hash));\n?&gt;\n</code>"
  },
  {
    "guid": 21,
    "text_a": "I want to validate a set of credentials against the domain controller.  e. g. :\n\n[CODE1]\n\nMethod 1.  Query Active Directory with Impersonation\n\nA lot of people suggest querying the Active Directory for something.  If an exception is thrown, then you know the credentials are not valid - as is suggested in this. \n\nThere are some serious drawbacks to this approach however:\n\n\nYou are not only authenticating a domain account, but you are also.  That is, you are reading properties from the AD using an impersonation token.  What if the otherwise valid account has no rights to read from the AD? By default all users have. \nBinding against the AD has a serious overhead, the AD schema cache has to be loaded at the client (ADSI.  This is both network, and AD server, resource consuming - and is too expensive for a simple operation like. \nYou're relying on an exception failure for a non-exceptional case, and assuming that means invalid username and password.  Other problems (e. g.  network failure, AD connectivity failure, memory allocation error, etc) are then mis-intrepreted as authentication failure. \n\n\nMethod 2.  LogonUser Win32 API\n\nOthers have suggested using the [CODE2] API function.  This sounds nice, but unfortunately the calling user sometimes needs a permission usually only given to the operating system.  If the\n  calling process does not have this\n  privilege, LogonUser fails and\n  GetLastError returns\n  ERROR_PRIVILEGE_NOT_HELD.  \n  \n  In some\n  cases, the process that calls\n  LogonUser must also have the\n .  This privilege is\n  not required for the local system\n  account or accounts that are members\n  of.  By\n  default, SE_CHANGE_NOTIFY_NAME is\n  enabled for all users, but some\n  administrators may disable it for\n . \n\n\nHanding out the \"Act as a part of the operating system\" privilege is not something you want to do willy-nilly. . . the process that is calling\n  LogonUser must have the SE_TCB_NAME\n  privilege (in User Manager, this is\n  the.  The SE_TCB_NAME\n  privilege is very powerful and\n  should not be granted to any arbitrary user just so. \n\n\nAdditionally, a call to [CODE3] will fail if a blank password is specified. \n\n\n\nWhat is the proper way to authenticate a set of domain credentials?\n\n\n\nI happen to be calling from managed code, but.  It can be assumed that the customers have the ",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 22,
    "text_a": "In order to generate a 32 character token for access to our API we currently use:\n\n[CODE1]\n\nI have read that this. \n\nIf this is the case, what would the equivalent code look like?\n\nI presume something like this, but I don't know. . . \n\n[CODE2]\n\nAlso what length makes sense that I should pass to the function?\nHere is the correct solution:\n\n[CODE3]\n",
    "tgt_text": "generate a 32 character token for access to our API",
    "label": "C1",
    "code": "<code>$token = md5(uniqid(mt_rand(), true));\n</code>"
  },
  {
    "guid": 23,
    "text_a": "I had a look at this question, and wanted to do it for myself.  When I ran this code (taken straight from this answer):\n\n[CODE1]\n\nHowever I get the warning\n\n[CODE2]\n\nSo I went and had a.  I found this comment, but still no mention of what the Initialization Vector should be and how I should.  Can anyone enlighten me?\n\nI know I could have done some more Googleing, but Stackoverflow comes up first in so. \n\nNow, your code appears to be setting the IV (1234567812345678) but not using it on decryption.  That's certain to fail. \nYou also may want to utilize some of PHP's IV generation functions.  I think this should work for you:\n[CODE3]\nFor storage/transmission, one option is to simply concatenate the IV and cipher text. \n\nFor more info, check out PHP's Mcrypt library.  It's quite full featured and has tons of examples, many of which can help you out with openssh encryption. \nhttp://php. net/manual/en/function. mcrypt-encrypt. php\n\nAn obligatory security disclaimer: My words describe the simplest of simple concepts in the simplest possible way.  In the reach and depth of my knowledge, I am an absolute novice.  Even the best of the best security researchers and experts introduce encryption vulnerabilities all the time.  Even so, the less you write on your own, the better off your users, customers, family, and friends will.  No offense! While it's fun, interesting, and even practical to learn about encryption theory, especially applied to computer science. 9999999% of us.  Nothing is perfect, but it's best to stand on the shoulders of giants.  As a wise man probably might have said, &quot;The more you learn the more you realize how little you. &quot;\n",
    "tgt_text": "Use of Initialization Vector in openssl_encrypt",
    "label": "C1",
    "code": "<code>$textToEncrypt = \"My super secret information.\";\n$encryptionMethod = \"AES-256-CBC\";  // AES is used by the U.S. gov't to encrypt top secret documents.\n$secretHash = \"25c6c7ff35b9979b151f2136cd13b0ff\";\n\n//To encrypt\n$encryptedMessage = openssl_encrypt($textToEncrypt, $encryptionMethod, $secretHash, '1234567812345678');\n\n//To Decrypt\n$decryptedMessage = openssl_decrypt($encryptedMessage, $encryptionMethod, $secretHash);\n\n//Result\necho \"Encrypted: $encryptedMessage &lt;br&gt;Decrypted: $decryptedMessage\";\n</code>"
  },
  {
    "guid": 24,
    "text_a": "I am developing a JSON/REST web API, for which I specifically want third party websites to be able to call.  Hence, my service is sending the famous CORS header:\n\n[CODE1]\n\nWhich allows third party sites to call my service through AJAX.  All fine so far. \n\nHowever, a subsection of my web api is non-public and requires authentication (pretty standard stuff with OAuth and an access_token.  Is it safe to enable CORS on this part of my site as well?\n\nOn the one hand, it would.  However, the reason that there is a same origin policy in the first place, is that this might be.  You don't want any website that you visit afterwards to be able to access your private content.  \n\nThe scenario that I am afraid of is that a user logs in on my web api, either on.  Will this allow every other website that he vists afterwards to access his private content using the existing session?\n\nSo. . . ?), the cookie is saved under the domain of the CORS server.  The main web page's JS code can't access the cookie, even via [CODE2].  The cookie is only sent to the server when the [CODE3] property is set, and even then, it is. \n\nYour first question is a little more open ended.  It is fairly secure, but there are ways to circumvent things.  For example, an attacker could use a DNS poisoning technique to cause a preflight request to hit the actual.  Here are some more resources on CORS security:\n\n\nhttp://code. google. com/p/html5security/wiki/CrossOriginRequestSecurity\nowasp. org CORS CheatSheet\n\n\nLastly, your concern is around giving any website access to your CORS data.  In order to protect against this, you should not use the [CODE4] header.  Instead, you should echo back the user's Origin value.  For example:\n\n[CODE5]\n\nThis header will allow only [CODE6] to access the response data. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 25,
    "text_a": "Update: Please note I am not asking what a salt is, what a rainbow table is, what a dictionary attack.  I am querying: If you know the users salt and hash, isn't it quite easy to calculate their password?\n\nI. \n\n[CODE1]\n\nIn the database you store:\n\n[CODE2]\n\nEvery implementation of salting I have seen adds the salt either at the end of the. \n\nSurely the implementation described above simply adds another step for the hacker, without actually solving the underlying issue?  What.  (Update, as pointed out in comments it's best to assume the hacker has access to all your information so. \n\nLet me give an example of how I propose a hacker would hack a user database with a list of. \n\nGiven 10,000 common passwords, and 10,000 user records, we would need to calculate 100,000,000 hashes to discover as many user.   It might take a few hours, but it's not really an issue. Yes, you need just 3 days for sha1(salt | password).  That's why good password storage algorithms use 1000-iteration hashing: you will need 8 years. \n",
    "tgt_text": "Every implementation of salting I have seen adds the salt either at the end of the password, or beginnin",
    "label": "C3",
    "code": "<code>hashed_Password = sha1(s + password )\nhashed_Password = sha1(password + s)\n</code>"
  },
  {
    "guid": 26,
    "text_a": "I read about DDD and Access Control, and I found some contradiction between the following two opinions:\n\n\n\"security concerns should be.  So where should I put the access control logic by domain driven design, and how should I implement it?\n\n(To. )\n\nI think it should be somewhere near to the business logic, for example a user story could be something like. . . \n\n\nBased on the user story we implement the domain model and the services, for example:\n\n[CODE1]\n\nThis is okay, but where is. stackexchange. com/a/71883/65755 the policy enforcement point should be right before the call of the [CODE2]. \n\nI came to the same conclusion: it cannot be in the UI because by multiple UIs we would have code.  It should be before the creation of domain events, because they indicated that we have already done something in.  So we can restrict the access to domain objects or to services which use those domain objects.  By CQRS we don't necessary have domain objects by the read model, just services, so we have to restrict.  We could put the access decisions at the beginning of every service operation, but that would be [CODE3] security. \n\n\n  How should I implement it?\n\n\nThis depends on which access control model fits to the domain, so it depends.  By an access decision we usually send an access request and wait a permission in return.  The access request usually has the following parts: subject, resource, operation, environment.  So the subject requires permission to perform an operation on the resource in an environment.  First we identify the subject, then we authenticate it, and after that comes the authorization, where we check whether.  Every access control model works in a similar way.  Ofc.  they can lack of some of these steps, but that does not matter. . .   \n\nI created a short list of access control models.  I put the rules, policies into annotations, but normally we should store them in a database probably in XACML. . . \n\n\nBy identity based access control (IBAC) we have an identity - permission storage (access control list, capability list, access control.  So for example by an access control list, we store the list of the users or groups whose can.   \n\n[CODE4]\nBy lattice based access control (LBAC) the subject has a clearance level, the resource has a required clearance",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 27,
    "text_a": "The jar (bcprov-jdk16-145. jar) has been added to the project, [CODE1] has been added to the class, and [CODE2] does return \"BC\" but. writeFile() still throws [CODE3].  Any ideas?\n\n[CODE4]\nIm not very familiar with the Android sdk, but it seems that the [CODE5] comes with the [CODE6]. \n\nWhat you will have to do in the PC environment is just add it manually,\n\n[CODE7]\n\nif you have access to the. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 28,
    "text_a": "Cross Site Request Forgery (CSRF) is typically prevent with one of the following methods:\n\n\nCheck referer - RESTful but unreliable\ninsert token.  \n\n[CODE1]\n\n\n[CODE2] fetched by the JavaScript from the authenticated user. \nResponse: [CODE3] This secret is conceptionally static, but can be changed every day/hour . . .  to improve security.  This is the only confidential thing. \nRead the cryptic (but static for all users!) form id with JavaScript, process it together with the user secret: [CODE4]\nSend. \nSince the server knows the user secret and the form id, it is possible to run the same generateToken function.  Only when both values are equal the action will be authorized. \n\n\nIs something wrong with this approach, despite the fact that it doesn't work without JavaScript?\n\nAddendum:\n\n\nStateless CSRF Protection\n\nThere are a lot. \nThings you should NOT do:\n\nIf you need to read the session token from JavaScript, you're doing something horribly wrong.   Your session identifier cookie should ALWAYS have HTTPOnly set on it so its not available to scripts. \nThis one protection makes it so that the impact of XSS is considerably reduced, since an attacker will no longer.  You don't want one error to give keys to the kingdom. \n\nThe session identifier should not be written to the contents of the page.  This is for the same reasons you set HTTPOnly.  This means that that your csrf token can not be your session id.  They need to be different values. \n\n\nThings you should do:\n\nFollow OWASP's guidance:\n\nSpecifically, if this is a REST application you can require double-submission of CSRF tokens.  If you do this, just be sure that you define it to a specific full-domain (www. mydomain. com) and not a parent domain (example. com), and that you also utilize the &quot;samesite&quot; cookie attribute which is gaining popularity. \n\n\nSimply create something cryptographically random, store it in ASCII Hex or Base64 encode, and add it as a cookie and.  On the server side make sure that the cookie value matches the form value.  Voila, you've killed CSRF, avoided extra prompts for your users, and not opened yourself up to more vulnerabilities. \nNOTE: As @krubo states below the double-submission technique has been found to have some weaknesses (See Double-Submission).  Since this weakness requires that:\n\nYou define a cookie scoped to the parent domain. \nYou fail to set HSTS",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 29,
    "text_a": "We have a high security application and we want to allow users to enter URLs that other users will see. \n\nThis introduces a high risk of XSS hacks - a user could potentially enter javascript that another user ends up.  Since we hold sensitive data it's essential that this never happens. \n\nWhat are the best practices in dealing with this? Is any security whitelist or escape pattern alone good enough? \n\nAny. com\n\n\nAnd have it output to another user:\n\n[CODE1]\n\nWhat I really worry about is them using this in a XSS hack.  I. e.  they input:\n\n\n  alert('hacked!');\n\n\nSo other users get this link:\n\n[CODE2]\n\nMy example is just to explain the risk - I'm well. \n\nYou'd be amazed how many sites you can break with this trick - HTML is even worse.  If they know to deal with links do they also know to sanitise [CODE3], [CODE4] and clever CSS references?\n\nI'm.  I'm happy that I could produce a Regex (or use one of the excellent suggestions so far) that could. org/www-community/xss-filter-evasion-cheatsheet\nRead that, and weep. \nHere's how we do it on Stack Overflow:\n[CODE5]\n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 30,
    "text_a": "I'm trying to implement JWT in my authentication system and I have a few questions.  To store the token, I could use cookies but it's also possible to use [CODE1] or [CODE2]. \n\nWhich would be the best choice? \n\nI have read that JWT protects the site from CSRF.  However, I can't imagine how that would work assuming I save the JWT token in cookie storage. \n\nHow would it then protect from CSRF?\n\nUpdate 1\nI saw some usage samples like the following:\n\n[CODE3]\n\nHow can I implement that when.  \n\nUpdate 2  \n\nI installed the Advanced REST Client Google Chrome extension and was able to pass the token.  Is it possible to set this header data via Javascript when making a GET request to the server? \n[EDIT].  One remark though and because the security pratices evolved since Nov.  2016, the Option 2 should be implemented in favour of the Option 1. \n\nLook at this web site: https://auth0. com/blog/2014/01/07/angularjs-authentication-with-cookies-vs-token/\n\nIf you want to store them, you should use the localStorage or sessionStorage if available or cookies. \nYou should also use the Authorization header, but instead of Basic scheme, use the Bearer one:\n\n[CODE4]\n\nWith JS, you could use",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 31,
    "text_a": "My Rails app uses Devise for authentication.  It has a sister iOS app, and users can log in to the iOS app using the same credentials.  So I need some kind of API for authentication. \n\nLots of similar questions on here point to this tutorial, but it seems to be out-of-date, as the [CODE1] module.  (I'm using Devise 3. 2. 2. ) I've attempted to roll my own based on that tutorial (and this one), but I'm not 100% confident in. \n\nFirstly, following the advice of this gist, I added an [CODE2] text attribute to my [CODE3] table, and the following. rb\n\n[CODE4]\n\n(Note that my [CODE5] has the line [CODE6]. )\n\napi/sessions_controller. rb\n\n[CODE7]\n\napi/registrations_controller. rb\n\n[CODE8]\n\nAnd in config/routes. rb:\n\n[CODE9]\n\nI'm out of my depth a bit and I'm sure there's something here that my future self will look back.  Some iffy parts:\n\nFirstly, you'll notice that [CODE10] inherits from [CODE11] whereas [CODE12] inherits from [CODE13] (I also have some. ) This is a pretty ugly arrangement, but I couldn't figure out another way of getting access the methods I.  The tutorial I linked to above has the line [CODE14], but this module seems to have been removed in. \n\nSecondly, I've disabled CSRF protection with the line [CODE15].  I have my doubts about whether this is a good idea - I see a lot of conflicting or. \n\nThirdly, I want to make sure I understand how authentication works once a user has signed in.  Say I have an API call [CODE16] which returns a list of the current user's friends.  As I understand it, the iOS app would have to get the user's [CODE17] from the database (which is. g.  [CODE18], then my [CODE19] could do something like [CODE20] to get the current_user.  Is it really this simple, or am I missing something?\n\nSo for anyone who's managed to read all the way. g.  when it comes to CSRF attacks?\nIs my understanding of how to authenticate requests once users are signed in correct?. . . \" above",
    "tgt_text": "Build an session controller",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 32,
    "text_a": "I am trying to use a client certificate to authenticate and authorize devices using a Web API and developed a.   I am running into an issue where the client certificate is not being received by the web application.   A number of people of reported this issue, including in this Q&amp;A, but none of them have an.   My hope is to provide more detail to revive this issue and hopefully get an answer for my.   I am open to other solutions.   The main requirement is that a standalone process written in C# can call a Web API and be.  \n\nThe Web API in this POC is very simple and just returns a single value.   It uses an attribute to validate that HTTPS is used and that a client certificate is present.   \n\n[CODE1]\n\nHere is the code for the RequireHttpsAttribute:\n\n[CODE2]\n\nIn this POC I am just checking for the availability of the.   Once this is working I can add checks for information in the certificate to validate against a list. \n\nHere are the setting in IIS for SSL for this web application. \n\n\n\nHere is the code for the client that sends the request with a client certificate.   This is a console application. \n\n[CODE3]\n\nWhen I run this test app I get back a status code of 403 Forbidden with a reason phrase of.   Running this through a debugger I have verified that the certificate is getting loaded and added to the.   The certificate is exported into a CER file that is being loaded.   The full certificate with the private key is located on the Local Machine\u9225\u6a9a Personal and Trusted Root stores.   For this test the client and web application are being run on the same machine. \n\nI can call this Web API method using Fiddler, attaching the same client certificate, and it works fine.   When using Fiddler it passes the tests in RequireHttpsAttribute and returns a successful status code of 200 and. \n\nHas anybody run into the same issue where HttpClient does not send a client certificate in the request and found.   Here is how I retrieved it:\n\n[CODE4]\n\nI verified that this certificate was getting retrieved correctly and it was being.   But I got the same results where the server code does not retrieve any client certificates. \n\nFor completeness here is the code used to retrieve the certificate from a file:\n\n[CODE5]\n\nYou will notice that when you get.   The X509CertificateCollection. Add Method is expecting a type of X509Certificate. \n\nUpdate 2:\nI am still trying to figure this out and have tried many different options but to no avail.   \n\n\nI changed the web application to run on a host name instead of local host. \nI set the web application to require SSL\nI verified that the certificate was set for Client Authentication and that it. \n\n\nAt one point during trying these options it started working",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 33,
    "text_a": "I have a situation where the client makes a call through curl to a https url.  The SSL certificate of the https url is self signed and therefore curl cannot do certificate validation and fails.  curl provides an option [CODE1] which disables certificate validation.  \n\nMy question is that on using [CODE2] option, is the data transfer that is done between client and server.  \nYes, the transfered data is still sent encrypted.  [CODE3]/[CODE4] will \"only make\" [CODE5] skip certificate validation, it will not turn off SSL all together.  \n\nMore information regarding the matter is available under the following link:\n\n\ncurl. haxx. se - Details on Server SSL Certificates\n\n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 34,
    "text_a": "From Android In App Billing version 3 (TrivialDrive)sample application coming with sdk\n\nMainActivity. java\n\n[CODE1]\n\nWell I am not sure I understand this security measure.  I know how to get the application public key (which is already base 64 encoded) from Google Play Developer.  \n\nWhat I am not understanding is this part\n\n[CODE2]\n\nAs far as I know, this public key is a constant string,.  \n\nHow can we create the same key programmatically using any bit manipulation process? Has someone done it before? Is.  Probably also something that doesn't store the key in base64 would be a good idea too, since raw base64. \n\nIt's not a particularly GOOD way to protect the key.  But it protects against a trivial attack where somebody just searches through literal strings in you APK looking for.  At least you make the #$#$ers work a little bit. \n\nPresumably evil people can do bad things if they identify your public key.  Google seems to think so, apparently.  I can guess what this step does, but I'm not sure I really want to speculate on that in.   You want to do it though. \n\nThe basic plot summary would be that you're making it more difficult for somebody to write an application that programmatically. \n\nOne assumes that anyone who's doing this makes a living cracking 20 or 30,000 android apps and republishing them.  Chances are, I suppose that they're not going to take the extra ten minutes to add your app to.  Unless you have a top tier application.  And then the battle is potentially endless, and probably ultimately futile. \n\nSplitting the key into consecutive chunks (as proposed in another answer) probably isn't good enough.  Because the key will end up in consecutive strings in the string constant tables in the APK.  Too easy to find that with a program. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 35,
    "text_a": "I have noticed that there are strange requests to my website trying to find phpmyadmin, like\n\n[CODE1]\n\netc. \n\nNow I have installed PMA on Ubuntu via apt and would like to access it via webaddress different from /phpmyadmin/.  What can I do to change it?\n\nThanks\n\n\n\nUpdate\n\nFor Ubuntu 9. 10 and Apache2, the corresponding setting is located in the file [CODE2] which is a link to [CODE3].  The file contains\n\n[CODE4]\n\nwhere the first [CODE5] should be changed to something different if one wants to avoid the unnecessary. g. :\n\n[CODE6]\nThe biggest threat is that an attacker could leverage a vulnerability such as; directory traversal,  or using SQL Injection.   As a pentester I have used this attack pattern to compromise a system. \nHere is a great way to lock down phpmyadmin:\n\nPhpMyAdmin lacks strong bruteforce protection, so you must use a long randomly. \nDO NOT ALLOW REMOTE ROOT LOGINS! Instead phpmyadmin can be configured to use &quot;Cookie Auth&quot; to limit what user can.   If you need some root privileges,  create a custom account that can add/drop/create but doesn't have [CODE7]. \nRemove [CODE8] permissions from every account.  [CODE9] is one of the most dangerous privileges in MySQL because it allows an attacker to read files or. \nWhitelist IP address who have access to the phpmyadmin interface.   Here is an example . htaccess reulset:\n\n\n[CODE10]\n\n\nDo not have a predictable file location like: [CODE11].   Vulnerability scanners like Nessus/Nikto/Acunetix/w3af will scan for this. \n\nFirewall off tcp port 3306 so that it cannot be accessed by an attacker. \n\nUse HTTPS,  otherwise data and passwords can be leaked to an\nattacker.   If you don't want to fork out the $30 for a cert,  then\nuse a self-signed.   You'll accept it once,  and even if it was\nchanged due to a MITM you'll be notified. \n\n\n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 36,
    "text_a": "Is it safe to use the [CODE1] in the users table for authenticating the user into the application?\n\nWhat is the.  Each time the user logs out, this token is regenerated. \nNo.  It's not supposed to be used to authenticate.  It's used by the framework to help against [CODE2] cookie hijacking.  The value is refreshed upon login and logout.  If a cookie is hijacked by a malicious person, logging out makes the hijacked cookie useless since it doesn't. \n\nRefer to this documentation:\n\nhttps://laravel. com/docs/4. 2/upgrade#upgrade-4. 1. 29\n",
    "tgt_text": "remember_token",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 37,
    "text_a": "I'm using [CODE1] encryption in Java 8 and I'm wondering whether my code has a security flaw.   My code seems to work, in that it encrypts and decrypts text, but a few details are unclear. \nMy main question is this:\n[CODE2]\nDoes that IV satisfy the requirement of &quot;For a given key, the IV MUST NOT repeat. &quot; from RFC 4106?\nI'd also appreciate any answers / insight for my related questions (see below), but that first question.   I don't know where to find source code or documentation that answers this. \n\nHere is the full code, roughly.   I apologize in case I introduced errors while writing this post:\n[CODE3]\nSuppose that users cracking my secret key =. \n\nMore detailed questions / related questions:\n\nIs the IV returned by cipher. getIV() safe for me to use in this way?\n\n\nDoes it avoid the catastrophe of reusing the IV,key combination in Galois/Counter. g.  including [CODE4] or random numbers)?\n\nWould it help if I padded the src data with random numbers before encryption? .   I can re-post them separately if that is more appropriate for StackOverflow's format.   Let me know!)\nQ1: Is the IV returned by cipher. getIV() safe for me to use in this way?\nYes, it is at least for the Oracle provided implementation.  It is generated separately using the default [CODE5] implementation.  As it is 12 bytes in size (the default for GCM) then you have 96 bits of randomness.  The chance that the counter repeats is abysmally small.  You can look up the source in the OpenJDK (GPL'ed) which the Oracle JDK is based on. \nI would however still recommend you to generate your own 12 random bytes as other providers may behave differently. \n\nQ2: Is that IV always 12 bytes long?\nIt's extremely likely as it is the GCM default, but other lengths are.  The algorithm will however have to do additional calculations for any other size than 12 bytes.  Due to weaknesses it is strongly recommended to keep it at 12 bytes / 96 bits and API's may. \n\nQ3: Is the authentication tag always 16 bytes (128 bits) long?\nNo, it can have any size in bytes ranging from.  If it is smaller it simply consists of the leftmost bytes of the authentication tag though.  You can specify another size of tag using [CODE6] as third parameter for your [CODE7] call. \nNote that the strength of GCM is strongly dependent on the size of the tag.  I would recommend keeping it to 128 bits.  96 bits should be the minimum especially if you want to generate a lot of ciphertext. \n\nQ4: With #2 and #3, and the lack of padding, does that mean my encrypted messages are always 12 +. length + 16 bytes long? (And so I can safely squish them into one byte array, for which I know",
    "tgt_text": "using AES/GCM/NoPadding encryption in Java 8",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 38,
    "text_a": "Let's consider a common-known ASP. NET Core scenario.  Firstly we add the middleware:\n[CODE1]\nThen serialize a principal:\n[CODE2]\nAfter these two calls an encrypted cookie will be stored at the.  You can see the cookie (in my case it was chunked) in any browser devtools:\n\nIt's not a problem (and. \nMy question is: how to decrypt the cookie outside the application? I guess a private key is needed for that,.  The AuthenticationScheme specified during configuration must\nalso be used when calling SignInAsync. \nUnder the covers the encryption used is ASP. NET's Data Protection\nsystem.  If you are hosting on multiple machines, load balancing or\nusing a web farm then you will need to configure. \n\nSo, is it possible to decrypt the authentication cookie, and if so how?\nUPDATE #1:\nBased on Ron C great answer and. AspNetCore. DataProtection. dll:\nAdditional information: The payload was invalid. \n\nI tested different variations of this code on several machines without positive result.  Probably I made a mistake, but where?\nUPDATE #2: My mistake was the [CODE3] hasn't been set in [CODE4].  Thanks to @RonC again. \nDecrypting the Authentication Cookie without needing the keys\n\nIt's worth noting that you don't need to gain access to the keys.   You simply need to use the right [CODE5]  created with the right purpose parameter, and subpurpose parameters.  \n\nBased on the [CODE6] source code https://github. com/aspnet/Security/blob/rel/1. 1. 1/src/Microsoft. AspNetCore. Authentication. Cookies/CookieAuthenticationMiddleware. cs#L4 it looks like the purpose you need to pass is [CODE7].  And since they are passing additional parameters to the [CODE8] you will need to match them.   So this line of code should get you an [CODE9] that can be used to decrypt the authentication. cs file. \n\nHere is an example action method for decrypting your authentication cookie two different ways:\n\n[CODE10]\n\nThis method uses an [CODE11] called [CODE12]",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 39,
    "text_a": "\nWhat is the difference between use [CODE1] in an HTTP header or token\nin the hidden field?\nWhen to use the hidden. \nCSRF protection comes in a number of methods. \n\nThe traditional way (the \"Synchronizer token\" pattern) usually involves setting a unique valid Token value for each request and then.  It is usually done by setting a hidden form field.  The token value is usually short lived and associated to that session, so if a hacker tries to reuse.  So only requests from your application will work and forged requests from outside your application/domain (aka cross site request. \n\nThe downside of that is it requires your application to set this hidden token on all HTML forms.  These pages now have to be dynamically generated by an application, when perhaps previously they were static HTML.  It can also break the back button (as you need to refresh the form to regenerate another unique CSRF.  You also now need to keep track of valid tokens on the server side and check any requests use.  This can take quite a bit of extra effort to implement and maintain going forward. \n\nAn alternative approach (called the \"Cookie-to-header token\" pattern) is to set a Cookie once per session and the have JavaScript.  Any requests will send both the header (set by Javascript) and the cookie (set by the browser as a.  The idea being that only JavaScript run on the same domain would have access to the cookie, so JavaScript.  Even fake links (e. g.  in a phishing email) would not work either, as even though they would appear to come from the right. \n\nThis can be MUCH easier to implement than the Synchronizer token pattern as you don't need to set the token.  All you need is to set a cookie to a random value for each session.  Some front end frameworks will even automatically generate the header for you if they see the cookie (e. g.  AngularJS does this for example). \n\nThe downside is that it requires JavaScript to work (but that may not be an issue if your app basically. g.  XHR requests) - regular HTML form requests would not set the header.  A variation on this (the \"Double Submit Cookie\" pattern) puts the [CODE2] value in a hidden form field rather.  It should be noted however that OWASP states some weaknesses with the Double Submit method, when the attacker is. \n\nAdditionally the Synchronizer token pattern can allow extra controls to enforce flow (e. g.  the hidden field CSRF token will only be set when the application thinks you have sent a valid request",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 40,
    "text_a": "I've been tasked with development of an intranet interface for command line software, and now I'm researching security options.  Our command line application is finished, but I haven't started writing the web interface.  I don't know exactly what the security requirements are for potential customers, although I believe [CODE1] is generally acceptable.  With this in mind, I'm asking for help developing a menu of choices with their associated pros/cons.  Some day, we may consider releasing our web interface to the internet, so I'm willing to consider more security. \n\nI've been doing a lot of reading, and my tentative conclusion is that SSL security with no certificate is the.  I, a security non-expert, wouldn't need to explain why less security is acceptable to security non-experts.  I could upgrade my application to use a certificate in the future if necessary. \n\nHere's a list of SSL related security choices, sorted by my perception of security level with my comments.  What level of protection do I need?\n\n\nNo SSL.  This might be acceptable if our customers aren't worried about their employees seeing/changing each others' data.  Their employees might want to share results with each other anyway, and I could use IP based access control. \nDo SSL with no certificate.  This encrypts the communication, which at least protects the data from being read by unauthorized employees.  Using a password, this is the same level of security as [CODE2] on the command line, right? I don't. \nDo SSL with a self-signed certificate.  What does this give me that no certificate gives me? If the DNS can be changed inappropriately, then the.  Worded another way, if the DNS can change, then I think [CODE3] would be vulnerable too. \nDo SSL with a local Certificate Authority.  OpenSSL lets me make my own Certificate Authority.  What does this give me that a self-signed certificate does not? I'm assuming that on a LAN, it's less.  \nDo SSL with an external Certificate Authority.  Is there ever a reason to go this route for an intranet? I found some \"intranet certificates\" for sale. \n\n\nFor reference, this page might be useful for comparing certificates:\n\nhttp://httpd. apache. org/docs/trunk/ssl/ssl_faq. html#aboutcerts\n\n[update]\n\nHere's an article discussing the risks and rules of obtaining an internal certificate from a public CA. \nYes, certificates are still useful for Intranet SSL. \n\nThere's an important difference between SSH and SSL-without-a-certificate: when you first connect to a server with SSH, your SSH stores.  If you then try to connect to what the SSH client believes to be the same machine but gets",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 41,
    "text_a": "My Android app contains OAuth consumer secret for Twitter's API.  At the moment it's in [CODE1] file in plain text, so it takes zero effort for someone to look. \n\nShould I take steps to obscure it (like, rot13 or stored in obfuscated Java code)? Or should I actually avoid. . . \n\nYou should do your best to protect secrets but at the end, a highly motivated hacker can always get to.  So it's the value of the secret vs.  difficulty of extraction. \n\nThe value of the client secret is impersonating the application.  It doesn't give any access to user data.  However, since Twitter supports automatic issuance of credentials to previously approved apps (their sign-in with Twitter flow), an attacker. \n\nThe problem with Twitter's implementation is that they do not ask the developer about the nature of the application.  If they did, they would not have issued you a secret to begin with, and would block anyone building. \n\nObfuscating is one option, but a weak one.  Moving the secret to a web server acting as an API proxy is another, but that just moves the.  However, this pattern can be reasonably secure if you require users to log into your site (which can use,.  This way, someone trying to abuse your proxy will need their users to open accounts on your service, which. \n\nIn short, go ahead and obfuscate it.  It doesn't hurt.  Consider using the proxy pattern too.  And maybe let Twitter know their security policies are \"not great\". \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 42,
    "text_a": "Is it possible to reverse a SHA-1?\nI'm thinking about using a SHA-1 to create a simple lightweight system to authenticate. \nLet's say that I create a sha1 like this with input from a &quot;secret key&quot; and spice it with a. \n[CODE1]\nThen I include this SHA-1 in the communication and the server, which can do the same calculation.  And hopefully, nobody would be able to figure out the &quot;secret key&quot;. \nBut is this really true?\nIf you know that this is how I did it, you would know that I did. \nCan you then use those two and figure out the &quot;secret key&quot;?\n[CODE2]\n\nNote1:\nI guess you could brute force in some way,. \nNo, you cannot reverse SHA-1, that is exactly why it is called a Secure Hash Algorithm. \n\nWhat you should definitely be doing though, is include the message that is being transmitted into the hash calculation.  Otherwise a man-in-the-middle could intercept the message, and use the signature (which only contains the sender's key and the. \n\nAnd you should probably be using SHA-256 for new systems now. \n\n[CODE3]\n\nYou also need to additionally transmit the timestamp in the clear, because otherwise you have no way to verify the. \n\nIf a brute force attack is feasible depends on the length of your secret key. \n\nThe security of your whole system would rely on this shared secret (because both sender and receiver need to know,.  An attacker would try to go after the key (either but brute-force guessing or by trying to get it. \n",
    "tgt_text": "create a sha1 like this with input from a &quot;secret key&quot; and spice it with a timestamp",
    "label": "C1",
    "code": "<code>sha1(&quot;My Secret Key&quot;+&quot;a timestamp&quot;)\n</code>"
  },
  {
    "guid": 43,
    "text_a": "I am trying to hide 2 secrets that I am using in one of my apps. \n\nAs I understand the keychain is a good place but I can not add them before I submit the app. \n\nI thought about this scenario -\n\n\nPre seed the secrets in my app's CoreData Database by spreading them in other entities.  (I already have a seed DB in that app). \nAs the app launches for the first time, generate and move the keys to the keychain. \nDelete the records from CoreData. \n\n\nIs that safe or can the hacker see this happening and get those keys?\n\n*THIRD EDIT**\nSorry for not explaining this scenario.  The user can purchase a level (IAP) and after the purchase is completed I need to download the files. \n\nFor iOS6 the files are stored with Apple new \"Hosted Content\" feature.  For iOS5 the files are stored in amazon S3. \n\nSo in all this process I have 2 keys:\n1.  IAP key, for verifying the purchase at Apple IAP. \n2.  S3 keys, for getting the files from S3 for iOS5 users:\n\n[CODE1]\n\nDo I need to protect those keys at all?.  Or that hackers will be able to build a hacked version with all the levels pre-downloaded inside. \nLet me try to break down your question to multiple subquestions/assumption:\n\nAssumptions:\n\na) Keychain is safe place\n\nActually, it's not that safe.  If your application is installed on jailbroked device, a hacker will be able to get your keys from the.  As soon as there is something in your binary, it could be reverse engineered. \n\nb) Will obfuscation help?\n\nYes.  It will increase time for a hacker to figure it out.  If the keys which you have in app will \"cost\" less than a time spend on reverse engineering -. \n\nHowever, in most cases, security through obscurity is bad practice, It gives you a feeling that you are secure, but. \n\nSo, this could be one of security measures, but you need to have other security measures in place too. \n\nc) What should I do in such case?*\n\nIt's hard to give you a good solution without knowing background what you. \n\nAs example, why everybody should have access to the same Amazon S3? Do they need to read-only or write (as.  \n\nI believe one of the most secure scenarios would be something like that:\n\n\nYour application should be passcode protected \nFirst. g.  Google)\nThe server sends some authentication token to a device (quite often it's some type of cookie). \nYou encrypt this token based on hash of your application passcode and save it in keychain in this form\nAnd now. \n\nc) Whoooa",
    "tgt_text": "IAP key, for verifying the purchase at Apple IAP",
    "label": "C1",
    "code": "<code>NSString *secretAccessKey = @\"xxxxxxxxx\";\nNSString *accessKey = @\"xxxxxxxxx\";\n</code>"
  },
  {
    "guid": 44,
    "text_a": "Inspired by a thought while looking at the question &quot;Correct HTTP status code when resource is available but not accessible. \nImagine I am building a a carpooling web service. \nSuppose the following\n[CODE1]\nretrieves the current position of user &quot;angela&quot;.  Only angela herself and a possible driver that is going to pick her should be able to know her. \nAlso consider the request\n[CODE2]\nwhen no user called john has registered with the system.  There is no john resource let alone a resource for john's location, so this obviously returns a 404 Not.  Or does it?\nWhat if I don't want to reveal whether or not john is registered with the system?\n(Perhaps the. 4. 4 403 Forbidden) doing the opposite.   If someone attempts to access a resource, but is not properly authenticated, return 404 then, rather than 403.   This still solves the information disclosure issue. \n\n\n  If the server does not wish to make\n  this information available to the\n  client, the status. \n\n\nThus, you would never return 403 (or 401).   However, I think your solution is also reasonable. \n\nEDIT: I think Gabe's on the right track.   You would have to reconsider part of the design, but why not:\n\n\nNot found - 404\nUser-specific insufficient permission -",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 45,
    "text_a": "Why was it decided that using XMLHTTPRequest for doing XML calls should not do calls across the domain boundary? .  Why are the Ajax HTTP requests not allowed to cross the domain boundaries?  It seems like an odd.   However, in this case, you could simply add an img, script, or iframe element to the document to.   \n\n[Edit] \n\nSome of the answers point out the following reasons, let's point out the reasons they don't . \n\nXSRF (Cross Site Request Forgery, also known as CSRF, XSRF)\n\nYour can do XSRF attacks without using this at all.   As a general rule, XMLHTTPRequest isn't used at all, simply because it's so hard to make an XMLHTTPRequest.   It's much easier to just add an img tag to the URL if you want them to load. \n\nPosting to third party site\n\n[CODE1]\n\nCould be accomplished with\n\n[CODE2]\n\nJPunyon: why would you leave the vulnerability in a new feature\n\nYou aren't creating.   You are just inconveniencing developers who want to use it in a way for good.   Anybody who wants to use this feature for evil (aka awesome) could just use some other method of. \n\nConclusion\n\nI'm marking the answer from bobince as correct because he pointed out the critical problem.   Because XMLHTTPRequest allows you to post, with credentials (cookies) to the destination site, and read the data sent.   In this way, you could browse through the target site, like a bank, and the bank's webserver would. \n\n  Why are Ajax HTTP Requests not allowed to cross domain boundaries. \n\n\nBecause AJAX requests are (a) submitted with user credentials, and (b) allow the caller to read the returned data. \n\nIt is a combination of these factors that can result in a vulnerability.  There are proposals to add a form of cross-domain AJAX that omits user credentials. \n\n\n  you could simply add an img, script, or iframe element to the document\n\n\nNone of those methods allow the. \n\n(Except scripts where either it's deliberately set up to allow that, for permitted cross-domain scripting - or where someone's made. )\n\n\n  Your can do XSS attacks without using this at all.  Posting to third party site\n\n\nThat's not an XSS attack.  That's a cross-site request forgery attack (XSRF).  There are known ways to solve XSRF attacks, such as including one-time or cryptographic tokens to verify that the. \n\nIf you allowed cross-domain AJAX you would lose this safeguard.  The attacking code could request a page from the banking site, read any authorisation tokens on it, and submit.  And that would be a cross-site scripting attack. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 46,
    "text_a": "I want to securely store a plaintext password on Windows PC.  I am currently using DPAPI [CODE1] to encrypt it, then store the encrypted blob in a file in user's.  \n\nIn Windows 7, there is Windows Vault, a credential manager (Control Panel\\User Accounts and Family Safety\\Credential Manager) that stores.  On the surface this looks like the right place for a program to store credentials.  However, I was not able to find any API for it.  I read Authentication function reference in MSDN, but frankly got lost in it. \n\nIs there an API to Windows Vault to store and retrieve credentials from a program, and, if yes, where can.  Here is a code sample that may be compiled and run, that I used to confirm that these functions.  There were questions raised in the comments about the difference between storing credentials in the vault and encrypting a.  Here's my understanding, possibly non-exhaustive, of the key differences. \n\nRoaming control.  Storage in the Vault is managed by the system.  In a domain environment, setting [CODE2] makes the encrypted credential part of the user's roaming profile, and thus available.  [CODE3] only encrypts data; the keeping of the ciphertext is the user's responsibility.  Storing ciphertext under [CODE4] possibly makes it roaming also, depending on the domain's roaming setup, but setting a proper.  Vault data are encrypted at rest by the system. \nUI visibility.  A Vault credential is shown in the Vault UI, and may be revoked when no longer needed or suspected.  Ciphertext obtained from [CODE5] is fully controlled by the application.  The visibility feature must be taken into account in the target software design. \nVault supports volatile per-logon-session secrets, stored encrypted in memory ([CODE6]).  An implementation of such a feature with the generic API is relatively hard to get right, as it involves. \nSalting.  In case of [CODE7], the caller may provide additional salt (that has to be provided again during decryption, thus.  Vault takes care of it internally. \nVault has a narrower scope.  Using Vault for storing of non-identity-related data is likely a design smell. \nAudit.  [CODE8] has control over creating an audit record when a blob is decrypted (the [CODE9] bit flag).  I cannot see anything like this in the Vault API ([CODE10])",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 47,
    "text_a": "Celery defaults to using pickle as its serialization method for tasks.   As noted in the FAQ, this represents a security hole.   Celery allows you to configure how tasks get serialized using the [CODE1] configuration parameter.   \n\nBut this doesn't solve the security problem.   Even if tasks are serialized with JSON or similar, the workers will still execute tasks inserted into the.   So anybody who can write to the task queue can effectively pown the worker processes by writing malicious. \n\nHow can I prevent the worker threads from running tasks serialized with pickle?\nI got an answer from the celery-users mailing.   Add these two lines to the config (celeryconfig/settings):\n\n[CODE2]\n",
    "tgt_text": "Celery allows you to configure how tasks get serialized using the CELERY_TASK_SERIALIZER configuration parameter",
    "label": "C1",
    "code": "<code>CELERY_TASK_SERIALIZER</code>"
  },
  {
    "guid": 48,
    "text_a": "I am trying to encode a message with [CODE1] but I have no experience with security subject except some base.  I have been given a private key as [CODE2].  I have managed to write following code block to do the job but I am not sure if I.  \n\nI am not an expert but putting my private key as String in code is not secure I guess.  Can anyone guide me?\n\n[CODE3]\n\nMy private key is in form as:\n\n[CODE4]\nYour key format is an unencrypted base64-encoded PKCS8-encoded private key.  Here is an example of how to decode it into a private key.  (Don't worry about the security of the private key in this example, it is just a throwaway for the. \n[CODE5]\n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 49,
    "text_a": "I'm new to PHP and this is also my first log in system so it would be great if you. \n\nSign Up:\n\nStep 1: I take the password the user chose and run it through this function:\nStep 2: I then store.  On my site no 2 users can share the same\nusername so the username field always has a unique value.  If I get 1 row returned I grab the salt for that user. \n\nStep 2: Then I run the user entered password through the encrypt function (as previously posted above) but this time.  So I so a second lookup on the database to see if the\nusername entered and the hashed password together.  If so then the user's credentials are correct. \n\nStep 4: In order to log the user in after their credentials passed I generate a random unique string and.  Of course they must set as that cookie's value a string which after it is encrypted must match a.  I am not sure what the chances of this is realistically, for a user (perhaps using an automated program). \n\nSorry for the big essay but since this is such a critical part of my site and due to my.  \n\nSo do you see any security holes in this route and how can it be improved?\nYou should include some.  There are a number of ways to do this, including IP-based blocking, incremental timeouts, etc.  None of these will ever stop a hacker, but they can make it much more difficult. \n\nAnother point (which you haven't mentioned, so I don't know your plan) is failure messages.  Make failure messages as vague as possible.  Providing an error message like 'That username exists, but the passwords did not match' might be helpful to the.  You just converted a brute-force attack that should take [CODE1] time to [CODE2] + [CODE3].  Instead of needed to try every permutation in a rainbow table (for example), the hacker just tries all values.  Then, it knows a valid user, and just has to brute force the password. \n\nAlong those lines, you should also make sure that the same amount of time elapses when a username exists and.  You are running additional processes when a username actually exists.  As such the response time would be longer when a username exists vs when it doesn't.  An incredibly skilled hacker could time page requests to find a valid username. \n\nSimilarly, you should make sure that, in addition to expiring cookies, you also expire the sessions table. \n\nLastly, in the [CODE4] call, you should terminate all open sessions if there are multiple concurrent, active logins.  Make sure you timeout sessions after a set amount of inactivity (like 30 minutes). \n\nAlong the lines of what @Greg Hewgill mentioned, you haven't included any of the following:\n\n\nSSL/encrypted connection between Server-Client\nOther transport protocols.  You should make sure you are only communicating over an encrypted protocol.  \n",
    "tgt_text": "The get_userinfo() function does a lookup on the users table in the database and returns an associative array",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 50,
    "text_a": "I have to write a Windows service that handles at some point confidential data (such as PIN codes, passwords, and.  Those informations are needed for a very short amount of time: usually they are sent almost immediately to a. \n\nLets consider this piece of code:\n\n[CODE1]\n\nNow my concern is about compiler optimizations.  Here the compiler might detect that password is about to be deleted and that changing its value at this. \n\nI don't expect my compiler to care about the value of future-unreferenced memory. \n\nAre my concerns legitimate ? How can I be sure that such a piece of code won't be optimized-out ?\nYes,.  You need to use specifically designed function like SecureZeroMemory() to prevent optimizations from modifying your code behavior. \n\nDon't forget that the string class should have been specifically designed for handling passwords.  For example, if the class reallocates the buffer to hold a longer string it has to erase the buffer.  I'm not sure, but it's likely [CODE2] doesn't do that (at least by default).  Using an unsuitable string handling class makes all your concerns worthless - you'll have the password copied all over. \n",
    "tgt_text": "",
    "label": "C1",
    "code": "<code>{\n  std::string password = getPassword(); // Get the password from the user\n\n  writePasswordToSmartCard(password);\n\n  // Okay, here we don't need password anymore.\n  // We set it all to '\\0' so it doesn't stay in memory.\n  std::fill(password.begin(), password.end(), '\\0');\n}\n</code>"
  },
  {
    "guid": 51,
    "text_a": "Original question\nSo the project I'm working on is deathly paranoid about file uploads. \nIn the scope of this question, I'm not using that term in regards to payloads; I'm talking confidentiality. \nPrograms can always crash and leave temporary files loafing around in the filesystem.  That's normal.  The slightly confidentiality-paranoid can write a cronjob that hits the temporary file folder every few minutes and deletes anything. \n. . . unfortunately, we take this paranoid a step further:\nIdeally, we'd love to never see temporary files from file uploads anywhere but. \nIs there a way to teach PHP to look for temporary file as blobs in memory rather than in the.  (Note also: 'Filesystem' is the keyword here, rather than 'disc', since there are of course ways to map the. )\nAlternatively, is there a way these temporary files can be encrypted immediately when they're being written to disc, so that.  Depending on what you are hoping to achieve, the accepted answer may not be interesting to you.  If you've come here through a search engine, please take a moment to read the whole thread. \nHere is a compilation of usecases as I see them for quick reference:\nRe: PHP's temporary files\n\nRAM instead of disc (e. g.  due to I/O concerns) \u922b?RAMdisk/comparable (plasmid87, Joe Hopfgartner)\n\nImmediate (per-filesystem-user) encryption \u922b?encFS (ADW) (+ a gotcha as per Sander Marechal)\n\nSecure. \n\nIf the PHP process crashes, the encrypted file is left around but can't be decrypted.  No unencrypted data gets written to (ram)disk. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 52,
    "text_a": "I've been trying to get some working Java code to use for encrypting Paypal buttons.  This is no easy task! Even when I get some code, from Paypal, I'm faced with errors. . ugh. . \n\nSo here is what I have so far, that I think will work eventually. \n\nI downloaded the Java. zip file from Paypal's website.  Within it are two classes - ClientSide. java and ButtonEncryption. java\n\nThe Problem - I'm getting an [CODE1] error. \n\nQuestions\n1) How do I resolve this issue? 2) What line of code is throwing the error?\n\n[CODE2]\n\n\n\nClientSide class\n\n[CODE3]\n\n\n\nButtonEncryption class\n\n[CODE4]\n\n\n\nEdited : info. \n\nPrivate Key\nopenssl genrsa -out private-key. pem 1024\n\nPublic Certificate\nopenssl req -new -key private-key. pem -x509 -days 1095 -out public-cert. pem\n\nCreated PKCS12 File\nopenssl pkcs12 -export -in public-cert. pem -inkey private-key. pem -out my_pkcs12. p12\n\n\nAdditionally, I had to download the Paypal Public Certificate from the Paypal website. \n\n\n\nEdited - adding compilation warnings - BouncyCastle\n\n[CODE5]\n\n\n\nJCE policy file installation steps\n\nThese are the steps I took to installing the JCE. \n2) Extracted files from zip. \n3) Placed local_policy. jar and US_export_policy. jar files in C:\\Java\\jdk1. 6. 0_22\\jre\\lib\\security folder.  \nNote: C:\\Java\\jdk1. 6. 0_22 is set as %JAVA_HOME% \n\n4) Updated system classpath to include location of jars. \n\nNote: There are other files, that came with the JDK 1",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 53,
    "text_a": "From what i understand the purpose of the Authorization Code flow is to exchange the auth code for access token.  This exchange happens between the server which serves the page and authorization server so that the actual access token. \n\nHow should the page server store the access token once it is obtained? I was learning from a Pluralsight example.  If not then the flow will be initiated.  The callback looks like this:\n\n[CODE1]\n\nDoesn't storing the access token in the cookie defeath the whole purpose of the authorization. \nTherefore, the access token should be stored on the web application server only.  It should not be exposed to the browser, and it doesn't need to, because the browser never makes any.  It talks to the web application server instead, which in turn makes requests to the resource server using the. \nHow the browser authenticates itself with the web application server has nothing to do with OAuth 2. 0.  For example, it might be a regular session cookie, and the web application server might associate each session or. \nThe token request, which exchanges the authentication code for an access token, is done by the web application server, and. g. , using a shared [CODE2]). \nAuthorization code flow ensures that the client can be authenticated, which protects against malicious clients posing as legitimate clients.  Not all web application clients have a server component, and in some cases, requests to the resource server are.  In such situations, the browser is the client, and the access token must be stored by the browser (in.  In this case, the client cannot be authenticated (but a reasonable amount of security may be achieved by using. \nRecommended reading regarding OAuth 2. 0 security: https://www. rfc-editor. org/rfc/rfc6819#section-4. 3. 3 (RFC 6819)\n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 54,
    "text_a": "I am inheriting from System. Web. Http. AuthorizeAttribute to create a custom authorization/authentication routine to meet some unusual requirements for a web application developed using ASP. NET MVC 4.  This adds security to the Web API used for Ajax calls from the web client.  The requirements are:\n\n\nThe user must logon each time they perform a transaction to verify\nsomeone else has not walked up. \nRoles cannot be assigned to the web service methods at program time. \nThey must be assigned at run time so that an administrator can\nconfigure this.  This information is stored in the system database. \n\n\nThe web client is a single page application (SPA) so the typical forms authentication does not work so well, but. NET security framework as I can to meet the requirements.   The customized AuthorizeAttribute works great for requirement 2 on determining what roles are associated with a web service.  I accept three parameters, application name, resource name and operation to determine which roles are associated with a method. \n\n[CODE1]\n\nI override the OnAuthorization method to get the roles and authenticate the user.  Since the user has to be authenticated for each transaction I reduce the back and forth chatter by performing.   I get the users credentials from the web client by using basic authentication which passes the encrypted credentials.  So my OnAuthorization method looks like this:\n\n[CODE2]\n\nGetUserNameAndPassword retrieves the credentials from the HTTP header.  I then use the Membership. ValidateUser to validate the credentials.  I have a custom membership provider and role provider plugged in to hit a custom database.  If the user is authenticated I then retrieve the roles for the resource and operation.  From there I use the base OnAuthorization to complete the authorization process.   Here is where it breaks down. \n\nIf the user is authenticated I use the standard forms authentication methods to log the user in (FormsAuthentication. SetAuthCookie) and if they fail I log them out (FormsAuthentication. SignOut).   But the problem seems to be that base OnAuthorization class does not have access to Principal that is.  It is always one step behind.  And my guess is that it is using some cached value that does not get updated until there is",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 55,
    "text_a": "I'd like to generate a certificate for development purposes, but I don't want to install the certificate in the store. \n\n[CODE1] with the switch [CODE2] doesn't create the private key if you specify an output file. \n\nWhen I tried to create a [CODE3] file by exporting the certificate created with [CODE4], it asks for a password. . . \n\nWhy in the hell is it so complicated? Do you know a simple tool to create a certificate with private. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 56,
    "text_a": "I want to store a secret key (\"abc123\") that I will use in the header of my REST API requests.   My server will check this secret key.  If it matches \"abc123\", then allow the request to be made. \n\nI'm thinking about a simple solution like:\n\n[CODE1]\n\nBut are there going to be any downfalls to this?\nCrazy as it sounds, this.  Everything else is more complicated, but not much more secure.  Any fancy obfuscation techniques you use are just going to be reverse engineered almost as quickly as they'll find.  But this static key solution, while wildly insecure, is nearly as secure than the other solutions while imposing nearly.  I love it. \n\nIt will be broken almost immediately, but so will all the other solutions.  So keep it simple. \n\nThe one thing that you really want to do here is use HTTPS and pin your certificates.  And I'd pick a long, random key that isn't a word.  Ideally, it should be a completely random string of bytes, stored as raw values (not characters) so that it.  If you want to get crazy, apply a SHA256 to it before sending it (so the actual key never.  Again, this is trivial to break, but it's easy, and won't waste a lot of time developing. \n\nIt is unlikely that any effort longer than an hour will be worth the trouble to implement this feature.  If you want lots more on the topic, see Secure https encryption for iPhone app to webpage and its.  \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 57,
    "text_a": "On my Java EE6, REST service, I want to use authentication tokens for login from mobile devices, User will send. \nCan I simply create a token myself like this?(I guess I do not need to encrypt this since I will. )\n[CODE1]\nOr there is a more standard way to create these tokens? maybe it exists in one of the API`s?\nThe scheme.  After an initial login, the UID and 'userid' will be made available to the client, which can be simply. \n\nIf you need a service with 'login' and a session token, then why not just use an HttpSession?\n",
    "tgt_text": "create a token myself like this with HTTPS",
    "label": "C1",
    "code": "<code>String token = UUID.randomUUID().toString().toUpperCase() \n            + &quot;|&quot; + &quot;userid&quot; + &quot;|&quot;\n            + cal.getTimeInMillis();\n</code>"
  },
  {
    "guid": 58,
    "text_a": "I'm making SPA, and decided to use JWT for Authentication/Authorization, and I have read some blogs about Tokens vs Cookies.  I understand how cookie authorization works, and understand how basic token authorization works.  The problem is, I don't see how refresh token fits into it, seems to me it decreases security.  Let me explain, as I see it:\nCookie approach\nWhen you authenticate user via username &amp; password, you create session ID.  And set it as cookie, every time that client calls to your server it sends that cookie, and server. \n\nThis approach is vulnerable to CSRF (Cross Site Request Forgery) To prevent CSRF You can use tokens with cookie\n\nServer also. \n\n\nToken approach\nWhen you authenticate user via username &amp; password, you create a signed Token, with expiration date, email address or.  in payload.  For security tokens should have short expiration time.  Tokens can be stored anywhere Local storage, Session storage, cookies.  I will be using local storage, or session storage, to prevent XSRF. \n\nThis vulnerable to XSS (Cross Site Scripting), but you can prevent this by validating HTML input. \nBecause tokens have short lifecycle, user must login again, when token expires. \n\nAccess Token &amp; Refresh Token\nSo I want to use Refresh tokens to prevent user from needing to login constantly.  So lets say on Authentication, I give user Access token and Refresh token, when users Access token expires, user. \n\nlets say I store access token in local storage.  If I also store Refresh token in local storage, I don't see any use for it.  Because if attacker can access local storage and get Access token he can also get Refresh token.  So in this case why not just make Access token long lived. \nIf you store Refresh token as a cookie, it is vulnerable to XSRF, and then attacker can get new access.  Also at this point, why not just use Cookie authorization ? Because you already have to look up local. \n\nWhat's the best practice ?\nCurrently I'm thinking about using:\n\nAccess Token (local storage, short lived)\nRefresh Token (Cookie, Long lived)\nToken for Refresh.  What you think about this implementation ? In my eyes this limits server lookups to database, as it uses. \nIs this OK ?\nThanks !\nRegarding access token and refresh token\nConsider the access token to be a &quot;dirty&quot; token.  Token you share a lot.  I does not have to be one server you pass the token to, can be many.  Because of this the attack surface rises.  If one server does something stupid like writing tokens into server logs and then exposing the logs to the. \nOn the other hand a refresh token is a &quot;clean&quot; token.  Something you store for yourself to remember and use it only if you must",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 59,
    "text_a": "I have a Rails 5 API app ([CODE1]).  The need came up to add a simple GUI form for one endpoint of this API. \nInitially, I was getting [CODE2] when I tried to render the form.  I added [CODE3] and [CODE4] to that endpoint.  Which solved that issue as expected. \nHowever, when I try to submit this form I get: [CODE5] [CODE6] [CODE7].  I've added [CODE8] and verified that [CODE9] and [CODE10] are present in my headers, and that [CODE11] is present.  (The tokens themselves are different from each other. )\nI've tried, [CODE12], no effect.  I can &quot;fix&quot; this issue by commenting out: [CODE13].  But my understanding is that that is turning off CSRF protection on my form.  (I want CSRF protection. )\nWhat am I missing?\nUPDATE:\nTo try to make this clear, 99% of this app is a pure JSON RESTful API.  The need came up to add one HTML view and form to this app.  So for one Controller I want to enable full CSRF protection.  The rest of the app doesn't need CSRF and can remain unchanged. \nUPDATE 2:\nI just compared the page source of this app's HTML form and Header with another conventional Rails 5 app.  The [CODE14] in the Header and the [CODE15] in the form are the same.  In the API app I'm having the problem with, they're different.  Maybe that's something?\nUPDATE 3:\nOk, I don't the the mismatch is the issue.  However, in further comparisons between the working and non-working apps I noticed that there's nothing in Network &gt; Cookies.  I see a bunch of things like [CODE16] in the cookies of the working app. \nHere's what the issue was: Rails 5, when in API mode, logically doesn't include the Cookie middleware.  Without it, there's no Session [CODE17] stored in a Cookie to be used when validating the token I passed.  \n\nSomewhat confusingly, changing things in [CODE18] had no effect.  \n\nI eventually found the answer to that problem here: Adding cookie session store back to Rails API app, which. com/rails/rails/pull/28009/files which mentioned exactly the lines I needed to add to application. rb to get working Cookies back:\n\n[CODE19]\n\nThose three lines coupled with:\n\n[CODE20]\n\nAnd of course a form generated through the proper helpers:\n\n[CODE21]\n\nGot me. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 60,
    "text_a": "What's the need of to put CSRF token name and value inside &lt;head&gt; tag using &lt;meta&gt; like:\n\ne. g:\n\n[CODE1]\n\nI've read about concept to keep CSRF value in cookie but does not find about why to keep inside &lt;head&gt;. \nTo prevent CSRF you need a value that is submitted with the request that cannot be sent by a malicious.  Authentication cookies are not suitable because if an attacker can make the browser send a request to the victim. \n\nFor example, by submitting a form via JavaScript contained on [CODE2] to attack the user's session on [CODE3]:\n\n[CODE4]\n\nStoring an anti. \n\nThese tokens can be stored anywhere within the page.  Most commonly it will be within hidden form fields, but they could also be stored within HTML 5 data-.  It seems like using [CODE5] tags is simply another way it can be stored where the JavaScript can include. \n",
    "tgt_text": "use Authentication cookies to prevent CSRF",
    "label": "C1",
    "code": "<code>&lt;meta content=\"authenticity_token\" name=\"csrf-param\" /&gt;\n&lt;meta content=\"4sWPhTlJAmt1IcyNq1FCyivsAVhHqjiDCKRXOgOQock=\" name=\"csrf-token\" /&gt;\n</code>"
  },
  {
    "guid": 61,
    "text_a": "I'm using the RNG crypto provider to generate numbers in a range the truly naive way:\n[CODE1]\nThis is great when the. \nSo I've been trying to think of a better way that will achieve a decent distribution but will be faster.   But now I'm getting into deeper maths and statistics that I simply didn't do at school, or at. g.  for 4 it would be 3 and for 17 it would be 5\nselect a number of bytes from the. g. 1 in this case for 8 bits\nsee if any of the upper bits in the allowed range (3-5) are set\nif. \nif any of the previous tests fail, start again. \n\nLike I say, this could be exceedingly naive, but I am sure it will return a match in a narrow.   I'm not in front of a computer at the moment so can't test, will be doing that tomorrow. \nBut of course speed isn't my only concern, otherwise I would just use Random (needs a couple of tick marks. \nThe biggest concern I have with the above approach is that I am always throwing away up to 7 bits.   I thought of ways to factor them in (e. g.  a simple addition) but they seem terribly unscientific hacks!\nI know about the mod trick, where you only have to. \nIs this a dead end?  Ultimately if the best solution is going to be to stick with the current. Random (which contains the nice range-random method that you're looking for) but instead of using pseudo random numbers their implementation. \n\nThe way he has implemented the Next(min, max) method is as follows:\n\n[CODE2]\n\nThe reasoning for the choice of implementation as well. \n\nThread safe bufferred CryptoRandom\n\nI've written an extended implementation of Stephen's class which utilized a random buffer in order to minimize.  My implementation also uses synchronization to provide thread safety, making it possible to share the instance between all your.  \n\nI wrote this for a very specific scenario so you should of course profile whether or not is makes.  I threw the code up on github if you wan't to check it out. \n\nThreadsafe buffered CryptoRandom based on Stephen Toub and Shawn Farkas' implementation\n\nWhen I wrote it (a couple of years back) I. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 62,
    "text_a": "A hypothetical web-site currently connects using:\n\n[CODE1]\n\nWhere the magical connection string is stored in [CODE2]:\n\n[CODE3]\n\nNow i'd like to move the connection. config file into Azure KeyVault.  How do you retrieve anything out of the Azure key vault?\n\n[CODE4]\n\nExcept i just made up the easy-to-use Azure API.  What is the actual api?\n\nUntested attempt\n\n[CODE5]\n\nBonus Reading\n\n\nMSDN Forums: Storing sql connection string passwords in Key Vault for my Cloud. \n\nPreparation:\n\nRegistry Azure Active Directory application and assign Role\n\nSteps:\n\n1. Create KeyVault and add secret from Azure portal\n\n\n\n2. Config Access policy\n\n\n\n3. Get Access token\n\n[CODE6]\n\nNote: The resource for Keyvault is [CODE7]\n\n4. Test with Fiddler\n\n  \n\nWe also can do that easily with SDK:\n\n1. Create a console project and a Utils. cs file\n\n[CODE8]\n\n2. Add the follow code in the main function and test it. \n\n\n\npackages. config file\n\n[CODE9]\n\nWe also can get more information from CtrlDot mentioned document. \n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  },
  {
    "guid": 63,
    "text_a": "I have read about CSRF and how the Unpredictable Synchronizer Token Pattern is used to prevent it.  I didn't quite understand how it works. \n\nLet's take this scenario :\n\nA user is logged into a site with this form:\n\n[CODE1]\n\nThe server also stores the token in.  When the request is sent it compares the token in the form data to the token in the session. \n\nHow does that prevent CSRF when the hacker can write JavaScript code that will:\n\n\nSend a GET request to the site\nReceive. \nSearch the html text for the CSRF token. \nMake the malicious request using that token. \n\n\nAm missing something?\nThe attacker can't use JavaScript to read the token from the site, because it would be a cross-origin. \n\nTake this for example:\n\n\n\n[CODE2]\n\n\n\n\nThe JS console reports:\n\n\n  XMLHttpRequest cannot load [CODE3].  No '[CODE4]' header is present on the requested resource. \n\n",
    "tgt_text": "",
    "label": "C5",
    "code": ""
  }
]